{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our pipeline process:\n",
    "#### Extract Features:\n",
    "- `Airport_Pair` which will be used for `Delay_Trend_Past_Week` to see if there was a Delay trend in the previous week\n",
    "- `Same_Day_Tail_Reuse`which will be using **ONLY** the date from `dep_datetime`, as well as using `Tail_Number`\n",
    "- `Previous_Flight_Delay` which will be using information from `Tail_Number`, `dep_date` which will derive from `dep_datetime`, and `CRSDepTime`\n",
    "- `Turnaround_Time` will also be extracted from `CRSDepTime` subtracted by `Previous_Arrival_Time`(Which is derived from `Tail_Number`, `dep_date`, and `CRSArrTime`)\n",
    "- `Slack_Time` that derives from `CRSArrTime` subtracted by `CRSElaspedTime`\n",
    "\n",
    "#### Outlier\n",
    "- `Aircraft_Age` outlier must be removed \n",
    "\n",
    "#### Transformations: \n",
    "- `log_distance` using the log transformation \n",
    "\n",
    "#### Drop \n",
    "- is_Holidays\n",
    "\n",
    "Because so much data is missing, it is reasonable to remove \n",
    "Originally_Scheduled_Code_Share_Airline\n",
    "DOT_ID_Originally_Scheduled_Code_Share_Airline\n",
    "IATA_Code_Originally_Scheduled_Code_Share_Airline\n",
    "Flight_Num_Originally_Scheduled_Code_Share_Airline\n",
    "Unnamed: 119\n",
    "precipitation_probability\n",
    "precipitation_probability_dest_dep_time\n",
    "\n",
    "# also not gonna need\n",
    "'Origin_Lon', 'Origin_Lat',\n",
    "'Dest_Lat', 'Dest_Lon', 'Duplicate', 'Origin', 'Dest', 'OriginAirportSeqID', 'OriginStateName', 'DestAirportSeqID', 'DestStateName', 'DestWac', 'OriginWac','Operated_or_Branded_Code_Share_Partners',\n",
    "'OriginCityName', 'DestCityName', 'DestState', 'OriginState', 'DepTimeBlk', 'ArrTimeBlk', 'DistanceGroup', 'Aircraft_Airline', 'Aircraft_ModelCode', 'Aircraft_Type',\n",
    "'IATA_Code_Marketing_Airline', 'IATA_Code_Operating_Airline', 'latitude_dest_dep_time', 'longitude_dest_dep_time', 'longitude', 'latitude', 'Marketing_Airline_Network', \n",
    "'DOT_ID_Marketing_Airline', 'Flight_Number_Marketing_Airline', 'Operating_Airline ', dest_dep_datetime, 'Flights'\n",
    "\n",
    "because they are redundant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, FunctionTransformer, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import time\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn import set_config\n",
    "set_config(transform_output = \"pandas\")\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def stratified_random_split(df: pd.DataFrame, target_column: str, test_size: float = 0.1, random_state: int = 42):\n",
    "    \"\"\"\n",
    "    Performs a stratified random train-test split to ensure all classes in \n",
    "    'Flight_Status' are proportionally represented in both sets.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The dataset containing the target variable.\n",
    "    target_column (str): The column representing the classification target.\n",
    "    test_size (float): The proportion of data to be used as test data.\n",
    "    random_state (int): Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "    tuple: (train_df, test_df) DataFrames.\n",
    "    \"\"\"\n",
    "    train_df, test_df = train_test_split(\n",
    "        df, test_size=test_size, stratify=df[target_column], random_state=random_state\n",
    "    )\n",
    "\n",
    "    print(f\"Train size: {len(train_df)} samples\")\n",
    "    print(f\"Test size: {len(test_df)} samples\")\n",
    "\n",
    "    return train_df, test_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setting up the DataFrame for the flight data\n",
    "flight_data = pd.read_parquet(\"WEATHER121.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 13184010 samples\n",
      "Test size: 1464890 samples\n"
     ]
    }
   ],
   "source": [
    "# Stratify the data\n",
    "train_data, test_data= stratified_random_split(flight_data, target_column=\"Flight_Status\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#downsample to 100000\n",
    "\n",
    "#train_data = train_data.sample(n=100000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Splitting the data into X and y\n",
    "X_train = train_data.drop(columns=[\"Flight_Status\"])\n",
    "y_train = train_data[\"Flight_Status\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Custom progress logger\n",
    "class ProgressLogger(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    A transformer that logs progress through a pipeline.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, total_rows, log_interval=0.01, name='Pipeline'):\n",
    "        self.total_rows = total_rows\n",
    "        self.log_interval = log_interval\n",
    "        self.name = name\n",
    "        self.start_time = None\n",
    "        self.last_log_percent = -1\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        # Initialize timer if not started\n",
    "        if self.start_time is None:\n",
    "            self.start_time = time.time()\n",
    "            print(f\"{self.name} processing started on {self.total_rows:,} rows\")\n",
    "        \n",
    "        # Calculate current progress\n",
    "        current_rows = X.shape[0]\n",
    "        percent_complete = current_rows / self.total_rows\n",
    "        \n",
    "        # Check if we need to log progress\n",
    "        int_percent = int(percent_complete / self.log_interval)\n",
    "        if int_percent > self.last_log_percent:\n",
    "            self.last_log_percent = int_percent\n",
    "            elapsed = time.time() - self.start_time\n",
    "            \n",
    "            # Estimate time remaining\n",
    "            percent_done = percent_complete * 100\n",
    "            if percent_complete > 0:\n",
    "                total_est = elapsed / percent_complete\n",
    "                remaining = total_est - elapsed\n",
    "                time_str = f\" - Est. remaining: {remaining:.1f}s\"\n",
    "            else:\n",
    "                time_str = \"\"\n",
    "                \n",
    "            print(f\"{self.name}: {percent_done:.1f}% complete ({current_rows:,}/{self.total_rows:,} rows){time_str}\")\n",
    "        \n",
    "        return X\n",
    "\n",
    "class DelayTrendEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer that precomputes a route-based delay trend using week_of_year and top N airports.\n",
    "\n",
    "    Parameters:\n",
    "        date_col (str): Name of the datetime column\n",
    "        origin_col (str): Origin airport column\n",
    "        dest_col (str): Destination airport column\n",
    "        status_col (str): Flight status column for delay signal\n",
    "        output_col (str): Name of the new delay trend feature\n",
    "        top_n_airports (int): Number of top airports to retain by frequency\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 date_col='dep_datetime',\n",
    "                 origin_col='OriginAirportID',\n",
    "                 dest_col='DestAirportID',\n",
    "                 status_col='Flight_Status',\n",
    "                 output_col='Delay_Trend',\n",
    "                 top_n_airports=15):\n",
    "        self.date_col = date_col\n",
    "        self.origin_col = origin_col\n",
    "        self.dest_col = dest_col\n",
    "        self.status_col = status_col\n",
    "        self.output_col = output_col\n",
    "        self.top_n_airports = top_n_airports\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X_temp = X.copy()\n",
    "        X_temp[self.date_col] = pd.to_datetime(X_temp[self.date_col])\n",
    "        X_temp['week_of_year'] = X_temp[self.date_col].dt.isocalendar().week\n",
    "\n",
    "        X_temp['Flight_Status'] = y.reset_index(drop=True)\n",
    "        \n",
    "        # Restrict to top N airports\n",
    "        all_airports = pd.concat([X_temp[self.origin_col], X_temp[self.dest_col]])\n",
    "        top_airports = all_airports.value_counts().head(self.top_n_airports).index\n",
    "        X_temp = X_temp[\n",
    "            X_temp[self.origin_col].isin(top_airports) &\n",
    "            X_temp[self.dest_col].isin(top_airports)\n",
    "        ]\n",
    "\n",
    "        # Create delay signal\n",
    "        delay_reasons = [\n",
    "            'CarrierDelay', 'WeatherDelay', 'NASDelay',\n",
    "            'SecurityDelay', 'LateAircraftDelay'\n",
    "        ]\n",
    "        X_temp['delay_signal'] = 0\n",
    "        mask = X_temp['Flight_Status'].str.contains('Delay', na=False)\n",
    "        delay_type = X_temp.loc[mask, 'Flight_Status'].str.split(' - ').str[-1]\n",
    "        valid = delay_type.isin(delay_reasons)\n",
    "        X_temp.loc[mask[mask].index[valid], 'delay_signal'] = 1\n",
    "\n",
    "        # Group by week and airport pair\n",
    "        self.trend_lookup_ = (\n",
    "            X_temp.groupby(['week_of_year', self.origin_col, self.dest_col])['delay_signal']\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "            .rename(columns={'delay_signal': self.output_col})\n",
    "        )\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X[self.date_col] = pd.to_datetime(X[self.date_col])\n",
    "        X['week_of_year'] = X[self.date_col].dt.isocalendar().week\n",
    "\n",
    "        X = X.merge(\n",
    "            self.trend_lookup_,\n",
    "            on=['week_of_year', self.origin_col, self.dest_col],\n",
    "            how='left'\n",
    "        )\n",
    "\n",
    "        X[self.output_col] = X[self.output_col].fillna(0)\n",
    "        return X.drop(columns=['week_of_year'])\n",
    "\n",
    "class SameDayTailReuseEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer that creates a feature counting how many times\n",
    "    the same tail number (aircraft) is used on the same day.\n",
    "\n",
    "    Parameters:\n",
    "        datetime_col (str): Column containing full departure datetime\n",
    "        tail_col (str): Column name for tail number\n",
    "        output_col (str): Name of the output column\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 datetime_col='dep_datetime',\n",
    "                 tail_col='Tail_Number',\n",
    "                 output_col='Same_Day_Tail_Reuse'):\n",
    "        self.datetime_col = datetime_col\n",
    "        self.tail_col = tail_col\n",
    "        self.output_col = output_col\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "\n",
    "        # Ensure datetime is parsed correctly\n",
    "        X[self.datetime_col] = pd.to_datetime(X[self.datetime_col])\n",
    "\n",
    "        # Extract just the date portion\n",
    "        X['dep_date'] = X[self.datetime_col].dt.date\n",
    "\n",
    "        # Count reuse of same tail number per day\n",
    "        X[self.output_col] = (\n",
    "            X.groupby([self.tail_col, 'dep_date'])[self.tail_col]\n",
    "            .transform('count')\n",
    "            .astype(float)  \n",
    "        )\n",
    "\n",
    "        return X.drop(columns=['dep_date'])\n",
    "\n",
    "    \n",
    "class TurnaroundDelayEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer that computes:\n",
    "    - Previous_Flight_Delay: scheduled departure time of previous flight with same tail number on same day\n",
    "    - Turnaround_Time: time between previous arrival and current departure\n",
    "\n",
    "    Parameters:\n",
    "        datetime_col (str): Column with full departure datetime\n",
    "        dep_time_col (str): Column with scheduled departure time (e.g. CRSDepTime)\n",
    "        arr_time_col (str): Column with scheduled arrival time (e.g. CRSArrTime)\n",
    "        tail_col (str): Tail number column\n",
    "        output_prefix (str): Prefix to use for new feature columns\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 datetime_col='dep_datetime',\n",
    "                 dep_time_col='CRSDepTime',\n",
    "                 arr_time_col='CRSArrTime',\n",
    "                 tail_col='Tail_Number',\n",
    "                 output_prefix=''):\n",
    "        self.datetime_col = datetime_col\n",
    "        self.dep_time_col = dep_time_col\n",
    "        self.arr_time_col = arr_time_col\n",
    "        self.tail_col = tail_col\n",
    "        self.output_prefix = output_prefix\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X[self.datetime_col] = pd.to_datetime(X[self.datetime_col])\n",
    "        X['dep_date'] = X[self.datetime_col].dt.date\n",
    "\n",
    "        # Sort the values\n",
    "        X = X.sort_values(by=[self.tail_col, 'dep_date', self.dep_time_col])\n",
    "\n",
    "        prev_delay_col = self.output_prefix + 'Previous_Flight_Delay'\n",
    "        turnaround_col = self.output_prefix + 'Turnaround_Time'\n",
    "\n",
    "        # Previous scheduled departure\n",
    "        X[prev_delay_col] = (\n",
    "            X.groupby([self.tail_col, 'dep_date'])[self.dep_time_col]\n",
    "            .shift(1)\n",
    "        )\n",
    "\n",
    "        # Previous scheduled arrival time\n",
    "        X['Previous_Arrival_Time'] = (\n",
    "            X.groupby([self.tail_col, 'dep_date'])[self.arr_time_col]\n",
    "            .shift(1)\n",
    "        )\n",
    "\n",
    "        # Compute turnaround time using a defined method\n",
    "        X[turnaround_col] = self._calculate_turnaround(X[self.dep_time_col], X['Previous_Arrival_Time'])\n",
    "\n",
    "        # Replace missing with 0\n",
    "        X[prev_delay_col] = X[prev_delay_col].fillna(0)\n",
    "        X[turnaround_col] = X[turnaround_col].fillna(0)\n",
    "\n",
    "        return X.drop(columns=['dep_date', 'Previous_Arrival_Time'])\n",
    "\n",
    "    def _calculate_turnaround(self, current_dep, previous_arr):\n",
    "        \"\"\"\n",
    "        Applies time difference logic with wrap-around at midnight (2400).\n",
    "        \"\"\"\n",
    "        diff = current_dep - previous_arr\n",
    "        adjusted = diff.mask((~diff.isna()) & (diff < 0), diff + 2400)\n",
    "        return adjusted\n",
    "\n",
    "class SlackTimeEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer that calculates slack time as the difference between scheduled\n",
    "    arrival time (CRSArrTime) and scheduled elapsed time (CRSElapsedTime).\n",
    "\n",
    "    Parameters:\n",
    "        arr_col (str): Column name for scheduled arrival time.\n",
    "        elapsed_col (str): Column name for scheduled elapsed time.\n",
    "        output_col (str): Name of the output column to store slack time.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 arr_col='CRSArrTime',\n",
    "                 elapsed_col='CRSElapsedTime',\n",
    "                 output_col='Slack_Time'):\n",
    "        self.arr_col = arr_col\n",
    "        self.elapsed_col = elapsed_col\n",
    "        self.output_col = output_col\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X[self.output_col] = X[self.arr_col] - X[self.elapsed_col]\n",
    "        return X\n",
    "    \n",
    "    \n",
    "\n",
    "class AgeClipper(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer that caps aircraft age at a maximum value.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    max_age : float, default=56.9\n",
    "        Maximum value for aircraft age\n",
    "    column_name : str, default='Aircraft_Age'\n",
    "        Name of the column to apply the cap to\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, max_age=56.9, column_name='Aircraft_Age'):\n",
    "        self.max_age = max_age\n",
    "        self.column_name = column_name\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        # Nothing to fit, just return self\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Convert to DataFrame if it's not already\n",
    "        X_transformed = X.copy() if isinstance(X, pd.DataFrame) else pd.DataFrame(X)\n",
    "        \n",
    "        # Apply the cap only if the column exists\n",
    "        if self.column_name in X_transformed.columns:\n",
    "            X_transformed[self.column_name] = np.minimum(X_transformed[self.column_name], self.max_age)\n",
    "        \n",
    "        # Return array if input was array\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X_transformed = X_transformed.values\n",
    "            \n",
    "        return X_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;initial_logger&#x27;,\n",
       "                 ProgressLogger(name=&#x27;Starting Pipeline&#x27;, total_rows=13000000)),\n",
       "                (&#x27;delay_trend&#x27;, DelayTrendEncoder()),\n",
       "                (&#x27;trend_logger&#x27;,\n",
       "                 ProgressLogger(name=&#x27;Delay Trend Complete&#x27;,\n",
       "                                total_rows=13000000)),\n",
       "                (&#x27;tail_reuse&#x27;, SameDayTailReuseEncoder()),\n",
       "                (&#x27;reuse_logger&#x27;,\n",
       "                 ProgressLogger(name=&#x27;Tail Reuse Complete&#x27;,\n",
       "                                total_rows=13000000)),\n",
       "                (&#x27;turnaround_delay&#x27;, T...\n",
       "                                                   &#x27;soil_temperature_0cm&#x27;,\n",
       "                                                   &#x27;rain&#x27;, &#x27;rain_dest_dep_time&#x27;,\n",
       "                                                   &#x27;dew_point_2m_dest_dep_time&#x27;,\n",
       "                                                   &#x27;cloud_cover_mid&#x27;,\n",
       "                                                   &#x27;cloud_cover&#x27;, ...])],\n",
       "                                   verbose_feature_names_out=False)),\n",
       "                (&#x27;prep_logger&#x27;,\n",
       "                 ProgressLogger(name=&#x27;Feature Prep Complete&#x27;,\n",
       "                                total_rows=13000000)),\n",
       "                (&#x27;select&#x27;, PCA(n_components=50, random_state=42)),\n",
       "                (&#x27;final_logger&#x27;,\n",
       "                 ProgressLogger(name=&#x27;Pipeline Complete&#x27;,\n",
       "                                total_rows=13000000))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-134\" type=\"checkbox\" ><label for=\"sk-estimator-id-134\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;initial_logger&#x27;,\n",
       "                 ProgressLogger(name=&#x27;Starting Pipeline&#x27;, total_rows=13000000)),\n",
       "                (&#x27;delay_trend&#x27;, DelayTrendEncoder()),\n",
       "                (&#x27;trend_logger&#x27;,\n",
       "                 ProgressLogger(name=&#x27;Delay Trend Complete&#x27;,\n",
       "                                total_rows=13000000)),\n",
       "                (&#x27;tail_reuse&#x27;, SameDayTailReuseEncoder()),\n",
       "                (&#x27;reuse_logger&#x27;,\n",
       "                 ProgressLogger(name=&#x27;Tail Reuse Complete&#x27;,\n",
       "                                total_rows=13000000)),\n",
       "                (&#x27;turnaround_delay&#x27;, T...\n",
       "                                                   &#x27;soil_temperature_0cm&#x27;,\n",
       "                                                   &#x27;rain&#x27;, &#x27;rain_dest_dep_time&#x27;,\n",
       "                                                   &#x27;dew_point_2m_dest_dep_time&#x27;,\n",
       "                                                   &#x27;cloud_cover_mid&#x27;,\n",
       "                                                   &#x27;cloud_cover&#x27;, ...])],\n",
       "                                   verbose_feature_names_out=False)),\n",
       "                (&#x27;prep_logger&#x27;,\n",
       "                 ProgressLogger(name=&#x27;Feature Prep Complete&#x27;,\n",
       "                                total_rows=13000000)),\n",
       "                (&#x27;select&#x27;, PCA(n_components=50, random_state=42)),\n",
       "                (&#x27;final_logger&#x27;,\n",
       "                 ProgressLogger(name=&#x27;Pipeline Complete&#x27;,\n",
       "                                total_rows=13000000))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-135\" type=\"checkbox\" ><label for=\"sk-estimator-id-135\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ProgressLogger</label><div class=\"sk-toggleable__content\"><pre>ProgressLogger(name=&#x27;Starting Pipeline&#x27;, total_rows=13000000)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-136\" type=\"checkbox\" ><label for=\"sk-estimator-id-136\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DelayTrendEncoder</label><div class=\"sk-toggleable__content\"><pre>DelayTrendEncoder()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-137\" type=\"checkbox\" ><label for=\"sk-estimator-id-137\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ProgressLogger</label><div class=\"sk-toggleable__content\"><pre>ProgressLogger(name=&#x27;Delay Trend Complete&#x27;, total_rows=13000000)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-138\" type=\"checkbox\" ><label for=\"sk-estimator-id-138\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SameDayTailReuseEncoder</label><div class=\"sk-toggleable__content\"><pre>SameDayTailReuseEncoder()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-139\" type=\"checkbox\" ><label for=\"sk-estimator-id-139\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ProgressLogger</label><div class=\"sk-toggleable__content\"><pre>ProgressLogger(name=&#x27;Tail Reuse Complete&#x27;, total_rows=13000000)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-140\" type=\"checkbox\" ><label for=\"sk-estimator-id-140\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TurnaroundDelayEncoder</label><div class=\"sk-toggleable__content\"><pre>TurnaroundDelayEncoder()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-141\" type=\"checkbox\" ><label for=\"sk-estimator-id-141\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ProgressLogger</label><div class=\"sk-toggleable__content\"><pre>ProgressLogger(name=&#x27;Turnaround Delay Complete&#x27;, total_rows=13000000)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-142\" type=\"checkbox\" ><label for=\"sk-estimator-id-142\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SlackTimeEncoder</label><div class=\"sk-toggleable__content\"><pre>SlackTimeEncoder()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-143\" type=\"checkbox\" ><label for=\"sk-estimator-id-143\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ProgressLogger</label><div class=\"sk-toggleable__content\"><pre>ProgressLogger(name=&#x27;Slack Time Complete&#x27;, total_rows=13000000)</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-144\" type=\"checkbox\" ><label for=\"sk-estimator-id-144\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">feature_prep: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(n_jobs=16, remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;numeric&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;, SimpleImputer()),\n",
       "                                                 (&#x27;age_clipper&#x27;, AgeClipper()),\n",
       "                                                 (&#x27;log1p_distance&#x27;,\n",
       "                                                  ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                                                    transformers=[(&#x27;log&#x27;,\n",
       "                                                                                   FunctionTransformer(func=&lt;ufunc &#x27;log1p&#x27;&gt;),\n",
       "                                                                                   [&#x27;Distance&#x27;,\n",
       "                                                                                    &#x27;wind_gusts_10m_dest_dep_time&#x27;])],\n",
       "                                                                    verbose_feature_names_out=False)...\n",
       "                                  &#x27;wind_speed_120m_dest_dep_time&#x27;,\n",
       "                                  &#x27;wind_speed_180m_dest_dep_time&#x27;,\n",
       "                                  &#x27;wind_direction_80m_dest_dep_time&#x27;,\n",
       "                                  &#x27;wind_direction_120m_dest_dep_time&#x27;,\n",
       "                                  &#x27;wind_direction_180m_dest_dep_time&#x27;,\n",
       "                                  &#x27;soil_temperature_0cm_dest_dep_time&#x27;,\n",
       "                                  &#x27;soil_temperature_0cm&#x27;, &#x27;rain&#x27;,\n",
       "                                  &#x27;rain_dest_dep_time&#x27;,\n",
       "                                  &#x27;dew_point_2m_dest_dep_time&#x27;,\n",
       "                                  &#x27;cloud_cover_mid&#x27;, &#x27;cloud_cover&#x27;, ...])],\n",
       "                  verbose_feature_names_out=False)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-145\" type=\"checkbox\" ><label for=\"sk-estimator-id-145\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">numeric</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Distance&#x27;, &#x27;relative_humidity_2m&#x27;, &#x27;temperature_2m&#x27;, &#x27;Aircraft_Age&#x27;, &#x27;temperature_2m_dest_dep_time&#x27;, &#x27;snowfall&#x27;, &#x27;soil_moisture_0_to_1cm&#x27;, &#x27;snowfall_dest_dep_time&#x27;, &#x27;et0_fao_evapotranspiration_dest_dep_time&#x27;, &#x27;surface_pressure_dest_dep_time&#x27;, &#x27;pressure_msl_dest_dep_time&#x27;, &#x27;wind_direction_10m_dest_dep_time&#x27;, &#x27;wind_gusts_10m_dest_dep_time&#x27;, &#x27;CRSElapsedTime&#x27;, &#x27;Slack_Time&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-146\" type=\"checkbox\" ><label for=\"sk-estimator-id-146\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-147\" type=\"checkbox\" ><label for=\"sk-estimator-id-147\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AgeClipper</label><div class=\"sk-toggleable__content\"><pre>AgeClipper()</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-148\" type=\"checkbox\" ><label for=\"sk-estimator-id-148\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">log1p_distance: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;log&#x27;,\n",
       "                                 FunctionTransformer(func=&lt;ufunc &#x27;log1p&#x27;&gt;),\n",
       "                                 [&#x27;Distance&#x27;, &#x27;wind_gusts_10m_dest_dep_time&#x27;])],\n",
       "                  verbose_feature_names_out=False)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-149\" type=\"checkbox\" ><label for=\"sk-estimator-id-149\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">log</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Distance&#x27;, &#x27;wind_gusts_10m_dest_dep_time&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-150\" type=\"checkbox\" ><label for=\"sk-estimator-id-150\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;ufunc &#x27;log1p&#x27;&gt;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-151\" type=\"checkbox\" ><label for=\"sk-estimator-id-151\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre></pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-152\" type=\"checkbox\" ><label for=\"sk-estimator-id-152\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-153\" type=\"checkbox\" ><label for=\"sk-estimator-id-153\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-154\" type=\"checkbox\" ><label for=\"sk-estimator-id-154\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">categorical</label><div class=\"sk-toggleable__content\"><pre>[&#x27;DayOfWeek&#x27;, &#x27;Month&#x27;, &#x27;OriginAirportID&#x27;, &#x27;DestAirportID&#x27;, &#x27;Is_Holiday_Week&#x27;, &#x27;Operating_Airline &#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-155\" type=\"checkbox\" ><label for=\"sk-estimator-id-155\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-156\" type=\"checkbox\" ><label for=\"sk-estimator-id-156\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OHE: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;top50&#x27;,\n",
       "                                 OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                               max_categories=51,\n",
       "                                               sparse_output=False),\n",
       "                                 [&#x27;OriginAirportID&#x27;, &#x27;DestAirportID&#x27;]),\n",
       "                                (&#x27;OHE&#x27;,\n",
       "                                 OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                               sparse_output=False),\n",
       "                                 [&#x27;DayOfWeek&#x27;, &#x27;Month&#x27;, &#x27;Operating_Airline &#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-157\" type=\"checkbox\" ><label for=\"sk-estimator-id-157\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">top50</label><div class=\"sk-toggleable__content\"><pre>[&#x27;OriginAirportID&#x27;, &#x27;DestAirportID&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-158\" type=\"checkbox\" ><label for=\"sk-estimator-id-158\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, max_categories=51, sparse_output=False)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-159\" type=\"checkbox\" ><label for=\"sk-estimator-id-159\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OHE</label><div class=\"sk-toggleable__content\"><pre>[&#x27;DayOfWeek&#x27;, &#x27;Month&#x27;, &#x27;Operating_Airline &#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-160\" type=\"checkbox\" ><label for=\"sk-estimator-id-160\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse_output=False)</pre></div></div></div></div></div></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-161\" type=\"checkbox\" ><label for=\"sk-estimator-id-161\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">drop</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Aircraft_Model&#x27;, &#x27;Aircraft_EngineType&#x27;, &#x27;Holiday&#x27;, &#x27;dep_datetime&#x27;, &#x27;Tail_Number&#x27;, &#x27;temperature_120m_dest_dep_time&#x27;, &#x27;temperature_180m_dest_dep_time&#x27;, &#x27;temperature_80m_dest_dep_time&#x27;, &#x27;temperature_180m&#x27;, &#x27;temperature_120m&#x27;, &#x27;temperature_80m&#x27;, &#x27;wind_speed_80m&#x27;, &#x27;wind_speed_120m&#x27;, &#x27;wind_speed_180m&#x27;, &#x27;wind_direction_80m&#x27;, &#x27;wind_direction_120m&#x27;, &#x27;wind_direction_180m&#x27;, &#x27;wind_speed_80m_dest_dep_time&#x27;, &#x27;wind_speed_120m_dest_dep_time&#x27;, &#x27;wind_speed_180m_dest_dep_time&#x27;, &#x27;wind_direction_80m_dest_dep_time&#x27;, &#x27;wind_direction_120m_dest_dep_time&#x27;, &#x27;wind_direction_180m_dest_dep_time&#x27;, &#x27;soil_temperature_0cm_dest_dep_time&#x27;, &#x27;soil_temperature_0cm&#x27;, &#x27;rain&#x27;, &#x27;rain_dest_dep_time&#x27;, &#x27;dew_point_2m_dest_dep_time&#x27;, &#x27;cloud_cover_mid&#x27;, &#x27;cloud_cover&#x27;, &#x27;cloud_cover_mid_dest_dep_time&#x27;, &#x27;cloud_cover_dest_dep_time&#x27;, &#x27;dew_point_2m&#x27;, &#x27;wind_speed_10m&#x27;, &#x27;wind_speed_10m_dest_dep_time&#x27;, &#x27;visibility_dest_dep_time&#x27;, &#x27;visibility&#x27;, &#x27;apparent_temperature&#x27;, &#x27;apparent_temperature_dest_dep_time&#x27;, &#x27;vapour_pressure_deficit&#x27;, &#x27;vapour_pressure_deficit_dest_dep_time&#x27;, &#x27;Flights&#x27;, &#x27;DOT_ID_Operating_Airline&#x27;, &#x27;Flight_Number_Operating_Airline&#x27;, &#x27;Aircraft_Engines&#x27;, &#x27;Aircraft_Seats&#x27;, &#x27;Is_Freighter&#x27;, &#x27;relative_humidity_2m_dest_dep_time&#x27;, &#x27;precipitation&#x27;, &#x27;showers&#x27;, &#x27;snow_depth&#x27;, &#x27;et0_fao_evapotranspiration&#x27;, &#x27;evapotranspiration&#x27;, &#x27;cloud_cover_high&#x27;, &#x27;cloud_cover_low&#x27;, &#x27;surface_pressure&#x27;, &#x27;weather_code&#x27;, &#x27;pressure_msl&#x27;, &#x27;wind_direction_10m&#x27;, &#x27;wind_gusts_10m&#x27;, &#x27;precipitation_dest_dep_time&#x27;, &#x27;showers_dest_dep_time&#x27;, &#x27;snow_depth_dest_dep_time&#x27;, &#x27;soil_moisture_0_to_1cm_dest_dep_time&#x27;, &#x27;evapotranspiration_dest_dep_time&#x27;, &#x27;cloud_cover_high_dest_dep_time&#x27;, &#x27;cloud_cover_low_dest_dep_time&#x27;, &#x27;weather_code_dest_dep_time&#x27;, &#x27;Operated_or_Branded_Code_Share_Partners&#x27;, &#x27;Year&#x27;, &#x27;Quarter&#x27;, &#x27;Marketing_Airline_Network&#x27;, &#x27;DayofMonth&#x27;, &#x27;DOT_ID_Marketing_Airline&#x27;, &#x27;Flight_Number_Marketing_Airline&#x27;, &#x27;OriginAirportSeqID&#x27;, &#x27;OriginCityMarketID&#x27;, &#x27;Origin&#x27;, &#x27;OriginCityName&#x27;, &#x27;OriginState&#x27;, &#x27;OriginStateFips&#x27;, &#x27;OriginStateName&#x27;, &#x27;OriginWac&#x27;, &#x27;DestAirportSeqID&#x27;, &#x27;DestCityMarketID&#x27;, &#x27;Dest&#x27;, &#x27;DestCityName&#x27;, &#x27;DestState&#x27;, &#x27;DestStateFips&#x27;, &#x27;DestStateName&#x27;, &#x27;DestWac&#x27;, &#x27;CRSDepTime&#x27;, &#x27;DepTimeBlk&#x27;, &#x27;CRSArrTime&#x27;, &#x27;ArrTimeBlk&#x27;, &#x27;DistanceGroup&#x27;, &#x27;Duplicate&#x27;, &#x27;Aircraft_Airline&#x27;, &#x27;Aircraft_ModelCode&#x27;, &#x27;Aircraft_Type&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-162\" type=\"checkbox\" ><label for=\"sk-estimator-id-162\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">drop</label><div class=\"sk-toggleable__content\"><pre>drop</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-163\" type=\"checkbox\" ><label for=\"sk-estimator-id-163\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre></pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-164\" type=\"checkbox\" ><label for=\"sk-estimator-id-164\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-165\" type=\"checkbox\" ><label for=\"sk-estimator-id-165\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ProgressLogger</label><div class=\"sk-toggleable__content\"><pre>ProgressLogger(name=&#x27;Feature Prep Complete&#x27;, total_rows=13000000)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-166\" type=\"checkbox\" ><label for=\"sk-estimator-id-166\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(n_components=50, random_state=42)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-167\" type=\"checkbox\" ><label for=\"sk-estimator-id-167\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ProgressLogger</label><div class=\"sk-toggleable__content\"><pre>ProgressLogger(name=&#x27;Pipeline Complete&#x27;, total_rows=13000000)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('initial_logger',\n",
       "                 ProgressLogger(name='Starting Pipeline', total_rows=13000000)),\n",
       "                ('delay_trend', DelayTrendEncoder()),\n",
       "                ('trend_logger',\n",
       "                 ProgressLogger(name='Delay Trend Complete',\n",
       "                                total_rows=13000000)),\n",
       "                ('tail_reuse', SameDayTailReuseEncoder()),\n",
       "                ('reuse_logger',\n",
       "                 ProgressLogger(name='Tail Reuse Complete',\n",
       "                                total_rows=13000000)),\n",
       "                ('turnaround_delay', T...\n",
       "                                                   'soil_temperature_0cm',\n",
       "                                                   'rain', 'rain_dest_dep_time',\n",
       "                                                   'dew_point_2m_dest_dep_time',\n",
       "                                                   'cloud_cover_mid',\n",
       "                                                   'cloud_cover', ...])],\n",
       "                                   verbose_feature_names_out=False)),\n",
       "                ('prep_logger',\n",
       "                 ProgressLogger(name='Feature Prep Complete',\n",
       "                                total_rows=13000000)),\n",
       "                ('select', PCA(n_components=50, random_state=42)),\n",
       "                ('final_logger',\n",
       "                 ProgressLogger(name='Pipeline Complete',\n",
       "                                total_rows=13000000))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "numerical_features = [\n",
    "    'Distance', 'relative_humidity_2m', 'temperature_2m',\n",
    "    'Aircraft_Age', 'temperature_2m_dest_dep_time',\n",
    "    'snowfall', 'soil_moisture_0_to_1cm',\n",
    "    'snowfall_dest_dep_time', \n",
    "    'et0_fao_evapotranspiration_dest_dep_time',\n",
    "    'surface_pressure_dest_dep_time', 'pressure_msl_dest_dep_time',\n",
    "    'wind_direction_10m_dest_dep_time', 'wind_gusts_10m_dest_dep_time', 'CRSElapsedTime', 'Slack_Time'\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    'DayOfWeek', 'Month',\n",
    "    'OriginAirportID',\n",
    "    'DestAirportID', 'Is_Holiday_Week', 'Operating_Airline '\n",
    "]\n",
    "\n",
    "drop_features = [\n",
    "            'Aircraft_Model', 'Aircraft_EngineType', 'Holiday',\n",
    "            'dep_datetime', 'Tail_Number', 'temperature_120m_dest_dep_time', \n",
    "            'temperature_180m_dest_dep_time', 'temperature_80m_dest_dep_time', 'temperature_180m', \n",
    "            'temperature_120m', 'temperature_80m', 'wind_speed_80m', 'wind_speed_120m',\n",
    "            'wind_speed_180m', 'wind_direction_80m', 'wind_direction_120m', 'wind_direction_180m',\n",
    "            'wind_speed_80m_dest_dep_time', 'wind_speed_120m_dest_dep_time', 'wind_speed_180m_dest_dep_time',\n",
    "            'wind_direction_80m_dest_dep_time', 'wind_direction_120m_dest_dep_time', 'wind_direction_180m_dest_dep_time', \n",
    "            'soil_temperature_0cm_dest_dep_time', 'soil_temperature_0cm', 'rain', 'rain_dest_dep_time', 'dew_point_2m_dest_dep_time', \n",
    "            'cloud_cover_mid', 'cloud_cover', 'cloud_cover_mid_dest_dep_time', 'cloud_cover_dest_dep_time', 'dew_point_2m', \n",
    "            'wind_speed_10m', 'wind_speed_10m_dest_dep_time', 'visibility_dest_dep_time', 'visibility', 'apparent_temperature', \n",
    "            'apparent_temperature_dest_dep_time', 'vapour_pressure_deficit', 'vapour_pressure_deficit_dest_dep_time', 'Flights',\n",
    "            'DOT_ID_Operating_Airline', 'Flight_Number_Operating_Airline', 'Aircraft_Engines', 'Aircraft_Seats', 'Is_Freighter',\n",
    "            'relative_humidity_2m_dest_dep_time', 'precipitation', 'showers', 'snow_depth', 'et0_fao_evapotranspiration',\n",
    "            'evapotranspiration', 'cloud_cover_high', 'cloud_cover_low', 'surface_pressure', 'weather_code', 'pressure_msl', \n",
    "            'wind_direction_10m', 'wind_gusts_10m', 'precipitation_dest_dep_time', 'showers_dest_dep_time', 'snow_depth_dest_dep_time',\n",
    "            'soil_moisture_0_to_1cm_dest_dep_time', 'evapotranspiration_dest_dep_time', 'cloud_cover_high_dest_dep_time',\n",
    "            'cloud_cover_low_dest_dep_time', 'weather_code_dest_dep_time', 'Operated_or_Branded_Code_Share_Partners', 'Year',\n",
    "            'Quarter', 'Marketing_Airline_Network', 'DayofMonth', 'DOT_ID_Marketing_Airline', 'Flight_Number_Marketing_Airline', \n",
    "            'OriginAirportSeqID', 'OriginCityMarketID', 'Origin', 'OriginCityName', 'OriginState', 'OriginStateFips', \n",
    "            'OriginStateName', 'OriginWac', 'DestAirportSeqID', 'DestCityMarketID', 'Dest', 'DestCityName', 'DestState', 'DestStateFips', \n",
    "            'DestStateName', 'DestWac', 'CRSDepTime', 'DepTimeBlk', 'CRSArrTime', 'ArrTimeBlk', 'DistanceGroup', 'Duplicate', \n",
    "            'Aircraft_Airline', 'Aircraft_ModelCode', 'Aircraft_Type'\n",
    "        ]\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('age_clipper', AgeClipper(max_age=56.9, column_name='Aircraft_Age')),\n",
    "    ('log1p_distance', ColumnTransformer([\n",
    "        ('log', FunctionTransformer(np.log1p), ['Distance', 'wind_gusts_10m_dest_dep_time'])\n",
    "    ], remainder='passthrough', verbose_feature_names_out=False)), \n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('OHE', ColumnTransformer([\n",
    "        ('top50', OneHotEncoder(handle_unknown='ignore', sparse_output=False, max_categories=51), ['OriginAirportID', 'DestAirportID']),\n",
    "        ('OHE' , OneHotEncoder(handle_unknown='ignore', sparse_output=False), ['DayOfWeek', 'Month', 'Operating_Airline '])\n",
    "    ]))\n",
    "])\n",
    "\n",
    "preprocessor = Pipeline([\n",
    "    ('initial_logger', ProgressLogger(total_rows=13000000, name='Starting Pipeline')),\n",
    "    \n",
    "    ('delay_trend', DelayTrendEncoder(\n",
    "        date_col='dep_datetime',\n",
    "        origin_col='OriginAirportID',\n",
    "        dest_col='DestAirportID',\n",
    "        status_col='Flight_Status',\n",
    "        output_col='Delay_Trend',\n",
    "        top_n_airports=15\n",
    "    )),\n",
    "    \n",
    "    ('trend_logger', ProgressLogger(total_rows=13000000, name='Delay Trend Complete')),\n",
    "    \n",
    "    ('tail_reuse', SameDayTailReuseEncoder(\n",
    "        datetime_col='dep_datetime',\n",
    "        tail_col='Tail_Number',\n",
    "        output_col='Same_Day_Tail_Reuse'\n",
    "    )),\n",
    "    \n",
    "    ('reuse_logger', ProgressLogger(total_rows=13000000, name='Tail Reuse Complete')),\n",
    "    \n",
    "    ('turnaround_delay', TurnaroundDelayEncoder(\n",
    "        datetime_col='dep_datetime',\n",
    "        dep_time_col='CRSDepTime',\n",
    "        arr_time_col='CRSArrTime',\n",
    "        tail_col='Tail_Number',\n",
    "        output_prefix=''\n",
    "    )),\n",
    "    \n",
    "    ('turnaround_logger', ProgressLogger(total_rows=13000000, name='Turnaround Delay Complete')),\n",
    "    \n",
    "    ('slack_time', SlackTimeEncoder(\n",
    "        arr_col='CRSArrTime',\n",
    "        elapsed_col='CRSElapsedTime',\n",
    "        output_col='Slack_Time'\n",
    "    )),\n",
    "    \n",
    "    ('slack_logger', ProgressLogger(total_rows=13000000, name='Slack Time Complete')),\n",
    "    \n",
    "    ('feature_prep', ColumnTransformer([\n",
    "        ('numeric', numeric_transformer, numerical_features),\n",
    "        ('categorical', categorical_transformer, categorical_features),\n",
    "        ('drop', 'drop', drop_features)\n",
    "    ], remainder='passthrough', verbose_feature_names_out=False, n_jobs=16)),\n",
    "    \n",
    "    ('prep_logger', ProgressLogger(total_rows=13000000, name='Feature Prep Complete')),\n",
    "    ('select', PCA(\n",
    "        n_components=50,\n",
    "        random_state=42,\n",
    "    )),\n",
    "    ('final_logger', ProgressLogger(total_rows=13000000, name='Pipeline Complete'))\n",
    "])\n",
    "# so that I dont forget, dep_datetime is dropped because of redundancy\n",
    "\n",
    "preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pipeline processing started on 13,000,000 rows\n",
      "Starting Pipeline: 101.4% complete (13,184,010/13,000,000 rows) - Est. remaining: -0.0s\n",
      "Delay Trend Complete processing started on 13,000,000 rows\n",
      "Delay Trend Complete: 101.4% complete (13,184,010/13,000,000 rows) - Est. remaining: -0.0s\n",
      "Tail Reuse Complete processing started on 13,000,000 rows\n",
      "Tail Reuse Complete: 101.4% complete (13,184,010/13,000,000 rows) - Est. remaining: -0.0s\n",
      "Turnaround Delay Complete processing started on 13,000,000 rows\n",
      "Turnaround Delay Complete: 101.4% complete (13,184,010/13,000,000 rows) - Est. remaining: -0.0s\n",
      "Slack Time Complete processing started on 13,000,000 rows\n",
      "Slack Time Complete: 101.4% complete (13,184,010/13,000,000 rows) - Est. remaining: -0.0s\n",
      "Feature Prep Complete processing started on 13,000,000 rows\n",
      "Feature Prep Complete: 101.4% complete (13,184,010/13,000,000 rows) - Est. remaining: -0.0s\n",
      "Pipeline Complete processing started on 13,000,000 rows\n",
      "Pipeline Complete: 101.4% complete (13,184,010/13,000,000 rows) - Est. remaining: -0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pca0</th>\n",
       "      <th>pca1</th>\n",
       "      <th>pca2</th>\n",
       "      <th>pca3</th>\n",
       "      <th>pca4</th>\n",
       "      <th>pca5</th>\n",
       "      <th>pca6</th>\n",
       "      <th>pca7</th>\n",
       "      <th>pca8</th>\n",
       "      <th>pca9</th>\n",
       "      <th>pca10</th>\n",
       "      <th>pca11</th>\n",
       "      <th>pca12</th>\n",
       "      <th>pca13</th>\n",
       "      <th>pca14</th>\n",
       "      <th>pca15</th>\n",
       "      <th>pca16</th>\n",
       "      <th>pca17</th>\n",
       "      <th>pca18</th>\n",
       "      <th>pca19</th>\n",
       "      <th>pca20</th>\n",
       "      <th>pca21</th>\n",
       "      <th>pca22</th>\n",
       "      <th>pca23</th>\n",
       "      <th>pca24</th>\n",
       "      <th>pca25</th>\n",
       "      <th>pca26</th>\n",
       "      <th>pca27</th>\n",
       "      <th>pca28</th>\n",
       "      <th>pca29</th>\n",
       "      <th>pca30</th>\n",
       "      <th>pca31</th>\n",
       "      <th>pca32</th>\n",
       "      <th>pca33</th>\n",
       "      <th>pca34</th>\n",
       "      <th>pca35</th>\n",
       "      <th>pca36</th>\n",
       "      <th>pca37</th>\n",
       "      <th>pca38</th>\n",
       "      <th>pca39</th>\n",
       "      <th>pca40</th>\n",
       "      <th>pca41</th>\n",
       "      <th>pca42</th>\n",
       "      <th>pca43</th>\n",
       "      <th>pca44</th>\n",
       "      <th>pca45</th>\n",
       "      <th>pca46</th>\n",
       "      <th>pca47</th>\n",
       "      <th>pca48</th>\n",
       "      <th>pca49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>237129</th>\n",
       "      <td>-854.833838</td>\n",
       "      <td>-22.350535</td>\n",
       "      <td>-2.076370</td>\n",
       "      <td>-0.440297</td>\n",
       "      <td>0.167337</td>\n",
       "      <td>0.572813</td>\n",
       "      <td>-1.737709</td>\n",
       "      <td>-1.939359</td>\n",
       "      <td>0.598997</td>\n",
       "      <td>-0.055869</td>\n",
       "      <td>-0.137670</td>\n",
       "      <td>-0.548254</td>\n",
       "      <td>-0.542312</td>\n",
       "      <td>-0.298612</td>\n",
       "      <td>-2.088348</td>\n",
       "      <td>0.848928</td>\n",
       "      <td>-0.670065</td>\n",
       "      <td>0.047236</td>\n",
       "      <td>-0.212079</td>\n",
       "      <td>-0.128787</td>\n",
       "      <td>-0.051648</td>\n",
       "      <td>-0.342953</td>\n",
       "      <td>0.748292</td>\n",
       "      <td>-0.345412</td>\n",
       "      <td>0.041730</td>\n",
       "      <td>-0.132633</td>\n",
       "      <td>0.142040</td>\n",
       "      <td>0.022152</td>\n",
       "      <td>-0.059687</td>\n",
       "      <td>-0.016585</td>\n",
       "      <td>-0.066402</td>\n",
       "      <td>-0.026409</td>\n",
       "      <td>0.022660</td>\n",
       "      <td>-0.050261</td>\n",
       "      <td>0.101513</td>\n",
       "      <td>0.066042</td>\n",
       "      <td>-0.130050</td>\n",
       "      <td>-0.550974</td>\n",
       "      <td>-0.570871</td>\n",
       "      <td>-0.209702</td>\n",
       "      <td>-0.269762</td>\n",
       "      <td>-0.001562</td>\n",
       "      <td>0.144834</td>\n",
       "      <td>-0.300568</td>\n",
       "      <td>-0.045557</td>\n",
       "      <td>-0.039284</td>\n",
       "      <td>0.002726</td>\n",
       "      <td>-0.013357</td>\n",
       "      <td>-0.034872</td>\n",
       "      <td>0.008718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4084368</th>\n",
       "      <td>-854.834141</td>\n",
       "      <td>-22.338888</td>\n",
       "      <td>-1.070168</td>\n",
       "      <td>0.928008</td>\n",
       "      <td>0.109072</td>\n",
       "      <td>-0.652765</td>\n",
       "      <td>1.616179</td>\n",
       "      <td>0.338744</td>\n",
       "      <td>0.239957</td>\n",
       "      <td>-0.415272</td>\n",
       "      <td>-0.021180</td>\n",
       "      <td>-0.514327</td>\n",
       "      <td>1.026836</td>\n",
       "      <td>0.051468</td>\n",
       "      <td>-0.161360</td>\n",
       "      <td>-0.747006</td>\n",
       "      <td>0.014806</td>\n",
       "      <td>-0.861882</td>\n",
       "      <td>0.250880</td>\n",
       "      <td>-0.119239</td>\n",
       "      <td>-0.133633</td>\n",
       "      <td>-0.564447</td>\n",
       "      <td>-0.641994</td>\n",
       "      <td>-0.424654</td>\n",
       "      <td>0.075837</td>\n",
       "      <td>0.196848</td>\n",
       "      <td>0.176961</td>\n",
       "      <td>-0.352887</td>\n",
       "      <td>-0.314717</td>\n",
       "      <td>0.040957</td>\n",
       "      <td>-0.038851</td>\n",
       "      <td>0.017130</td>\n",
       "      <td>-0.036814</td>\n",
       "      <td>-0.053807</td>\n",
       "      <td>0.053965</td>\n",
       "      <td>0.037875</td>\n",
       "      <td>0.115357</td>\n",
       "      <td>-0.299556</td>\n",
       "      <td>0.404938</td>\n",
       "      <td>0.723895</td>\n",
       "      <td>-0.138716</td>\n",
       "      <td>0.011560</td>\n",
       "      <td>0.018870</td>\n",
       "      <td>-0.168647</td>\n",
       "      <td>-0.030812</td>\n",
       "      <td>0.037567</td>\n",
       "      <td>0.036142</td>\n",
       "      <td>-0.042263</td>\n",
       "      <td>-0.116985</td>\n",
       "      <td>-0.060923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029548</th>\n",
       "      <td>147.713096</td>\n",
       "      <td>-77.108846</td>\n",
       "      <td>-2.508873</td>\n",
       "      <td>-0.219041</td>\n",
       "      <td>0.183271</td>\n",
       "      <td>0.052362</td>\n",
       "      <td>-1.468815</td>\n",
       "      <td>-0.891923</td>\n",
       "      <td>0.671056</td>\n",
       "      <td>-0.296954</td>\n",
       "      <td>-0.029719</td>\n",
       "      <td>-1.096354</td>\n",
       "      <td>-0.770653</td>\n",
       "      <td>0.639488</td>\n",
       "      <td>-0.545767</td>\n",
       "      <td>-0.418539</td>\n",
       "      <td>-0.463200</td>\n",
       "      <td>0.530307</td>\n",
       "      <td>-0.035674</td>\n",
       "      <td>-0.098353</td>\n",
       "      <td>-0.162390</td>\n",
       "      <td>-0.570236</td>\n",
       "      <td>-0.655938</td>\n",
       "      <td>-0.407612</td>\n",
       "      <td>0.078903</td>\n",
       "      <td>0.174136</td>\n",
       "      <td>0.140763</td>\n",
       "      <td>-0.348507</td>\n",
       "      <td>-0.346499</td>\n",
       "      <td>0.049225</td>\n",
       "      <td>-0.071596</td>\n",
       "      <td>-0.003263</td>\n",
       "      <td>-0.006059</td>\n",
       "      <td>-0.044298</td>\n",
       "      <td>0.045863</td>\n",
       "      <td>0.068025</td>\n",
       "      <td>0.124905</td>\n",
       "      <td>-0.333909</td>\n",
       "      <td>0.390048</td>\n",
       "      <td>0.723567</td>\n",
       "      <td>-0.149370</td>\n",
       "      <td>-0.045389</td>\n",
       "      <td>0.032171</td>\n",
       "      <td>-0.168937</td>\n",
       "      <td>-0.031922</td>\n",
       "      <td>-0.040047</td>\n",
       "      <td>0.011496</td>\n",
       "      <td>-0.131700</td>\n",
       "      <td>-0.011625</td>\n",
       "      <td>-0.015509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11163145</th>\n",
       "      <td>-854.831051</td>\n",
       "      <td>-22.315751</td>\n",
       "      <td>0.932171</td>\n",
       "      <td>1.247213</td>\n",
       "      <td>0.264628</td>\n",
       "      <td>-0.378429</td>\n",
       "      <td>1.092836</td>\n",
       "      <td>0.747042</td>\n",
       "      <td>-0.019225</td>\n",
       "      <td>-0.376363</td>\n",
       "      <td>-0.005954</td>\n",
       "      <td>-0.375436</td>\n",
       "      <td>-0.156368</td>\n",
       "      <td>-0.354746</td>\n",
       "      <td>0.050448</td>\n",
       "      <td>-0.307444</td>\n",
       "      <td>-0.060815</td>\n",
       "      <td>-0.807921</td>\n",
       "      <td>0.260014</td>\n",
       "      <td>-0.296096</td>\n",
       "      <td>-0.442353</td>\n",
       "      <td>0.695594</td>\n",
       "      <td>-0.105101</td>\n",
       "      <td>-0.350372</td>\n",
       "      <td>0.069165</td>\n",
       "      <td>0.235374</td>\n",
       "      <td>0.162357</td>\n",
       "      <td>-0.368976</td>\n",
       "      <td>-0.373376</td>\n",
       "      <td>0.025128</td>\n",
       "      <td>-0.027154</td>\n",
       "      <td>-0.014787</td>\n",
       "      <td>-0.057837</td>\n",
       "      <td>-0.081301</td>\n",
       "      <td>0.079118</td>\n",
       "      <td>0.050852</td>\n",
       "      <td>0.108255</td>\n",
       "      <td>-0.309205</td>\n",
       "      <td>0.403263</td>\n",
       "      <td>0.745437</td>\n",
       "      <td>-0.141418</td>\n",
       "      <td>0.018153</td>\n",
       "      <td>0.017904</td>\n",
       "      <td>-0.187889</td>\n",
       "      <td>-0.014081</td>\n",
       "      <td>0.025421</td>\n",
       "      <td>0.022275</td>\n",
       "      <td>-0.030729</td>\n",
       "      <td>-0.126334</td>\n",
       "      <td>-0.055377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12079249</th>\n",
       "      <td>-119.476685</td>\n",
       "      <td>-38.252221</td>\n",
       "      <td>-0.403234</td>\n",
       "      <td>0.088713</td>\n",
       "      <td>0.273856</td>\n",
       "      <td>-0.885572</td>\n",
       "      <td>-0.906457</td>\n",
       "      <td>0.789604</td>\n",
       "      <td>0.586895</td>\n",
       "      <td>-0.564328</td>\n",
       "      <td>0.173975</td>\n",
       "      <td>-1.293512</td>\n",
       "      <td>-1.045807</td>\n",
       "      <td>0.493408</td>\n",
       "      <td>-0.800316</td>\n",
       "      <td>-0.377957</td>\n",
       "      <td>-0.731336</td>\n",
       "      <td>0.488200</td>\n",
       "      <td>-0.055334</td>\n",
       "      <td>-0.272335</td>\n",
       "      <td>-0.448231</td>\n",
       "      <td>0.696689</td>\n",
       "      <td>-0.107188</td>\n",
       "      <td>-0.339161</td>\n",
       "      <td>0.062435</td>\n",
       "      <td>0.195067</td>\n",
       "      <td>0.137958</td>\n",
       "      <td>-0.358201</td>\n",
       "      <td>-0.377980</td>\n",
       "      <td>0.034737</td>\n",
       "      <td>-0.053403</td>\n",
       "      <td>-0.025451</td>\n",
       "      <td>-0.045867</td>\n",
       "      <td>-0.086990</td>\n",
       "      <td>0.071079</td>\n",
       "      <td>0.072455</td>\n",
       "      <td>0.108627</td>\n",
       "      <td>-0.313937</td>\n",
       "      <td>0.391182</td>\n",
       "      <td>0.760339</td>\n",
       "      <td>-0.142154</td>\n",
       "      <td>-0.032643</td>\n",
       "      <td>0.032447</td>\n",
       "      <td>-0.195417</td>\n",
       "      <td>0.006769</td>\n",
       "      <td>-0.028557</td>\n",
       "      <td>0.003164</td>\n",
       "      <td>-0.126971</td>\n",
       "      <td>-0.017519</td>\n",
       "      <td>-0.006554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4840623</th>\n",
       "      <td>1446.920810</td>\n",
       "      <td>1804.960411</td>\n",
       "      <td>16.114719</td>\n",
       "      <td>2.422619</td>\n",
       "      <td>1.610649</td>\n",
       "      <td>-0.672875</td>\n",
       "      <td>0.969258</td>\n",
       "      <td>0.592852</td>\n",
       "      <td>0.183474</td>\n",
       "      <td>-0.746838</td>\n",
       "      <td>0.094900</td>\n",
       "      <td>-1.218365</td>\n",
       "      <td>0.083777</td>\n",
       "      <td>-0.472712</td>\n",
       "      <td>-0.095805</td>\n",
       "      <td>-1.852203</td>\n",
       "      <td>1.153189</td>\n",
       "      <td>0.728729</td>\n",
       "      <td>-0.041103</td>\n",
       "      <td>-0.053404</td>\n",
       "      <td>0.011857</td>\n",
       "      <td>-0.055555</td>\n",
       "      <td>0.029238</td>\n",
       "      <td>0.410233</td>\n",
       "      <td>-0.748385</td>\n",
       "      <td>0.465689</td>\n",
       "      <td>0.282304</td>\n",
       "      <td>-0.387809</td>\n",
       "      <td>-0.183253</td>\n",
       "      <td>-0.041832</td>\n",
       "      <td>-0.231200</td>\n",
       "      <td>0.201801</td>\n",
       "      <td>0.159446</td>\n",
       "      <td>-0.228248</td>\n",
       "      <td>-0.209145</td>\n",
       "      <td>0.538293</td>\n",
       "      <td>0.012855</td>\n",
       "      <td>0.290036</td>\n",
       "      <td>0.311480</td>\n",
       "      <td>-0.237649</td>\n",
       "      <td>-0.298210</td>\n",
       "      <td>-0.055947</td>\n",
       "      <td>-0.012867</td>\n",
       "      <td>-0.086320</td>\n",
       "      <td>-0.094366</td>\n",
       "      <td>0.080918</td>\n",
       "      <td>-0.002684</td>\n",
       "      <td>-0.034766</td>\n",
       "      <td>0.057815</td>\n",
       "      <td>0.020743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3552614</th>\n",
       "      <td>1481.735235</td>\n",
       "      <td>1815.057061</td>\n",
       "      <td>15.927770</td>\n",
       "      <td>1.738535</td>\n",
       "      <td>1.102894</td>\n",
       "      <td>-0.766987</td>\n",
       "      <td>-1.048087</td>\n",
       "      <td>-0.406609</td>\n",
       "      <td>0.001147</td>\n",
       "      <td>0.025129</td>\n",
       "      <td>-0.039639</td>\n",
       "      <td>0.033922</td>\n",
       "      <td>-1.720980</td>\n",
       "      <td>0.440557</td>\n",
       "      <td>-1.980516</td>\n",
       "      <td>-0.355618</td>\n",
       "      <td>-1.014928</td>\n",
       "      <td>0.132163</td>\n",
       "      <td>0.074193</td>\n",
       "      <td>-0.259497</td>\n",
       "      <td>0.047569</td>\n",
       "      <td>-0.056746</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.344437</td>\n",
       "      <td>-0.708481</td>\n",
       "      <td>0.774321</td>\n",
       "      <td>0.353554</td>\n",
       "      <td>-0.731177</td>\n",
       "      <td>-0.290823</td>\n",
       "      <td>-0.058627</td>\n",
       "      <td>-0.207307</td>\n",
       "      <td>0.196359</td>\n",
       "      <td>0.167049</td>\n",
       "      <td>-0.224005</td>\n",
       "      <td>-0.235772</td>\n",
       "      <td>0.591216</td>\n",
       "      <td>0.245028</td>\n",
       "      <td>0.328596</td>\n",
       "      <td>0.390303</td>\n",
       "      <td>-0.269474</td>\n",
       "      <td>-0.090319</td>\n",
       "      <td>-0.014113</td>\n",
       "      <td>-0.042403</td>\n",
       "      <td>-0.161968</td>\n",
       "      <td>0.010416</td>\n",
       "      <td>0.025028</td>\n",
       "      <td>-0.126482</td>\n",
       "      <td>0.003035</td>\n",
       "      <td>0.014830</td>\n",
       "      <td>0.113438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3919427</th>\n",
       "      <td>1548.791783</td>\n",
       "      <td>1824.509533</td>\n",
       "      <td>15.677436</td>\n",
       "      <td>1.876378</td>\n",
       "      <td>1.746183</td>\n",
       "      <td>-0.700656</td>\n",
       "      <td>-1.643239</td>\n",
       "      <td>-0.711924</td>\n",
       "      <td>0.211755</td>\n",
       "      <td>-0.202342</td>\n",
       "      <td>0.123060</td>\n",
       "      <td>-0.448522</td>\n",
       "      <td>-1.297856</td>\n",
       "      <td>0.692134</td>\n",
       "      <td>-1.638968</td>\n",
       "      <td>-0.015735</td>\n",
       "      <td>-1.040784</td>\n",
       "      <td>0.249929</td>\n",
       "      <td>-0.238392</td>\n",
       "      <td>0.003897</td>\n",
       "      <td>-0.026105</td>\n",
       "      <td>-0.040807</td>\n",
       "      <td>0.009947</td>\n",
       "      <td>0.485450</td>\n",
       "      <td>-0.788205</td>\n",
       "      <td>0.007574</td>\n",
       "      <td>0.209793</td>\n",
       "      <td>0.100577</td>\n",
       "      <td>0.097209</td>\n",
       "      <td>-0.039116</td>\n",
       "      <td>-0.231329</td>\n",
       "      <td>0.152183</td>\n",
       "      <td>0.178976</td>\n",
       "      <td>-0.158408</td>\n",
       "      <td>-0.167657</td>\n",
       "      <td>0.561432</td>\n",
       "      <td>-0.150555</td>\n",
       "      <td>0.334187</td>\n",
       "      <td>0.428725</td>\n",
       "      <td>-0.305908</td>\n",
       "      <td>-0.206265</td>\n",
       "      <td>-0.031733</td>\n",
       "      <td>0.096635</td>\n",
       "      <td>0.175397</td>\n",
       "      <td>0.029542</td>\n",
       "      <td>0.611845</td>\n",
       "      <td>0.371691</td>\n",
       "      <td>0.308198</td>\n",
       "      <td>-0.090158</td>\n",
       "      <td>0.175399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592306</th>\n",
       "      <td>1570.035200</td>\n",
       "      <td>1838.599017</td>\n",
       "      <td>15.483712</td>\n",
       "      <td>1.772993</td>\n",
       "      <td>1.485489</td>\n",
       "      <td>-0.392773</td>\n",
       "      <td>-1.326895</td>\n",
       "      <td>-0.203323</td>\n",
       "      <td>-0.108285</td>\n",
       "      <td>-0.113250</td>\n",
       "      <td>-0.141969</td>\n",
       "      <td>-0.310526</td>\n",
       "      <td>-3.409197</td>\n",
       "      <td>2.777021</td>\n",
       "      <td>1.569630</td>\n",
       "      <td>-0.193509</td>\n",
       "      <td>-0.997710</td>\n",
       "      <td>-0.807068</td>\n",
       "      <td>0.165139</td>\n",
       "      <td>-0.074919</td>\n",
       "      <td>-0.013840</td>\n",
       "      <td>-0.052491</td>\n",
       "      <td>0.027435</td>\n",
       "      <td>0.422841</td>\n",
       "      <td>-0.754428</td>\n",
       "      <td>0.257316</td>\n",
       "      <td>0.220303</td>\n",
       "      <td>-0.386106</td>\n",
       "      <td>-0.367061</td>\n",
       "      <td>-0.057872</td>\n",
       "      <td>-0.231652</td>\n",
       "      <td>0.158008</td>\n",
       "      <td>0.179158</td>\n",
       "      <td>-0.163109</td>\n",
       "      <td>-0.198327</td>\n",
       "      <td>0.584778</td>\n",
       "      <td>0.052776</td>\n",
       "      <td>0.258012</td>\n",
       "      <td>0.453432</td>\n",
       "      <td>-0.352048</td>\n",
       "      <td>-0.233304</td>\n",
       "      <td>0.053192</td>\n",
       "      <td>0.028380</td>\n",
       "      <td>-0.193773</td>\n",
       "      <td>-0.071399</td>\n",
       "      <td>-0.015947</td>\n",
       "      <td>-0.155446</td>\n",
       "      <td>0.019068</td>\n",
       "      <td>-0.020207</td>\n",
       "      <td>0.039576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231042</th>\n",
       "      <td>1581.139892</td>\n",
       "      <td>1810.713738</td>\n",
       "      <td>15.782918</td>\n",
       "      <td>1.799413</td>\n",
       "      <td>1.501623</td>\n",
       "      <td>-0.306342</td>\n",
       "      <td>-1.068746</td>\n",
       "      <td>-0.087166</td>\n",
       "      <td>-0.188167</td>\n",
       "      <td>-0.091997</td>\n",
       "      <td>-0.167388</td>\n",
       "      <td>-0.200664</td>\n",
       "      <td>-3.611013</td>\n",
       "      <td>2.961715</td>\n",
       "      <td>1.213690</td>\n",
       "      <td>-0.193170</td>\n",
       "      <td>-1.118065</td>\n",
       "      <td>-0.832767</td>\n",
       "      <td>0.152957</td>\n",
       "      <td>-0.083591</td>\n",
       "      <td>-0.007079</td>\n",
       "      <td>-0.052143</td>\n",
       "      <td>0.027114</td>\n",
       "      <td>0.426958</td>\n",
       "      <td>-0.757515</td>\n",
       "      <td>0.246776</td>\n",
       "      <td>0.220799</td>\n",
       "      <td>-0.372343</td>\n",
       "      <td>-0.347769</td>\n",
       "      <td>-0.056536</td>\n",
       "      <td>-0.230374</td>\n",
       "      <td>0.157972</td>\n",
       "      <td>0.183749</td>\n",
       "      <td>-0.165324</td>\n",
       "      <td>-0.198880</td>\n",
       "      <td>0.594721</td>\n",
       "      <td>0.051879</td>\n",
       "      <td>0.284724</td>\n",
       "      <td>0.460584</td>\n",
       "      <td>-0.344346</td>\n",
       "      <td>-0.248078</td>\n",
       "      <td>0.065642</td>\n",
       "      <td>0.065391</td>\n",
       "      <td>-0.276618</td>\n",
       "      <td>-0.051883</td>\n",
       "      <td>-0.011331</td>\n",
       "      <td>-0.127924</td>\n",
       "      <td>0.008292</td>\n",
       "      <td>-0.022350</td>\n",
       "      <td>0.075840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13184010 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 pca0         pca1       pca2      pca3      pca4      pca5  \\\n",
       "237129    -854.833838   -22.350535  -2.076370 -0.440297  0.167337  0.572813   \n",
       "4084368   -854.834141   -22.338888  -1.070168  0.928008  0.109072 -0.652765   \n",
       "1029548    147.713096   -77.108846  -2.508873 -0.219041  0.183271  0.052362   \n",
       "11163145  -854.831051   -22.315751   0.932171  1.247213  0.264628 -0.378429   \n",
       "12079249  -119.476685   -38.252221  -0.403234  0.088713  0.273856 -0.885572   \n",
       "...               ...          ...        ...       ...       ...       ...   \n",
       "4840623   1446.920810  1804.960411  16.114719  2.422619  1.610649 -0.672875   \n",
       "3552614   1481.735235  1815.057061  15.927770  1.738535  1.102894 -0.766987   \n",
       "3919427   1548.791783  1824.509533  15.677436  1.876378  1.746183 -0.700656   \n",
       "592306    1570.035200  1838.599017  15.483712  1.772993  1.485489 -0.392773   \n",
       "231042    1581.139892  1810.713738  15.782918  1.799413  1.501623 -0.306342   \n",
       "\n",
       "              pca6      pca7      pca8      pca9     pca10     pca11  \\\n",
       "237129   -1.737709 -1.939359  0.598997 -0.055869 -0.137670 -0.548254   \n",
       "4084368   1.616179  0.338744  0.239957 -0.415272 -0.021180 -0.514327   \n",
       "1029548  -1.468815 -0.891923  0.671056 -0.296954 -0.029719 -1.096354   \n",
       "11163145  1.092836  0.747042 -0.019225 -0.376363 -0.005954 -0.375436   \n",
       "12079249 -0.906457  0.789604  0.586895 -0.564328  0.173975 -1.293512   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "4840623   0.969258  0.592852  0.183474 -0.746838  0.094900 -1.218365   \n",
       "3552614  -1.048087 -0.406609  0.001147  0.025129 -0.039639  0.033922   \n",
       "3919427  -1.643239 -0.711924  0.211755 -0.202342  0.123060 -0.448522   \n",
       "592306   -1.326895 -0.203323 -0.108285 -0.113250 -0.141969 -0.310526   \n",
       "231042   -1.068746 -0.087166 -0.188167 -0.091997 -0.167388 -0.200664   \n",
       "\n",
       "             pca12     pca13     pca14     pca15     pca16     pca17  \\\n",
       "237129   -0.542312 -0.298612 -2.088348  0.848928 -0.670065  0.047236   \n",
       "4084368   1.026836  0.051468 -0.161360 -0.747006  0.014806 -0.861882   \n",
       "1029548  -0.770653  0.639488 -0.545767 -0.418539 -0.463200  0.530307   \n",
       "11163145 -0.156368 -0.354746  0.050448 -0.307444 -0.060815 -0.807921   \n",
       "12079249 -1.045807  0.493408 -0.800316 -0.377957 -0.731336  0.488200   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "4840623   0.083777 -0.472712 -0.095805 -1.852203  1.153189  0.728729   \n",
       "3552614  -1.720980  0.440557 -1.980516 -0.355618 -1.014928  0.132163   \n",
       "3919427  -1.297856  0.692134 -1.638968 -0.015735 -1.040784  0.249929   \n",
       "592306   -3.409197  2.777021  1.569630 -0.193509 -0.997710 -0.807068   \n",
       "231042   -3.611013  2.961715  1.213690 -0.193170 -1.118065 -0.832767   \n",
       "\n",
       "             pca18     pca19     pca20     pca21     pca22     pca23  \\\n",
       "237129   -0.212079 -0.128787 -0.051648 -0.342953  0.748292 -0.345412   \n",
       "4084368   0.250880 -0.119239 -0.133633 -0.564447 -0.641994 -0.424654   \n",
       "1029548  -0.035674 -0.098353 -0.162390 -0.570236 -0.655938 -0.407612   \n",
       "11163145  0.260014 -0.296096 -0.442353  0.695594 -0.105101 -0.350372   \n",
       "12079249 -0.055334 -0.272335 -0.448231  0.696689 -0.107188 -0.339161   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "4840623  -0.041103 -0.053404  0.011857 -0.055555  0.029238  0.410233   \n",
       "3552614   0.074193 -0.259497  0.047569 -0.056746  0.000133  0.344437   \n",
       "3919427  -0.238392  0.003897 -0.026105 -0.040807  0.009947  0.485450   \n",
       "592306    0.165139 -0.074919 -0.013840 -0.052491  0.027435  0.422841   \n",
       "231042    0.152957 -0.083591 -0.007079 -0.052143  0.027114  0.426958   \n",
       "\n",
       "             pca24     pca25     pca26     pca27     pca28     pca29  \\\n",
       "237129    0.041730 -0.132633  0.142040  0.022152 -0.059687 -0.016585   \n",
       "4084368   0.075837  0.196848  0.176961 -0.352887 -0.314717  0.040957   \n",
       "1029548   0.078903  0.174136  0.140763 -0.348507 -0.346499  0.049225   \n",
       "11163145  0.069165  0.235374  0.162357 -0.368976 -0.373376  0.025128   \n",
       "12079249  0.062435  0.195067  0.137958 -0.358201 -0.377980  0.034737   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "4840623  -0.748385  0.465689  0.282304 -0.387809 -0.183253 -0.041832   \n",
       "3552614  -0.708481  0.774321  0.353554 -0.731177 -0.290823 -0.058627   \n",
       "3919427  -0.788205  0.007574  0.209793  0.100577  0.097209 -0.039116   \n",
       "592306   -0.754428  0.257316  0.220303 -0.386106 -0.367061 -0.057872   \n",
       "231042   -0.757515  0.246776  0.220799 -0.372343 -0.347769 -0.056536   \n",
       "\n",
       "             pca30     pca31     pca32     pca33     pca34     pca35  \\\n",
       "237129   -0.066402 -0.026409  0.022660 -0.050261  0.101513  0.066042   \n",
       "4084368  -0.038851  0.017130 -0.036814 -0.053807  0.053965  0.037875   \n",
       "1029548  -0.071596 -0.003263 -0.006059 -0.044298  0.045863  0.068025   \n",
       "11163145 -0.027154 -0.014787 -0.057837 -0.081301  0.079118  0.050852   \n",
       "12079249 -0.053403 -0.025451 -0.045867 -0.086990  0.071079  0.072455   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "4840623  -0.231200  0.201801  0.159446 -0.228248 -0.209145  0.538293   \n",
       "3552614  -0.207307  0.196359  0.167049 -0.224005 -0.235772  0.591216   \n",
       "3919427  -0.231329  0.152183  0.178976 -0.158408 -0.167657  0.561432   \n",
       "592306   -0.231652  0.158008  0.179158 -0.163109 -0.198327  0.584778   \n",
       "231042   -0.230374  0.157972  0.183749 -0.165324 -0.198880  0.594721   \n",
       "\n",
       "             pca36     pca37     pca38     pca39     pca40     pca41  \\\n",
       "237129   -0.130050 -0.550974 -0.570871 -0.209702 -0.269762 -0.001562   \n",
       "4084368   0.115357 -0.299556  0.404938  0.723895 -0.138716  0.011560   \n",
       "1029548   0.124905 -0.333909  0.390048  0.723567 -0.149370 -0.045389   \n",
       "11163145  0.108255 -0.309205  0.403263  0.745437 -0.141418  0.018153   \n",
       "12079249  0.108627 -0.313937  0.391182  0.760339 -0.142154 -0.032643   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "4840623   0.012855  0.290036  0.311480 -0.237649 -0.298210 -0.055947   \n",
       "3552614   0.245028  0.328596  0.390303 -0.269474 -0.090319 -0.014113   \n",
       "3919427  -0.150555  0.334187  0.428725 -0.305908 -0.206265 -0.031733   \n",
       "592306    0.052776  0.258012  0.453432 -0.352048 -0.233304  0.053192   \n",
       "231042    0.051879  0.284724  0.460584 -0.344346 -0.248078  0.065642   \n",
       "\n",
       "             pca42     pca43     pca44     pca45     pca46     pca47  \\\n",
       "237129    0.144834 -0.300568 -0.045557 -0.039284  0.002726 -0.013357   \n",
       "4084368   0.018870 -0.168647 -0.030812  0.037567  0.036142 -0.042263   \n",
       "1029548   0.032171 -0.168937 -0.031922 -0.040047  0.011496 -0.131700   \n",
       "11163145  0.017904 -0.187889 -0.014081  0.025421  0.022275 -0.030729   \n",
       "12079249  0.032447 -0.195417  0.006769 -0.028557  0.003164 -0.126971   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "4840623  -0.012867 -0.086320 -0.094366  0.080918 -0.002684 -0.034766   \n",
       "3552614  -0.042403 -0.161968  0.010416  0.025028 -0.126482  0.003035   \n",
       "3919427   0.096635  0.175397  0.029542  0.611845  0.371691  0.308198   \n",
       "592306    0.028380 -0.193773 -0.071399 -0.015947 -0.155446  0.019068   \n",
       "231042    0.065391 -0.276618 -0.051883 -0.011331 -0.127924  0.008292   \n",
       "\n",
       "             pca48     pca49  \n",
       "237129   -0.034872  0.008718  \n",
       "4084368  -0.116985 -0.060923  \n",
       "1029548  -0.011625 -0.015509  \n",
       "11163145 -0.126334 -0.055377  \n",
       "12079249 -0.017519 -0.006554  \n",
       "...            ...       ...  \n",
       "4840623   0.057815  0.020743  \n",
       "3552614   0.014830  0.113438  \n",
       "3919427  -0.090158  0.175399  \n",
       "592306   -0.020207  0.039576  \n",
       "231042   -0.022350  0.075840  \n",
       "\n",
       "[13184010 rows x 50 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the pipeline in this cell and run it on X, this cell must end with the transformed data\n",
    "X = preprocessor.fit_transform(X_train, y_train)\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the preprocessor as a parquet file\n",
    "X.to_parquet(\"preprocessor.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pickle the preprocessor\n",
    "import pickle\n",
    "with open(\"preprocessor.pkl\", \"wb\") as f:\n",
    "    pickle.dump(preprocessor, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_logger <class '__main__.ProgressLogger'> 48\n",
      "delay_trend <class '__main__.DelayTrendEncoder'> 48\n",
      "trend_logger <class '__main__.ProgressLogger'> 48\n",
      "tail_reuse <class '__main__.SameDayTailReuseEncoder'> 48\n",
      "reuse_logger <class '__main__.ProgressLogger'> 48\n",
      "turnaround_delay <class '__main__.TurnaroundDelayEncoder'> 48\n",
      "turnaround_logger <class '__main__.ProgressLogger'> 48\n",
      "slack_time <class '__main__.SlackTimeEncoder'> 48\n",
      "slack_logger <class '__main__.ProgressLogger'> 48\n",
      "feature_prep <class 'sklearn.compose._column_transformer.ColumnTransformer'> 48\n",
      "prep_logger <class '__main__.ProgressLogger'> 48\n",
      "select <class 'sklearn.feature_selection._from_model.SelectFromModel'> 48\n",
      "final_logger <class '__main__.ProgressLogger'> 48\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "for name, step in preprocessor.named_steps.items():\n",
    "    print(name, type(step), sys.getsizeof(step))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, precision_score, recall_score, precision_recall_curve\n",
    "def precision_at_recall(y, y_pred, *, recall, **kwargs):\n",
    "    \"\"\"\n",
    "    Calculate the precision at a given recall level.\n",
    "\n",
    "    To use this with cross_val_score, you need to use the make_scorer function to\n",
    "    create a scoring function that can be used with cross_val_score. For example:\n",
    "\n",
    "        scorer = make_scorer(precision_at_recall, recall=0.9)  # 0.9 is the minimum recall level\n",
    "        cross_val_score(model, X, y, cv=5, scoring=scorer)\n",
    "\n",
    "    The default will only work for binary classification problems. You must change the\n",
    "    average parameter if you want to use for multiclass classification. For example:\n",
    "\n",
    "        scorer = make_scorer(precision_at_recall, recall=0.9, average=\"micro\")\n",
    "    \"\"\"\n",
    "    return precision_score(y, y_pred, **kwargs) if recall_score(y, y_pred, **kwargs) > recall else 0.0\n",
    "\n",
    "def recall_at_precision(y, y_pred, *, precision, **kwargs):\n",
    "    \"\"\"\n",
    "    Calculate the recall at a given precision level.\n",
    "\n",
    "    To use this with cross_val_score, you need to use the make_scorer function to\n",
    "    create a scoring function that can be used with cross_val_score. For example:\n",
    "\n",
    "        scorer = make_scorer(recall_at_precision, precision=0.9)\n",
    "        cross_val_score(model, X, y, cv=5, scoring=scorer)\n",
    "\n",
    "    The default will only work for binary classification problems. You must change the\n",
    "    average parameter if you want to use for multiclass classification. For example:\n",
    "\n",
    "        scorer = make_scorer(recall_at_precision, precision=0.9, average=\"micro\")\n",
    "    \"\"\"\n",
    "    return recall_score(y, y_pred, **kwargs) if precision_score(y, y_pred, **kwargs) > precision else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_sample = X.sample(n=100000, random_state=42)\n",
    "y_train = y_train.sample(n=100000, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=64)]: Using backend LokyBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done   5 out of   5 | elapsed:   19.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.0520\n",
      "Precision: 0.0549\n",
      "F1 Score: 0.0131\n",
      "Cross-Validation Classification Report:\n",
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "            Carrier Cancellation       0.00      0.14      0.01       424\n",
      "      Major Delay - CarrierDelay       0.01      0.11      0.01       514\n",
      " Major Delay - LateAircraftDelay       0.01      0.12      0.01       649\n",
      "          Major Delay - NASDelay       0.00      0.01      0.00        91\n",
      "      Major Delay - WeatherDelay       0.00      0.06      0.00        96\n",
      "     Medium Delay - CarrierDelay       0.02      0.06      0.03      1881\n",
      "Medium Delay - LateAircraftDelay       0.03      0.02      0.03      2886\n",
      "         Medium Delay - NASDelay       0.00      0.11      0.01       487\n",
      "     Medium Delay - WeatherDelay       0.00      0.05      0.01       325\n",
      "      Minor Delay - CarrierDelay       0.03      0.03      0.03      3539\n",
      " Minor Delay - LateAircraftDelay       0.04      0.02      0.02      4238\n",
      "          Minor Delay - NASDelay       0.01      0.03      0.01      1060\n",
      "      Minor Delay - WeatherDelay       0.00      0.06      0.01       326\n",
      "                NAS Cancellation       0.00      0.07      0.00       205\n",
      "                         On-Time       0.78      0.01      0.02     78470\n",
      "                  Security Issue       0.00      0.00      0.00        51\n",
      "                         Unknown       0.04      0.02      0.03      3977\n",
      "            Weather Cancellation       0.01      0.03      0.01       781\n",
      "\n",
      "                        accuracy                           0.01    100000\n",
      "                       macro avg       0.05      0.05      0.01    100000\n",
      "                    weighted avg       0.62      0.01      0.02    100000\n",
      "\n",
      "Mean precision at recall 0.2: 0.0000 ± 0.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import classification_report, recall_score, precision_score, f1_score\n",
    "\n",
    "dt = DecisionTreeClassifier(\n",
    "    random_state=42,\n",
    "    max_depth=20,\n",
    "    min_samples_leaf=10,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "scorer = make_scorer(precision_at_recall, recall=0.2, average='weighted')\n",
    "\n",
    "scores = cross_val_score(dt, X_sample, y_train, cv=5, scoring=scorer, verbose=1, n_jobs=64)\n",
    "\n",
    "# Fit the model and predict using cross-validation\n",
    "y_pred_cv = cross_val_predict(dt, X_sample, y_train, cv=5, n_jobs=64)\n",
    "\n",
    "# Calculate recall, precision, and F1 score\n",
    "recall = recall_score(y_train, y_pred_cv, average='macro')\n",
    "precision = precision_score(y_train, y_pred_cv, average='macro', zero_division=0)\n",
    "f1 = f1_score(y_train, y_pred_cv, average='macro')\n",
    "\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Cross-validated performance\n",
    "print(\"Cross-Validation Classification Report:\")\n",
    "print(classification_report(y_train, y_pred_cv, zero_division=0))\n",
    "\n",
    "print(f\"Mean precision at recall 0.2: {scores.mean():.4f} ± {scores.std():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Flight_Status\n",
       "On-Time                             78470\n",
       "Minor Delay - LateAircraftDelay      4238\n",
       "Unknown                              3977\n",
       "Minor Delay - CarrierDelay           3539\n",
       "Medium Delay - LateAircraftDelay     2886\n",
       "Medium Delay - CarrierDelay          1881\n",
       "Minor Delay - NASDelay               1060\n",
       "Weather Cancellation                  781\n",
       "Major Delay - LateAircraftDelay       649\n",
       "Major Delay - CarrierDelay            514\n",
       "Medium Delay - NASDelay               487\n",
       "Carrier Cancellation                  424\n",
       "Minor Delay - WeatherDelay            326\n",
       "Medium Delay - WeatherDelay           325\n",
       "NAS Cancellation                      205\n",
       "Major Delay - WeatherDelay             96\n",
       "Major Delay - NASDelay                 91\n",
       "Security Issue                         51\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=64)]: Using backend LokyBackend with 64 concurrent workers.\n",
      "/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[Parallel(n_jobs=64)]: Done   5 out of   5 | elapsed:  6.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.0556\n",
      "Precision: 0.0482\n",
      "F1 Score: 0.0494\n",
      "Cross-Validation Classification Report:\n",
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "            Carrier Cancellation       0.03      0.00      0.00       424\n",
      "      Major Delay - CarrierDelay       0.02      0.00      0.00       514\n",
      " Major Delay - LateAircraftDelay       0.00      0.00      0.00       649\n",
      "          Major Delay - NASDelay       0.00      0.00      0.00        91\n",
      "      Major Delay - WeatherDelay       0.00      0.00      0.00        96\n",
      "     Medium Delay - CarrierDelay       0.00      0.00      0.00      1881\n",
      "Medium Delay - LateAircraftDelay       0.00      0.00      0.00      2886\n",
      "         Medium Delay - NASDelay       0.03      0.00      0.00       487\n",
      "     Medium Delay - WeatherDelay       0.00      0.00      0.00       325\n",
      "      Minor Delay - CarrierDelay       0.00      0.00      0.00      3539\n",
      " Minor Delay - LateAircraftDelay       0.00      0.00      0.00      4238\n",
      "          Minor Delay - NASDelay       0.00      0.00      0.00      1060\n",
      "      Minor Delay - WeatherDelay       0.00      0.00      0.00       326\n",
      "                NAS Cancellation       0.00      0.00      0.00       205\n",
      "                         On-Time       0.78      0.99      0.88     78470\n",
      "                  Security Issue       0.00      0.00      0.00        51\n",
      "                         Unknown       0.00      0.00      0.00      3977\n",
      "            Weather Cancellation       0.00      0.00      0.00       781\n",
      "\n",
      "                        accuracy                           0.78    100000\n",
      "                       macro avg       0.05      0.06      0.05    100000\n",
      "                    weighted avg       0.62      0.78      0.69    100000\n",
      "\n",
      "Mean precision at recall 0.2: 0.6161 ± 0.0006\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "\n",
    "# Create Gradient Boosting classifier\n",
    "model = GradientBoostingClassifier(\n",
    "    n_estimators=20,    \n",
    "    max_depth=3,        \n",
    "    learning_rate=0.1,  \n",
    "    subsample=0.6,       \n",
    "    random_state=42,\n",
    "    verbose=2            \n",
    ")\n",
    "\n",
    "# Create scorer for precision at recall\n",
    "scorer = make_scorer(precision_at_recall, recall=0.2, average='weighted')\n",
    "\n",
    "# Run cross-validation with the Gradient Boosting model\n",
    "scores = cross_val_score(model, X_sample, y_train, cv=5, scoring=scorer, verbose=1, n_jobs=64)\n",
    "\n",
    "# Fit the model and predict using cross-validation\n",
    "y_pred_cv = cross_val_predict(model, X_sample, y_train, cv=5, n_jobs=64)\n",
    "\n",
    "# Calculate metrics\n",
    "recall = recall_score(y_train, y_pred_cv, average='macro')\n",
    "precision = precision_score(y_train, y_pred_cv, average='macro', zero_division=0)\n",
    "f1 = f1_score(y_train, y_pred_cv, average='macro')\n",
    "\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Print classification report\n",
    "print(\"Cross-Validation Classification Report:\")\n",
    "print(classification_report(y_train, y_pred_cv, zero_division=0))\n",
    "print(f\"Mean precision at recall 0.2: {scores.mean():.4f} ± {scores.std():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=64)]: Using backend LokyBackend with 64 concurrent workers.\n",
      "/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[Parallel(n_jobs=64)]: Done   5 out of   5 | elapsed:   29.8s finished\n",
      "/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.0555\n",
      "Precision: 0.0436\n",
      "F1 Score: 0.0488\n",
      "Cross-Validation Classification Report:\n",
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "            Carrier Cancellation       0.00      0.00      0.00       424\n",
      "      Major Delay - CarrierDelay       0.00      0.00      0.00       514\n",
      " Major Delay - LateAircraftDelay       0.00      0.00      0.00       649\n",
      "          Major Delay - NASDelay       0.00      0.00      0.00        91\n",
      "      Major Delay - WeatherDelay       0.00      0.00      0.00        96\n",
      "     Medium Delay - CarrierDelay       0.00      0.00      0.00      1881\n",
      "Medium Delay - LateAircraftDelay       0.00      0.00      0.00      2886\n",
      "         Medium Delay - NASDelay       0.00      0.00      0.00       487\n",
      "     Medium Delay - WeatherDelay       0.00      0.00      0.00       325\n",
      "      Minor Delay - CarrierDelay       0.00      0.00      0.00      3539\n",
      " Minor Delay - LateAircraftDelay       0.00      0.00      0.00      4238\n",
      "          Minor Delay - NASDelay       0.00      0.00      0.00      1060\n",
      "      Minor Delay - WeatherDelay       0.00      0.00      0.00       326\n",
      "                NAS Cancellation       0.00      0.00      0.00       205\n",
      "                         On-Time       0.78      1.00      0.88     78470\n",
      "                  Security Issue       0.00      0.00      0.00        51\n",
      "                         Unknown       0.00      0.00      0.00      3977\n",
      "            Weather Cancellation       0.00      0.00      0.00       781\n",
      "\n",
      "                        accuracy                           0.78    100000\n",
      "                       macro avg       0.04      0.06      0.05    100000\n",
      "                    weighted avg       0.62      0.78      0.69    100000\n",
      "\n",
      "Mean precision at recall 0.2: 0.6158 ± 0.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# Basic SGD classifier for multi-class classification\n",
    "sgd_classifier = SGDClassifier(\n",
    "    loss='log_loss',     \n",
    "    alpha=0.0001,   \n",
    "    n_jobs=64,\n",
    "    random_state=42       \n",
    ")\n",
    "\n",
    "# Create scorer for precision at recall\n",
    "scorer = make_scorer(precision_at_recall, recall=0.2, average='weighted')\n",
    "\n",
    "# Run cross-validation with the Gradient Boosting model\n",
    "scores = cross_val_score(sgd_classifier, X_sample, y_train, cv=5, scoring=scorer, verbose=1, n_jobs=64)\n",
    "\n",
    "# Fit the model and predict using cross-validation\n",
    "y_pred_cv = cross_val_predict(sgd_classifier, X_sample, y_train, cv=5, n_jobs=64)\n",
    "\n",
    "# Calculate metrics\n",
    "recall = recall_score(y_train, y_pred_cv, average='macro')\n",
    "precision = precision_score(y_train, y_pred_cv, average='macro', zero_division=0)\n",
    "f1 = f1_score(y_train, y_pred_cv, average='macro')\n",
    "\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Print classification report\n",
    "print(\"Cross-Validation Classification Report:\")\n",
    "print(classification_report(y_train, y_pred_cv, zero_division=0))\n",
    "print(f\"Mean precision at recall 0.2: {scores.mean():.4f} ± {scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=64)]: Using backend LokyBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          918     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31230D+05    |proj g|=  4.52906D+05\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          918     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31230D+05    |proj g|=  5.08173D+05\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          918     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31230D+05    |proj g|=  5.06678D+05\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          918     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31230D+05    |proj g|=  6.82702D+05\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          918     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31230D+05    |proj g|=  4.50830D+05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   50    f=  2.30413D+05    |proj g|=  1.83678D+04\n",
      "\n",
      "At iterate   50    f=  2.30460D+05    |proj g|=  7.64161D+03\n",
      "\n",
      "At iterate   50    f=  2.30432D+05    |proj g|=  2.04515D+04\n",
      "\n",
      "At iterate   50    f=  2.30363D+05    |proj g|=  3.13326D+04\n",
      "\n",
      "At iterate   50    f=  2.30345D+05    |proj g|=  1.77993D+05\n",
      "\n",
      "At iterate  100    f=  2.29901D+05    |proj g|=  6.31362D+04\n",
      "\n",
      "At iterate  100    f=  2.29820D+05    |proj g|=  1.75573D+04\n",
      "\n",
      "At iterate  100    f=  2.30006D+05    |proj g|=  7.56836D+04\n",
      "\n",
      "At iterate  100    f=  2.29745D+05    |proj g|=  3.66572D+04\n",
      "\n",
      "At iterate  100    f=  2.29718D+05    |proj g|=  9.28460D+04\n",
      "\n",
      "At iterate  150    f=  2.28940D+05    |proj g|=  2.57050D+04\n",
      "\n",
      "At iterate  150    f=  2.29335D+05    |proj g|=  4.78086D+04\n",
      "\n",
      "At iterate  150    f=  2.29303D+05    |proj g|=  1.39796D+04\n",
      "\n",
      "At iterate  150    f=  2.29740D+05    |proj g|=  2.78229D+04\n",
      "\n",
      "At iterate  150    f=  2.29359D+05    |proj g|=  1.66245D+04\n",
      "\n",
      "At iterate  200    f=  2.28725D+05    |proj g|=  8.22377D+04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  918    200    211      1     0     0   8.224D+04   2.287D+05\n",
      "  F =   228724.81232402046     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n",
      "\n",
      "At iterate  200    f=  2.28655D+05    |proj g|=  1.18179D+04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  918    200    210      1     0     0   1.182D+04   2.287D+05\n",
      "  F =   228655.09423526545     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=64)]: Done   1 out of   1 | elapsed:   10.8s finished\n",
      "/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=64)]: Done   1 out of   1 | elapsed:   10.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate  200    f=  2.28091D+05    |proj g|=  5.04936D+04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  918    200    214      1     0     0   5.049D+04   2.281D+05\n",
      "  F =   228091.21236615849     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n",
      "\n",
      "At iterate  200    f=  2.29113D+05    |proj g|=  3.50903D+04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  918    200    213      1     0     0   3.509D+04   2.291D+05\n",
      "  F =   229113.05220798624     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=64)]: Done   1 out of   1 | elapsed:   11.1s finished\n",
      "[Parallel(n_jobs=64)]: Done   1 out of   1 | elapsed:   11.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate  200    f=  2.28640D+05    |proj g|=  1.39139D+04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  918    200    217      1     0     0   1.391D+04   2.286D+05\n",
      "  F =   228639.94628400612     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=64)]: Done   1 out of   1 | elapsed:   11.3s finished\n",
      "[Parallel(n_jobs=64)]: Done   5 out of   5 | elapsed:   12.8s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          918     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31230D+05    |proj g|=  5.08173D+05\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          918     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31230D+05    |proj g|=  5.06678D+05\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          918     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31230D+05    |proj g|=  4.50830D+05\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          918     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31230D+05    |proj g|=  4.52906D+05\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          918     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31230D+05    |proj g|=  6.82702D+05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   50    f=  2.30345D+05    |proj g|=  1.77993D+05\n",
      "\n",
      "At iterate   50    f=  2.30432D+05    |proj g|=  2.04515D+04\n",
      "\n",
      "At iterate   50    f=  2.30460D+05    |proj g|=  7.64161D+03\n",
      "\n",
      "At iterate   50    f=  2.30413D+05    |proj g|=  1.83678D+04\n",
      "\n",
      "At iterate   50    f=  2.30363D+05    |proj g|=  3.13326D+04\n",
      "\n",
      "At iterate  100    f=  2.29718D+05    |proj g|=  9.28460D+04\n",
      "\n",
      "At iterate  100    f=  2.29820D+05    |proj g|=  1.75573D+04\n",
      "\n",
      "At iterate  100    f=  2.30006D+05    |proj g|=  7.56836D+04\n",
      "\n",
      "At iterate  100    f=  2.29901D+05    |proj g|=  6.31362D+04\n",
      "\n",
      "At iterate  100    f=  2.29745D+05    |proj g|=  3.66572D+04\n",
      "\n",
      "At iterate  150    f=  2.29303D+05    |proj g|=  1.39796D+04\n",
      "\n",
      "At iterate  150    f=  2.29359D+05    |proj g|=  1.66245D+04\n",
      "\n",
      "At iterate  150    f=  2.29740D+05    |proj g|=  2.78229D+04\n",
      "\n",
      "At iterate  150    f=  2.29335D+05    |proj g|=  4.78086D+04\n",
      "\n",
      "At iterate  150    f=  2.28940D+05    |proj g|=  2.57050D+04\n",
      "\n",
      "At iterate  200    f=  2.28655D+05    |proj g|=  1.18179D+04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  918    200    210      1     0     0   1.182D+04   2.287D+05\n",
      "  F =   228655.09423526545     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=64)]: Done   1 out of   1 | elapsed:   10.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate  200    f=  2.29113D+05    |proj g|=  3.50903D+04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  918    200    213      1     0     0   3.509D+04   2.291D+05\n",
      "  F =   229113.05220798624     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n",
      "\n",
      "At iterate  200    f=  2.28640D+05    |proj g|=  1.39139D+04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  918    200    217      1     0     0   1.391D+04   2.286D+05\n",
      "  F =   228639.94628400612     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=64)]: Done   1 out of   1 | elapsed:   11.7s finished\n",
      "/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=64)]: Done   1 out of   1 | elapsed:   11.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate  200    f=  2.28725D+05    |proj g|=  8.22377D+04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  918    200    211      1     0     0   8.224D+04   2.287D+05\n",
      "  F =   228724.81232402046     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=64)]: Done   1 out of   1 | elapsed:   12.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate  200    f=  2.28091D+05    |proj g|=  5.04936D+04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  918    200    214      1     0     0   5.049D+04   2.281D+05\n",
      "  F =   228091.21236615849     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=64)]: Done   1 out of   1 | elapsed:   12.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.0682\n",
      "Precision: 0.0681\n",
      "F1 Score: 0.0058\n",
      "Cross-Validation Classification Report:\n",
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "            Carrier Cancellation       0.00      0.04      0.01       424\n",
      "      Major Delay - CarrierDelay       0.01      0.07      0.01       514\n",
      " Major Delay - LateAircraftDelay       0.00      0.00      0.00       649\n",
      "          Major Delay - NASDelay       0.00      0.10      0.00        91\n",
      "      Major Delay - WeatherDelay       0.00      0.27      0.00        96\n",
      "     Medium Delay - CarrierDelay       0.04      0.00      0.01      1881\n",
      "Medium Delay - LateAircraftDelay       0.04      0.01      0.01      2886\n",
      "         Medium Delay - NASDelay       0.00      0.05      0.01       487\n",
      "     Medium Delay - WeatherDelay       0.00      0.05      0.01       325\n",
      "      Minor Delay - CarrierDelay       0.03      0.00      0.00      3539\n",
      " Minor Delay - LateAircraftDelay       0.04      0.00      0.00      4238\n",
      "          Minor Delay - NASDelay       0.02      0.02      0.02      1060\n",
      "      Minor Delay - WeatherDelay       0.00      0.02      0.01       326\n",
      "                NAS Cancellation       0.00      0.10      0.00       205\n",
      "                         On-Time       1.00      0.00      0.00     78470\n",
      "                  Security Issue       0.00      0.45      0.00        51\n",
      "                         Unknown       0.02      0.00      0.00      3977\n",
      "            Weather Cancellation       0.01      0.03      0.01       781\n",
      "\n",
      "                        accuracy                           0.00    100000\n",
      "                       macro avg       0.07      0.07      0.01    100000\n",
      "                    weighted avg       0.79      0.00      0.00    100000\n",
      "\n",
      "Mean precision at recall 0.2: 0.0000 ± 0.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Fast but effective logistic regression configuration\n",
    "log_reg = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    C=1.0,                 \n",
    "    max_iter=200,        \n",
    "    tol=1e-3,           \n",
    "    class_weight='balanced', \n",
    "    n_jobs=64,          \n",
    "    random_state=42,     \n",
    "    verbose=1            \n",
    ")\n",
    "\n",
    "# Run cross-validation with the Gradient Boosting model\n",
    "scores = cross_val_score(log_reg, X_sample, y_train, cv=5, scoring=scorer, verbose=1, n_jobs=64)\n",
    "\n",
    "# Fit the model and predict using cross-validation\n",
    "y_pred_cv = cross_val_predict(log_reg, X_sample, y_train, cv=5, n_jobs=64)\n",
    "\n",
    "# Calculate metrics\n",
    "recall = recall_score(y_train, y_pred_cv, average='macro')\n",
    "precision = precision_score(y_train, y_pred_cv, average='macro', zero_division=0)\n",
    "f1 = f1_score(y_train, y_pred_cv, average='macro')\n",
    "\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Print classification report\n",
    "print(\"Cross-Validation Classification Report:\")\n",
    "print(classification_report(y_train, y_pred_cv, zero_division=0))\n",
    "print(f\"Mean precision at recall 0.2: {scores.mean():.4f} ± {scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_MissingValues' from 'sklearn.utils._param_validation' (/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/utils/_param_validation.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01munder_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomUnderSampler\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report, precision_score, recall_score, f1_score, make_scorer\n",
      "File \u001b[0;32m/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/imblearn/__init__.py:52\u001b[0m\n\u001b[1;32m     48\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPartial import of imblearn during the build process.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     53\u001b[0m         combine,\n\u001b[1;32m     54\u001b[0m         ensemble,\n\u001b[1;32m     55\u001b[0m         exceptions,\n\u001b[1;32m     56\u001b[0m         metrics,\n\u001b[1;32m     57\u001b[0m         over_sampling,\n\u001b[1;32m     58\u001b[0m         pipeline,\n\u001b[1;32m     59\u001b[0m         tensorflow,\n\u001b[1;32m     60\u001b[0m         under_sampling,\n\u001b[1;32m     61\u001b[0m         utils,\n\u001b[1;32m     62\u001b[0m     )\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_version\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FunctionSampler\n",
      "File \u001b[0;32m/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/imblearn/combine/__init__.py:5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"The :mod:`imblearn.combine` provides methods which combine\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mover-sampling and under-sampling.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote_enn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTEENN\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote_tomek\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTETomek\n\u001b[1;32m      8\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTEENN\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTETomek\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/imblearn/combine/_smote_enn.py:12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_X_y\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseSampler\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseOverSampler\n",
      "File \u001b[0;32m/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/imblearn/base.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmulticlass\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_classification_targets\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_sampling_strategy, check_target_type\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_parameter_constraints\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ArraysTransformer\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mSamplerMixin\u001b[39;00m(BaseEstimator, metaclass\u001b[38;5;241m=\u001b[39mABCMeta):\n",
      "File \u001b[0;32m/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/imblearn/utils/_param_validation.py:908\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generate_valid_param  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m    907\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_parameter_constraints  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m--> 908\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    909\u001b[0m     HasMethods,\n\u001b[1;32m    910\u001b[0m     Hidden,\n\u001b[1;32m    911\u001b[0m     Interval,\n\u001b[1;32m    912\u001b[0m     Options,\n\u001b[1;32m    913\u001b[0m     StrOptions,\n\u001b[1;32m    914\u001b[0m     _ArrayLikes,\n\u001b[1;32m    915\u001b[0m     _Booleans,\n\u001b[1;32m    916\u001b[0m     _Callables,\n\u001b[1;32m    917\u001b[0m     _CVObjects,\n\u001b[1;32m    918\u001b[0m     _InstancesOf,\n\u001b[1;32m    919\u001b[0m     _IterablesNotString,\n\u001b[1;32m    920\u001b[0m     _MissingValues,\n\u001b[1;32m    921\u001b[0m     _NoneConstraint,\n\u001b[1;32m    922\u001b[0m     _PandasNAConstraint,\n\u001b[1;32m    923\u001b[0m     _RandomStates,\n\u001b[1;32m    924\u001b[0m     _SparseMatrices,\n\u001b[1;32m    925\u001b[0m     _VerboseHelper,\n\u001b[1;32m    926\u001b[0m     make_constraint,\n\u001b[1;32m    927\u001b[0m     validate_params,\n\u001b[1;32m    928\u001b[0m )\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name '_MissingValues' from 'sklearn.utils._param_validation' (/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/utils/_param_validation.py)"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, precision_score\n",
    "\n",
    "# Create the MLP classifier with precision-focused parameters\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(100),\n",
    "    max_iter=100,              \n",
    "    early_stopping=True,\n",
    "    random_state=42            \n",
    ")\n",
    "\n",
    "# Create scorer for precision at recall\n",
    "scorer = make_scorer(precision_at_recall, recall=0.2, average='weighted')\n",
    "\n",
    "# Run cross-validation with the Gradient Boosting model\n",
    "scores = cross_val_score(mlp, X_sample, y_train, cv=5, scoring=scorer, verbose=1, n_jobs=64)\n",
    "\n",
    "# Fit the model and predict using cross-validation\n",
    "y_pred_cv = cross_val_predict(mlp, X_sample, y_train, cv=5, n_jobs=64)\n",
    "\n",
    "# Calculate metrics\n",
    "recall = recall_score(y_train, y_pred_cv, average='macro')\n",
    "precision = precision_score(y_train, y_pred_cv, average='macro', zero_division=0)\n",
    "f1 = f1_score(y_train, y_pred_cv, average='macro')\n",
    "\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Print classification report\n",
    "print(\"Cross-Validation Classification Report:\")\n",
    "print(classification_report(y_train, y_pred_cv, zero_division=0))\n",
    "print(f\"Mean precision at recall 0.2: {scores.mean():.4f} ± {scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=64)]: Using backend LokyBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    7.6s remaining:    2.7s\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    7.6s remaining:    2.7s\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    7.7s remaining:    2.7s\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    7.9s remaining:    2.8s\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    8.1s remaining:    2.8s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    8.4s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    8.5s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    8.6s finished\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    8.6s finished\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    8.6s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=64)]: Done   5 out of   5 | elapsed:   10.6s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    7.1s remaining:    2.5s\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    7.5s remaining:    2.6s\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    7.5s remaining:    2.6s\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    7.6s remaining:    2.7s\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    7.8s remaining:    2.8s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    8.1s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    8.2s finished\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    8.3s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    8.3s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    8.5s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.0564\n",
      "Precision: 0.0559\n",
      "F1 Score: 0.0523\n",
      "Cross-Validation Classification Report:\n",
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "            Carrier Cancellation       0.00      0.01      0.01       424\n",
      "      Major Delay - CarrierDelay       0.01      0.01      0.01       514\n",
      " Major Delay - LateAircraftDelay       0.01      0.02      0.01       649\n",
      "          Major Delay - NASDelay       0.00      0.00      0.00        91\n",
      "      Major Delay - WeatherDelay       0.00      0.00      0.00        96\n",
      "     Medium Delay - CarrierDelay       0.02      0.04      0.03      1881\n",
      "Medium Delay - LateAircraftDelay       0.03      0.06      0.04      2886\n",
      "         Medium Delay - NASDelay       0.01      0.02      0.01       487\n",
      "     Medium Delay - WeatherDelay       0.00      0.01      0.01       325\n",
      "      Minor Delay - CarrierDelay       0.04      0.07      0.05      3539\n",
      " Minor Delay - LateAircraftDelay       0.04      0.08      0.05      4238\n",
      "          Minor Delay - NASDelay       0.01      0.03      0.02      1060\n",
      "      Minor Delay - WeatherDelay       0.01      0.02      0.01       326\n",
      "                NAS Cancellation       0.00      0.00      0.00       205\n",
      "                         On-Time       0.79      0.54      0.64     78470\n",
      "                  Security Issue       0.00      0.00      0.00        51\n",
      "                         Unknown       0.04      0.08      0.05      3977\n",
      "            Weather Cancellation       0.01      0.01      0.01       781\n",
      "\n",
      "                        accuracy                           0.44    100000\n",
      "                       macro avg       0.06      0.06      0.05    100000\n",
      "                    weighted avg       0.62      0.44      0.51    100000\n",
      "\n",
      "Mean precision at recall 0.2: 0.6231 ± 0.0013\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Random Forest classifier\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100,        \n",
    "    max_depth=15,            \n",
    "    min_samples_split=10,    \n",
    "    min_samples_leaf=5,     \n",
    "    max_features='sqrt',     \n",
    "    bootstrap=True,          \n",
    "    class_weight='balanced', \n",
    "    n_jobs=64,              \n",
    "    random_state=42,         \n",
    "    verbose=1               \n",
    ")\n",
    "\n",
    "# Create scorer for precision at recall\n",
    "scorer = make_scorer(precision_at_recall, recall=0.2, average='weighted')\n",
    "\n",
    "# Run cross-validation with the Gradient Boosting model\n",
    "scores = cross_val_score(rf, X_sample, y_train, cv=5, scoring=scorer, verbose=1, n_jobs=64)\n",
    "\n",
    "# Fit the model and predict using cross-validation\n",
    "y_pred_cv = cross_val_predict(rf, X_sample, y_train, cv=5, n_jobs=64)\n",
    "\n",
    "# Calculate metrics\n",
    "recall = recall_score(y_train, y_pred_cv, average='macro')\n",
    "precision = precision_score(y_train, y_pred_cv, average='macro', zero_division=0)\n",
    "f1 = f1_score(y_train, y_pred_cv, average='macro')\n",
    "\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Print classification report\n",
    "print(\"Cross-Validation Classification Report:\")\n",
    "print(classification_report(y_train, y_pred_cv, zero_division=0))\n",
    "print(f\"Mean precision at recall 0.2: {scores.mean():.4f} ± {scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=64)]: Using backend LokyBackend with 64 concurrent workers.\n",
      "/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[Parallel(n_jobs=64)]: Done   5 out of   5 | elapsed:   12.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.0560\n",
      "Precision: 0.0589\n",
      "F1 Score: 0.0513\n",
      "Cross-Validation Classification Report:\n",
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "            Carrier Cancellation       0.00      0.00      0.00       424\n",
      "      Major Delay - CarrierDelay       0.00      0.00      0.00       514\n",
      " Major Delay - LateAircraftDelay       0.00      0.00      0.00       649\n",
      "          Major Delay - NASDelay       0.00      0.00      0.00        91\n",
      "      Major Delay - WeatherDelay       0.10      0.01      0.02        96\n",
      "     Medium Delay - CarrierDelay       0.02      0.00      0.00      1881\n",
      "Medium Delay - LateAircraftDelay       0.02      0.00      0.00      2886\n",
      "         Medium Delay - NASDelay       0.00      0.00      0.00       487\n",
      "     Medium Delay - WeatherDelay       0.00      0.00      0.00       325\n",
      "      Minor Delay - CarrierDelay       0.03      0.00      0.01      3539\n",
      " Minor Delay - LateAircraftDelay       0.05      0.01      0.01      4238\n",
      "          Minor Delay - NASDelay       0.00      0.00      0.00      1060\n",
      "      Minor Delay - WeatherDelay       0.00      0.00      0.00       326\n",
      "                NAS Cancellation       0.00      0.00      0.00       205\n",
      "                         On-Time       0.78      0.98      0.87     78470\n",
      "                  Security Issue       0.00      0.00      0.00        51\n",
      "                         Unknown       0.04      0.00      0.01      3977\n",
      "            Weather Cancellation       0.03      0.00      0.00       781\n",
      "\n",
      "                        accuracy                           0.77    100000\n",
      "                       macro avg       0.06      0.06      0.05    100000\n",
      "                    weighted avg       0.62      0.77      0.68    100000\n",
      "\n",
      "Mean precision at recall 0.2: 0.6217 ± 0.0022\n"
     ]
    }
   ],
   "source": [
    "# KNN configuration\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(\n",
    "    n_neighbors=5,   \n",
    "    weights='distance', \n",
    "    n_jobs=64           \n",
    ")\n",
    "\n",
    "\n",
    "# Create scorer for precision at recall\n",
    "scorer = make_scorer(precision_at_recall, recall=0.2, average='weighted')\n",
    "\n",
    "# Run cross-validation with the Gradient Boosting model\n",
    "scores = cross_val_score(knn, X_sample, y_train, cv=5, scoring=scorer, verbose=1, n_jobs=64)\n",
    "\n",
    "# Fit the model and predict using cross-validation\n",
    "y_pred_cv = cross_val_predict(knn, X_sample, y_train, cv=5, n_jobs=64)\n",
    "\n",
    "# Calculate metrics\n",
    "recall = recall_score(y_train, y_pred_cv, average='macro')\n",
    "precision = precision_score(y_train, y_pred_cv, average='macro', zero_division=0)\n",
    "f1 = f1_score(y_train, y_pred_cv, average='macro')\n",
    "\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Print classification report\n",
    "print(\"Cross-Validation Classification Report:\")\n",
    "print(classification_report(y_train, y_pred_cv, zero_division=0))\n",
    "print(f\"Mean precision at recall 0.2: {scores.mean():.4f} ± {scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=64)]: Using backend LokyBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done   5 out of   5 | elapsed:    4.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.0566\n",
      "Precision: 0.0560\n",
      "F1 Score: 0.0548\n",
      "Cross-Validation Classification Report:\n",
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "            Carrier Cancellation       0.00      0.00      0.00       424\n",
      "      Major Delay - CarrierDelay       0.01      0.01      0.01       514\n",
      " Major Delay - LateAircraftDelay       0.00      0.00      0.00       649\n",
      "          Major Delay - NASDelay       0.00      0.00      0.00        91\n",
      "      Major Delay - WeatherDelay       0.01      0.02      0.01        96\n",
      "     Medium Delay - CarrierDelay       0.02      0.01      0.01      1881\n",
      "Medium Delay - LateAircraftDelay       0.03      0.01      0.02      2886\n",
      "         Medium Delay - NASDelay       0.01      0.01      0.01       487\n",
      "     Medium Delay - WeatherDelay       0.00      0.00      0.00       325\n",
      "      Minor Delay - CarrierDelay       0.04      0.02      0.02      3539\n",
      " Minor Delay - LateAircraftDelay       0.04      0.02      0.02      4238\n",
      "          Minor Delay - NASDelay       0.01      0.01      0.01      1060\n",
      "      Minor Delay - WeatherDelay       0.00      0.00      0.00       326\n",
      "                NAS Cancellation       0.00      0.00      0.00       205\n",
      "                         On-Time       0.78      0.90      0.84     78470\n",
      "                  Security Issue       0.00      0.00      0.00        51\n",
      "                         Unknown       0.04      0.02      0.02      3977\n",
      "            Weather Cancellation       0.00      0.00      0.00       781\n",
      "\n",
      "                        accuracy                           0.71    100000\n",
      "                       macro avg       0.06      0.06      0.05    100000\n",
      "                    weighted avg       0.62      0.71      0.66    100000\n",
      "\n",
      "Mean precision at recall 0.2: 0.6218 ± 0.0013\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           1.0042          -0.0317            6.95m\n",
      "         2           1.0081      -40138.2895            6.27m\n",
      "         3       26759.8696       40138.2951            5.82m\n",
      "         4       26759.8875        -121.8885            5.44m\n",
      "         5           1.0818  -415411197.7708            5.07m\n",
      "         6   276940799.5580   415411197.7211            4.72m\n",
      "         7   276940880.8312         121.9090            4.37m\n",
      "         8   276940880.8185          -0.0142            4.02m\n",
      "         9       26841.2141  -415371063.1719            3.68m\n",
      "        10       26843.7205           3.7629            3.34m\n",
      "        11   276914121.9561   415330917.3110            3.00m\n",
      "        12       26843.6908  -415330917.3881            2.66m\n",
      "        13   276940880.8633   415371055.7658            2.33m\n",
      "        14   276940880.8772           0.0149            1.99m\n",
      "        15       26843.7076  -415371055.7526            1.66m\n",
      "        16           3.5668      -40260.2077            1.33m\n",
      "        17          84.9036         122.0118           59.70s\n",
      "        18   276914121.8809   415371055.4643           39.77s\n",
      "        19           3.5674  -415371177.4653           19.87s\n",
      "        20          84.8314         121.8969            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           1.0043          -0.0376            6.43m\n",
      "         2           1.0049           0.0037            5.99m\n",
      "         3           1.0078          -0.0048            5.62m\n",
      "         4           1.0222     -278407.6737            5.28m\n",
      "         5      185606.0684   -12775237.3040            4.94m\n",
      "         6      185606.6518          -7.4648            4.60m\n",
      "         7      185611.0364           6.5751            4.27m\n",
      "         8      185606.1488          -7.3286            3.94m\n",
      "         9     8702431.6062    12775238.1871            3.61m\n",
      "        10     8702431.0132          -0.8934            3.28m\n",
      "        11           6.0809   -13053637.3981            2.95m\n",
      "        12     8888036.5648    13332045.7319            2.62m\n",
      "        13      185611.0528   -13182295.8674            2.29m\n",
      "        14      185611.1330           0.1250            1.96m\n",
      "        15     8788208.2275    12903895.6414            1.64m\n",
      "        16     8788207.7244          -1.0527            1.31m\n",
      "        17      271382.9511   -12775237.1602           58.89s\n",
      "        18      271382.9593           0.0139           39.26s\n",
      "        19      185611.7129     -128656.8732           19.63s\n",
      "        20      185611.8214        -434.4813            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.9989          -0.0443            6.69m\n",
      "         2           1.0105           0.0080            6.12m\n",
      "         3           1.0220           0.0155            5.72m\n",
      "         4           1.0290     -198855.3433            5.36m\n",
      "         5          43.3558          63.4819            5.00m\n",
      "         6      132328.5837      198396.6984            4.66m\n",
      "         7      132592.0441         395.1927            4.32m\n",
      "         8      132573.8231         -27.3239            3.98m\n",
      "         9      132514.3373         -89.7144            3.65m\n",
      "        10      132580.3590          99.0342            3.32m\n",
      "        11         186.7526     -198590.4069            2.98m\n",
      "        12      897125.4030    -2095340.3973            2.65m\n",
      "        13      897139.9995          21.8954            2.32m\n",
      "        14     1661813.8500     1147010.7721            1.99m\n",
      "        15     2426382.2634     1146852.6185            1.65m\n",
      "        16          72.4774    -3639464.6765            1.32m\n",
      "        17     2426421.7210     3639523.8699           59.49s\n",
      "        18     2426313.6848      -12788.9745           39.64s\n",
      "        19     1668416.4523    -1136845.8448           19.82s\n",
      "        20     1665129.5969       -4930.2830            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.9989          -0.0443            6.83m\n",
      "         2           1.0105           0.0080            6.19m\n",
      "         3           1.0220           0.0155            5.75m\n",
      "         4           1.0290     -198855.3433            5.37m\n",
      "         5          43.3558          63.4819            5.01m\n",
      "         6      132328.5837      198396.6984            4.66m\n",
      "         7      132592.0441         395.1927            4.32m\n",
      "         8      132573.8231         -27.3239            3.98m\n",
      "         9      132514.3373         -89.7144            3.65m\n",
      "        10      132580.3590          99.0342            3.31m\n",
      "        11         186.7526     -198590.4069            2.98m\n",
      "        12      897125.4030    -2095340.3973            2.64m\n",
      "        13      897139.9995          21.8954            2.31m\n",
      "        14     1661813.8500     1147010.7721            1.98m\n",
      "        15     2426382.2634     1146852.6185            1.65m\n",
      "        16          72.4774    -3639464.6765            1.32m\n",
      "        17     2426421.7210     3639523.8699           59.35s\n",
      "        18     2426313.6848      -12788.9745           39.55s\n",
      "        19     1668416.4523    -1136845.8448           19.77s\n",
      "        20     1665129.5969       -4930.2830            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           1.0033          -0.0419            6.83m\n",
      "         2           1.0143      -40217.9447            6.21m\n",
      "         3       26775.3964       39823.1068            5.78m\n",
      "         4       27038.6471   -15726328.6679            5.40m\n",
      "         5           1.0268      -40556.4357            5.08m\n",
      "         6       26888.2093       40121.9979            4.71m\n",
      "         7    10511541.3437    15726827.9891            4.36m\n",
      "         8    10511623.7946         127.8016            4.01m\n",
      "         9    10511720.9930         145.8003            3.66m\n",
      "        10    10511754.1429          49.7211            3.33m\n",
      "        11    10484946.5750      -40211.3505            2.99m\n",
      "        12    10511639.7268       40039.7234            2.66m\n",
      "        13    10511474.9770        -247.1253            2.32m\n",
      "        14    10511645.7582         116.1771            1.99m\n",
      "        15    10511510.9228        -216.2119            1.66m\n",
      "        16         369.4739   -17228000.0540            1.32m\n",
      "        17    11459114.5885    17188117.6568           59.64s\n",
      "        18    10484845.3011    -1461403.9294           39.73s\n",
      "        19         387.3242   -15726686.9550           19.85s\n",
      "        20    11458911.1057    17187785.6706            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           1.0033          -0.0419            6.35m\n",
      "         2           1.0143      -40217.9447            5.93m\n",
      "         3       26775.3964       39823.1068            5.58m\n",
      "         4       27038.6471   -15726328.6679            5.24m\n",
      "         5           1.0268      -40556.4357            4.90m\n",
      "         6       26888.2093       40121.9979            4.57m\n",
      "         7    10511541.3437    15726827.9891            4.24m\n",
      "         8    10511623.7946         127.8016            3.91m\n",
      "         9    10511720.9930         145.8003            3.59m\n",
      "        10    10511754.1429          49.7211            3.26m\n",
      "        11    10484946.5750      -40211.3505            2.93m\n",
      "        12    10511639.7268       40039.7234            2.61m\n",
      "        13    10511474.9770        -247.1253            2.28m\n",
      "        14    10511645.7582         116.1771            1.96m\n",
      "        15    10511510.9228        -216.2119            1.63m\n",
      "        16         369.4739   -17228000.0540            1.30m\n",
      "        17    11459114.5885    17188117.6568           58.68s\n",
      "        18    10484845.3011    -1461403.9294           39.12s\n",
      "        19         387.3242   -15726686.9550           19.56s\n",
      "        20    11458911.1057    17187785.6706            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           1.0075          -0.0456            6.91m\n",
      "         2       13389.5128           0.0298            6.24m\n",
      "         3           1.0228      -20205.2374            5.80m\n",
      "         4          82.6839         122.4923            5.41m\n",
      "         5       13471.1723     -152324.8901            5.05m\n",
      "         6       54676.1275       61807.4354            4.70m\n",
      "         7      128409.4461      110599.9741            4.35m\n",
      "         8       41205.9724     -130805.2123            4.01m\n",
      "         9          82.6883      -61684.9601            3.67m\n",
      "        10      128327.7992      192367.6686            3.33m\n",
      "        11       13471.3343     -172284.7029            3.00m\n",
      "        12      128409.4627      172407.1943            2.66m\n",
      "        13       54594.6025     -110722.2900            2.33m\n",
      "        14           1.1816      -81890.1345            2.00m\n",
      "        15       87204.5088      130804.9838            1.66m\n",
      "        16 417730552426737883879129541714640896.0000 -626595828640106788925206165152858112.0000            1.33m\n",
      "        17 417730552426737883879129541714640896.0000           0.0000           59.95s\n",
      "        18 417730552426737883879129541714640896.0000           0.0000           39.93s\n",
      "        19 835461104853475767758259083429281792.0000 626595828640106788925206165152858112.0000           19.95s\n",
      "        20       73816.0273 -1253191657280213577850412330305716224.0000            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           1.0075          -0.0456            6.48m\n",
      "         2       13389.5128           0.0298            6.00m\n",
      "         3           1.0228      -20205.2374            5.63m\n",
      "         4          82.6839         122.4923            5.28m\n",
      "         5       13471.1723     -152324.8901            4.94m\n",
      "         6       54676.1275       61807.4354            4.60m\n",
      "         7      128409.4461      110599.9741            4.27m\n",
      "         8       41205.9724     -130805.2123            3.94m\n",
      "         9          82.6883      -61684.9601            3.61m\n",
      "        10      128327.7992      192367.6686            3.28m\n",
      "        11       13471.3343     -172284.7029            2.95m\n",
      "        12      128409.4627      172407.1943            2.62m\n",
      "        13       54594.6025     -110722.2900            2.30m\n",
      "        14           1.1816      -81890.1345            1.97m\n",
      "        15       87204.5088      130804.9838            1.64m\n",
      "        16 417730552426737883879129541714640896.0000 -626595828640106788925206165152858112.0000            1.31m\n",
      "        17 417730552426737883879129541714640896.0000           0.0000           58.97s\n",
      "        18 417730552426737883879129541714640896.0000           0.0000           39.30s\n",
      "        19 835461104853475767758259083429281792.0000 626595828640106788925206165152858112.0000           19.65s\n",
      "        20       73816.0273 -1253191657280213577850412330305716224.0000            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           1.0043          -0.0376            6.71m\n",
      "         2           1.0049           0.0037            6.16m\n",
      "         3           1.0078          -0.0048            5.76m\n",
      "         4           1.0222     -278407.6737            5.39m\n",
      "         5      185606.0684   -12775237.3040            5.03m\n",
      "         6      185606.6518          -7.4648            4.68m\n",
      "         7      185611.0364           6.5751            4.34m\n",
      "         8      185606.1488          -7.3286            4.00m\n",
      "         9     8702431.6062    12775238.1871            3.67m\n",
      "        10     8702431.0132          -0.8934            3.33m\n",
      "        11           6.0809   -13053637.3981            2.99m\n",
      "        12     8888036.5648    13332045.7319            2.66m\n",
      "        13      185611.0528   -13182295.8674            2.33m\n",
      "        14      185611.1330           0.1250            1.99m\n",
      "        15     8788208.2275    12903895.6414            1.66m\n",
      "        16     8788207.7244          -1.0527            1.33m\n",
      "        17      271382.9511   -12775237.1602           59.60s\n",
      "        18      271382.9593           0.0139           39.71s\n",
      "        19      185611.7129     -128656.8732           19.85s\n",
      "        20      185611.8214        -434.4813            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           1.0042          -0.0317            6.60m\n",
      "         2           1.0081      -40138.2895            6.07m\n",
      "         3       26759.8696       40138.2951            5.68m\n",
      "         4       26759.8875        -121.8885            5.32m\n",
      "         5           1.0818  -415411197.7708            4.98m\n",
      "         6   276940799.5580   415411197.7211            4.64m\n",
      "         7   276940880.8312         121.9090            4.30m\n",
      "         8   276940880.8185          -0.0142            3.97m\n",
      "         9       26841.2141  -415371063.1719            3.64m\n",
      "        10       26843.7205           3.7629            3.30m\n",
      "        11   276914121.9561   415330917.3110            2.97m\n",
      "        12       26843.6908  -415330917.3881            2.64m\n",
      "        13   276940880.8633   415371055.7658            2.31m\n",
      "        14   276940880.8772           0.0149            1.98m\n",
      "        15       26843.7076  -415371055.7526            1.65m\n",
      "        16           3.5668      -40260.2077            1.32m\n",
      "        17          84.9036         122.0118           59.30s\n",
      "        18   276914121.8809   415371055.4643           39.53s\n",
      "        19           3.5674  -415371177.4653           19.76s\n",
      "        20          84.8314         121.8969            0.00s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "extra_trees = ExtraTreesClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=15,\n",
    "    class_weight='balanced',\n",
    "    n_jobs=64,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Create scorer for precision at recall\n",
    "scorer = make_scorer(precision_at_recall, recall=0.2, average='weighted')\n",
    "\n",
    "# Run cross-validation with the Gradient Boosting model\n",
    "scores = cross_val_score(extra_trees, X_sample, y_train, cv=5, scoring=scorer, verbose=1, n_jobs=64)\n",
    "\n",
    "# Fit the model and predict using cross-validation\n",
    "y_pred_cv = cross_val_predict(extra_trees, X_sample, y_train, cv=5, n_jobs=64)\n",
    "\n",
    "# Calculate metrics\n",
    "recall = recall_score(y_train, y_pred_cv, average='macro')\n",
    "precision = precision_score(y_train, y_pred_cv, average='macro', zero_division=0)\n",
    "f1 = f1_score(y_train, y_pred_cv, average='macro')\n",
    "\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Print classification report\n",
    "print(\"Cross-Validation Classification Report:\")\n",
    "print(classification_report(y_train, y_pred_cv, zero_division=0))\n",
    "print(f\"Mean precision at recall 0.2: {scores.mean():.4f} ± {scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
