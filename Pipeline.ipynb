{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Extraction**\n",
    "\n",
    "1.  **Capture Historical Delay Patterns:**\n",
    "    * **Feature:** `Delay_Trend`\n",
    "    * **Goal:** Identify recurring delays between specific airport pairs during particular weeks.\n",
    "    * **Implementation:** Aggregate weekly delay data, focusing on the top 15 airports to manage memory and ensure generalizability.\n",
    "    * **Rationale:** Historical delay patterns are strong indicators of future delays.\n",
    "\n",
    "2.  **Assess Aircraft Reuse:**\n",
    "    * **Feature:** `Same_Day_Tail_Reuse`\n",
    "    * **Goal:** Determine if an aircraft is scheduled for multiple flights on the same day.\n",
    "    * **Rationale:** High reuse can lead to delay propagation.\n",
    "\n",
    "3.  **Calculate Turnaround Time:**\n",
    "    * **Feature:** `Turnaround_Time`\n",
    "    * **Goal:** Measure the time between an aircraft's arrival and its next scheduled departure.\n",
    "    * **Rationale:** Short turnaround times increase delay vulnerability.\n",
    "\n",
    "4.  **Determine Slack Time:**\n",
    "    * **Feature:** `Slack_Time`\n",
    "    * **Goal:** Calculate the difference between scheduled arrival and expected travel time.\n",
    "    * **Rationale:** Slack time indicates buffer capacity, which can absorb minor delays.\n",
    "\n",
    "**Outlier**\n",
    "\n",
    "1.  **Handle Extreme Aircraft Age Values:**\n",
    "    * **Feature:** `Aircraft_Age`\n",
    "    * **Issue:** Presence of unrealistic age values.\n",
    "    * **Solution:** Clip outliers to a realistic maximum (e.g., 56.9 years).\n",
    "    * **Rationale:** Prevent outliers from skewing model training.\n",
    "\n",
    "**Transformation and Imputation**\n",
    "\n",
    "1.  **Apply Logarithmic Transformation:**\n",
    "    * **Features:** `Distance`, `Wind_Gust`\n",
    "    * **Transformation:** `log1p`\n",
    "    * **Rationale:** Address right-skewed distributions and improve model robustness.\n",
    "\n",
    "2.  **Impute Missing Values:**\n",
    "    * **Strategy:** Mean imputation for numeric features, most frequent imputation for categorical features.\n",
    "    * **Rationale:** Maintain data completeness with a simple and effective approach.\n",
    "\n",
    "**Feature Pruning**\n",
    "\n",
    "1.  **Remove Redundant Information:**\n",
    "    * **Action:** Drop columns like city/state names, latitude/longitude, and detailed marketing airline data.\n",
    "    * **Rationale:** Eliminate redundant information that doesn't contribute to prediction accuracy.\n",
    "\n",
    "2.  **Discard Uninformative or Highly Missing Columns:**\n",
    "    * **Action:** Remove columns with significant missing data or those that offer little predictive value.\n",
    "    * **Rationale:** Reduce noise and improve model focus.\n",
    "\n",
    "**Encoding and Categorical**\n",
    "\n",
    "1.  **One-Hot Encoding with Cardinality Limits:**\n",
    "    * **Features:** `OriginAirportID`, `DestAirportID`\n",
    "    * **Encoding:** `OneHotEncoder` with `max_categories=50`.\n",
    "    * **Rationale:** Handle high-cardinality features efficiently while preserving important information.\n",
    "\n",
    "2.  **Full One-Hot Encoding:**\n",
    "    * **Features:** `DayOfWeek`, `Month`, `Operating_Airline`\n",
    "    * **Encoding:** Complete one-hot encoding.\n",
    "    * **Rationale:** Preserve category identity for time- and airline-sensitive predictions.\n",
    "\n",
    "**Dimensionality Reduction**\n",
    "\n",
    "- **Principal Component Analysis (PCA):**\n",
    "    * **Technique:** `PCA(n_components=50)`\n",
    "    * **Rationale:** Address multicollinearity and reduce dimensionality, especially with correlated weather and location data.\n",
    "    * **Benefit:** Improved training efficiency and reduced overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, FunctionTransformer, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import time\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn import set_config\n",
    "set_config(transform_output = \"pandas\")\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def stratified_random_split(df: pd.DataFrame, target_column: str, test_size: float = 0.1, random_state: int = 42):\n",
    "    \"\"\"\n",
    "    Performs a stratified random train-test split to ensure all classes in \n",
    "    'Flight_Status' are proportionally represented in both sets.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The dataset containing the target variable.\n",
    "    target_column (str): The column representing the classification target.\n",
    "    test_size (float): The proportion of data to be used as test data.\n",
    "    random_state (int): Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "    tuple: (train_df, test_df) DataFrames.\n",
    "    \"\"\"\n",
    "    train_df, test_df = train_test_split(\n",
    "        df, test_size=test_size, stratify=df[target_column], random_state=random_state\n",
    "    )\n",
    "\n",
    "    print(f\"Train size: {len(train_df)} samples\")\n",
    "    print(f\"Test size: {len(test_df)} samples\")\n",
    "\n",
    "    return train_df, test_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setting up the DataFrame for the flight data\n",
    "flight_data = pd.read_parquet(\"WEATHER121.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 13184010 samples\n",
      "Test size: 1464890 samples\n"
     ]
    }
   ],
   "source": [
    "# Stratify the data\n",
    "train_data, test_data= stratified_random_split(flight_data, target_column=\"Flight_Status\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#downsample to 100000\n",
    "\n",
    "train_data = train_data.sample(n=100000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Splitting the data into X and y\n",
    "X_train = train_data.drop(columns=[\"Flight_Status\"])\n",
    "y_train = train_data[\"Flight_Status\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Custom progress logger\n",
    "class ProgressLogger(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    A transformer that logs progress through a pipeline.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, total_rows, log_interval=0.01, name='Pipeline'):\n",
    "        self.total_rows = total_rows\n",
    "        self.log_interval = log_interval\n",
    "        self.name = name\n",
    "        self.start_time = None\n",
    "        self.last_log_percent = -1\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        # Initialize timer if not started\n",
    "        if self.start_time is None:\n",
    "            self.start_time = time.time()\n",
    "            print(f\"{self.name} processing started on {self.total_rows:,} rows\")\n",
    "        \n",
    "        # Calculate current progress\n",
    "        current_rows = X.shape[0]\n",
    "        percent_complete = current_rows / self.total_rows\n",
    "        \n",
    "        # Check if we need to log progress\n",
    "        int_percent = int(percent_complete / self.log_interval)\n",
    "        if int_percent > self.last_log_percent:\n",
    "            self.last_log_percent = int_percent\n",
    "            elapsed = time.time() - self.start_time\n",
    "            \n",
    "            # Estimate time remaining\n",
    "            percent_done = percent_complete * 100\n",
    "            if percent_complete > 0:\n",
    "                total_est = elapsed / percent_complete\n",
    "                remaining = total_est - elapsed\n",
    "                time_str = f\" - Est. remaining: {remaining:.1f}s\"\n",
    "            else:\n",
    "                time_str = \"\"\n",
    "                \n",
    "            print(f\"{self.name}: {percent_done:.1f}% complete ({current_rows:,}/{self.total_rows:,} rows){time_str}\")\n",
    "        \n",
    "        return X\n",
    "\n",
    "class DelayTrendEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer that precomputes a route-based delay trend using week_of_year and top N airports.\n",
    "\n",
    "    Parameters:\n",
    "        date_col (str): Name of the datetime column\n",
    "        origin_col (str): Origin airport column\n",
    "        dest_col (str): Destination airport column\n",
    "        status_col (str): Flight status column for delay signal\n",
    "        output_col (str): Name of the new delay trend feature\n",
    "        top_n_airports (int): Number of top airports to retain by frequency\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 date_col='dep_datetime',\n",
    "                 origin_col='OriginAirportID',\n",
    "                 dest_col='DestAirportID',\n",
    "                 status_col='Flight_Status',\n",
    "                 output_col='Delay_Trend',\n",
    "                 top_n_airports=15):\n",
    "        self.date_col = date_col\n",
    "        self.origin_col = origin_col\n",
    "        self.dest_col = dest_col\n",
    "        self.status_col = status_col\n",
    "        self.output_col = output_col\n",
    "        self.top_n_airports = top_n_airports\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X_temp = X.copy()\n",
    "        X_temp[self.date_col] = pd.to_datetime(X_temp[self.date_col])\n",
    "        X_temp['week_of_year'] = X_temp[self.date_col].dt.isocalendar().week\n",
    "\n",
    "        X_temp['Flight_Status'] = y.reset_index(drop=True)\n",
    "        \n",
    "        # Restrict to top N airports\n",
    "        all_airports = pd.concat([X_temp[self.origin_col], X_temp[self.dest_col]])\n",
    "        top_airports = all_airports.value_counts().head(self.top_n_airports).index\n",
    "        X_temp = X_temp[\n",
    "            X_temp[self.origin_col].isin(top_airports) &\n",
    "            X_temp[self.dest_col].isin(top_airports)\n",
    "        ]\n",
    "\n",
    "        # Create delay signal\n",
    "        delay_reasons = [\n",
    "            'CarrierDelay', 'WeatherDelay', 'NASDelay',\n",
    "            'SecurityDelay', 'LateAircraftDelay'\n",
    "        ]\n",
    "        X_temp['delay_signal'] = 0\n",
    "        mask = X_temp['Flight_Status'].str.contains('Delay', na=False)\n",
    "        delay_type = X_temp.loc[mask, 'Flight_Status'].str.split(' - ').str[-1]\n",
    "        valid = delay_type.isin(delay_reasons)\n",
    "        X_temp.loc[mask[mask].index[valid], 'delay_signal'] = 1\n",
    "\n",
    "        # Group by week and airport pair\n",
    "        self.trend_lookup_ = (\n",
    "            X_temp.groupby(['week_of_year', self.origin_col, self.dest_col])['delay_signal']\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "            .rename(columns={'delay_signal': self.output_col})\n",
    "        )\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X[self.date_col] = pd.to_datetime(X[self.date_col])\n",
    "        X['week_of_year'] = X[self.date_col].dt.isocalendar().week\n",
    "\n",
    "        X = X.merge(\n",
    "            self.trend_lookup_,\n",
    "            on=['week_of_year', self.origin_col, self.dest_col],\n",
    "            how='left'\n",
    "        )\n",
    "\n",
    "        X[self.output_col] = X[self.output_col].fillna(0)\n",
    "        return X.drop(columns=['week_of_year'])\n",
    "\n",
    "class SameDayTailReuseEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer that creates a feature counting how many times\n",
    "    the same tail number (aircraft) is used on the same day.\n",
    "\n",
    "    Parameters:\n",
    "        datetime_col (str): Column containing full departure datetime\n",
    "        tail_col (str): Column name for tail number\n",
    "        output_col (str): Name of the output column\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 datetime_col='dep_datetime',\n",
    "                 tail_col='Tail_Number',\n",
    "                 output_col='Same_Day_Tail_Reuse'):\n",
    "        self.datetime_col = datetime_col\n",
    "        self.tail_col = tail_col\n",
    "        self.output_col = output_col\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "\n",
    "        # Ensure datetime is parsed correctly\n",
    "        X[self.datetime_col] = pd.to_datetime(X[self.datetime_col])\n",
    "\n",
    "        # Extract just the date portion\n",
    "        X['dep_date'] = X[self.datetime_col].dt.date\n",
    "\n",
    "        # Count reuse of same tail number per day\n",
    "        X[self.output_col] = (\n",
    "            X.groupby([self.tail_col, 'dep_date'])[self.tail_col]\n",
    "            .transform('count')\n",
    "            .astype(float)  \n",
    "        )\n",
    "\n",
    "        return X.drop(columns=['dep_date'])\n",
    "\n",
    "    \n",
    "class TurnaroundDelayEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer that computes:\n",
    "    - Previous_Flight_Delay: scheduled departure time of previous flight with same tail number on same day\n",
    "    - Turnaround_Time: time between previous arrival and current departure\n",
    "\n",
    "    Parameters:\n",
    "        datetime_col (str): Column with full departure datetime\n",
    "        dep_time_col (str): Column with scheduled departure time (e.g. CRSDepTime)\n",
    "        arr_time_col (str): Column with scheduled arrival time (e.g. CRSArrTime)\n",
    "        tail_col (str): Tail number column\n",
    "        output_prefix (str): Prefix to use for new feature columns\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 datetime_col='dep_datetime',\n",
    "                 dep_time_col='CRSDepTime',\n",
    "                 arr_time_col='CRSArrTime',\n",
    "                 tail_col='Tail_Number',\n",
    "                 output_prefix=''):\n",
    "        self.datetime_col = datetime_col\n",
    "        self.dep_time_col = dep_time_col\n",
    "        self.arr_time_col = arr_time_col\n",
    "        self.tail_col = tail_col\n",
    "        self.output_prefix = output_prefix\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X[self.datetime_col] = pd.to_datetime(X[self.datetime_col])\n",
    "        X['dep_date'] = X[self.datetime_col].dt.date\n",
    "\n",
    "        # Sort the values\n",
    "        X = X.sort_values(by=[self.tail_col, 'dep_date', self.dep_time_col])\n",
    "\n",
    "        prev_delay_col = self.output_prefix + 'Previous_Flight_Delay'\n",
    "        turnaround_col = self.output_prefix + 'Turnaround_Time'\n",
    "\n",
    "        # Previous scheduled departure\n",
    "        X[prev_delay_col] = (\n",
    "            X.groupby([self.tail_col, 'dep_date'])[self.dep_time_col]\n",
    "            .shift(1)\n",
    "        )\n",
    "\n",
    "        # Previous scheduled arrival time\n",
    "        X['Previous_Arrival_Time'] = (\n",
    "            X.groupby([self.tail_col, 'dep_date'])[self.arr_time_col]\n",
    "            .shift(1)\n",
    "        )\n",
    "\n",
    "        # Compute turnaround time using a defined method\n",
    "        X[turnaround_col] = self._calculate_turnaround(X[self.dep_time_col], X['Previous_Arrival_Time'])\n",
    "\n",
    "        # Replace missing with 0\n",
    "        X[prev_delay_col] = X[prev_delay_col].fillna(0)\n",
    "        X[turnaround_col] = X[turnaround_col].fillna(0)\n",
    "\n",
    "        return X.drop(columns=['dep_date', 'Previous_Arrival_Time'])\n",
    "\n",
    "    def _calculate_turnaround(self, current_dep, previous_arr):\n",
    "        \"\"\"\n",
    "        Applies time difference logic with wrap-around at midnight (2400).\n",
    "        \"\"\"\n",
    "        diff = current_dep - previous_arr\n",
    "        adjusted = diff.mask((~diff.isna()) & (diff < 0), diff + 2400)\n",
    "        return adjusted\n",
    "\n",
    "class SlackTimeEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer that calculates slack time as the difference between scheduled\n",
    "    arrival time (CRSArrTime) and scheduled elapsed time (CRSElapsedTime).\n",
    "\n",
    "    Parameters:\n",
    "        arr_col (str): Column name for scheduled arrival time.\n",
    "        elapsed_col (str): Column name for scheduled elapsed time.\n",
    "        output_col (str): Name of the output column to store slack time.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 arr_col='CRSArrTime',\n",
    "                 elapsed_col='CRSElapsedTime',\n",
    "                 output_col='Slack_Time'):\n",
    "        self.arr_col = arr_col\n",
    "        self.elapsed_col = elapsed_col\n",
    "        self.output_col = output_col\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X[self.output_col] = X[self.arr_col] - X[self.elapsed_col]\n",
    "        return X\n",
    "    \n",
    "    \n",
    "\n",
    "class AgeClipper(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer that caps aircraft age at a maximum value.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    max_age : float, default=56.9\n",
    "        Maximum value for aircraft age\n",
    "    column_name : str, default='Aircraft_Age'\n",
    "        Name of the column to apply the cap to\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, max_age=56.9, column_name='Aircraft_Age'):\n",
    "        self.max_age = max_age\n",
    "        self.column_name = column_name\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        # Nothing to fit, just return self\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Convert to DataFrame if it's not already\n",
    "        X_transformed = X.copy() if isinstance(X, pd.DataFrame) else pd.DataFrame(X)\n",
    "        \n",
    "        # Apply the cap only if the column exists\n",
    "        if self.column_name in X_transformed.columns:\n",
    "            X_transformed[self.column_name] = np.minimum(X_transformed[self.column_name], self.max_age)\n",
    "        \n",
    "        # Return array if input was array\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X_transformed = X_transformed.values\n",
    "            \n",
    "        return X_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-19 {color: black;}#sk-container-id-19 pre{padding: 0;}#sk-container-id-19 div.sk-toggleable {background-color: white;}#sk-container-id-19 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-19 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-19 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-19 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-19 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-19 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-19 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-19 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-19 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-19 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-19 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-19 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-19 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-19 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-19 div.sk-item {position: relative;z-index: 1;}#sk-container-id-19 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-19 div.sk-item::before, #sk-container-id-19 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-19 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-19 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-19 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-19 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-19 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-19 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-19 div.sk-label-container {text-align: center;}#sk-container-id-19 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-19 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-19\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;initial_logger&#x27;,\n",
       "                 ProgressLogger(name=&#x27;Starting Pipeline&#x27;, total_rows=13000000)),\n",
       "                (&#x27;delay_trend&#x27;, DelayTrendEncoder()),\n",
       "                (&#x27;trend_logger&#x27;,\n",
       "                 ProgressLogger(name=&#x27;Delay Trend Complete&#x27;,\n",
       "                                total_rows=13000000)),\n",
       "                (&#x27;tail_reuse&#x27;, SameDayTailReuseEncoder()),\n",
       "                (&#x27;reuse_logger&#x27;,\n",
       "                 ProgressLogger(name=&#x27;Tail Reuse Complete&#x27;,\n",
       "                                total_rows=13000000)),\n",
       "                (&#x27;turnaround_delay&#x27;, T...\n",
       "                                                   &#x27;soil_temperature_0cm&#x27;,\n",
       "                                                   &#x27;rain&#x27;, &#x27;rain_dest_dep_time&#x27;,\n",
       "                                                   &#x27;dew_point_2m_dest_dep_time&#x27;,\n",
       "                                                   &#x27;cloud_cover_mid&#x27;,\n",
       "                                                   &#x27;cloud_cover&#x27;, ...])],\n",
       "                                   verbose_feature_names_out=False)),\n",
       "                (&#x27;prep_logger&#x27;,\n",
       "                 ProgressLogger(name=&#x27;Feature Prep Complete&#x27;,\n",
       "                                total_rows=13000000)),\n",
       "                (&#x27;select&#x27;, PCA(n_components=75, random_state=42)),\n",
       "                (&#x27;final_logger&#x27;,\n",
       "                 ProgressLogger(name=&#x27;Pipeline Complete&#x27;,\n",
       "                                total_rows=13000000))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-596\" type=\"checkbox\" ><label for=\"sk-estimator-id-596\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;initial_logger&#x27;,\n",
       "                 ProgressLogger(name=&#x27;Starting Pipeline&#x27;, total_rows=13000000)),\n",
       "                (&#x27;delay_trend&#x27;, DelayTrendEncoder()),\n",
       "                (&#x27;trend_logger&#x27;,\n",
       "                 ProgressLogger(name=&#x27;Delay Trend Complete&#x27;,\n",
       "                                total_rows=13000000)),\n",
       "                (&#x27;tail_reuse&#x27;, SameDayTailReuseEncoder()),\n",
       "                (&#x27;reuse_logger&#x27;,\n",
       "                 ProgressLogger(name=&#x27;Tail Reuse Complete&#x27;,\n",
       "                                total_rows=13000000)),\n",
       "                (&#x27;turnaround_delay&#x27;, T...\n",
       "                                                   &#x27;soil_temperature_0cm&#x27;,\n",
       "                                                   &#x27;rain&#x27;, &#x27;rain_dest_dep_time&#x27;,\n",
       "                                                   &#x27;dew_point_2m_dest_dep_time&#x27;,\n",
       "                                                   &#x27;cloud_cover_mid&#x27;,\n",
       "                                                   &#x27;cloud_cover&#x27;, ...])],\n",
       "                                   verbose_feature_names_out=False)),\n",
       "                (&#x27;prep_logger&#x27;,\n",
       "                 ProgressLogger(name=&#x27;Feature Prep Complete&#x27;,\n",
       "                                total_rows=13000000)),\n",
       "                (&#x27;select&#x27;, PCA(n_components=75, random_state=42)),\n",
       "                (&#x27;final_logger&#x27;,\n",
       "                 ProgressLogger(name=&#x27;Pipeline Complete&#x27;,\n",
       "                                total_rows=13000000))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-597\" type=\"checkbox\" ><label for=\"sk-estimator-id-597\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ProgressLogger</label><div class=\"sk-toggleable__content\"><pre>ProgressLogger(name=&#x27;Starting Pipeline&#x27;, total_rows=13000000)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-598\" type=\"checkbox\" ><label for=\"sk-estimator-id-598\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DelayTrendEncoder</label><div class=\"sk-toggleable__content\"><pre>DelayTrendEncoder()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-599\" type=\"checkbox\" ><label for=\"sk-estimator-id-599\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ProgressLogger</label><div class=\"sk-toggleable__content\"><pre>ProgressLogger(name=&#x27;Delay Trend Complete&#x27;, total_rows=13000000)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-600\" type=\"checkbox\" ><label for=\"sk-estimator-id-600\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SameDayTailReuseEncoder</label><div class=\"sk-toggleable__content\"><pre>SameDayTailReuseEncoder()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-601\" type=\"checkbox\" ><label for=\"sk-estimator-id-601\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ProgressLogger</label><div class=\"sk-toggleable__content\"><pre>ProgressLogger(name=&#x27;Tail Reuse Complete&#x27;, total_rows=13000000)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-602\" type=\"checkbox\" ><label for=\"sk-estimator-id-602\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TurnaroundDelayEncoder</label><div class=\"sk-toggleable__content\"><pre>TurnaroundDelayEncoder()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-603\" type=\"checkbox\" ><label for=\"sk-estimator-id-603\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ProgressLogger</label><div class=\"sk-toggleable__content\"><pre>ProgressLogger(name=&#x27;Turnaround Delay Complete&#x27;, total_rows=13000000)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-604\" type=\"checkbox\" ><label for=\"sk-estimator-id-604\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SlackTimeEncoder</label><div class=\"sk-toggleable__content\"><pre>SlackTimeEncoder()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-605\" type=\"checkbox\" ><label for=\"sk-estimator-id-605\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ProgressLogger</label><div class=\"sk-toggleable__content\"><pre>ProgressLogger(name=&#x27;Slack Time Complete&#x27;, total_rows=13000000)</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-606\" type=\"checkbox\" ><label for=\"sk-estimator-id-606\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">feature_prep: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(n_jobs=16, remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;numeric&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;, SimpleImputer()),\n",
       "                                                 (&#x27;age_clipper&#x27;, AgeClipper()),\n",
       "                                                 (&#x27;log1p_distance&#x27;,\n",
       "                                                  ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                                                    transformers=[(&#x27;log&#x27;,\n",
       "                                                                                   FunctionTransformer(func=&lt;ufunc &#x27;log1p&#x27;&gt;),\n",
       "                                                                                   [&#x27;Distance&#x27;,\n",
       "                                                                                    &#x27;wind_gusts_10m_dest_dep_time&#x27;])],\n",
       "                                                                    verbose_feature_names_out=False)...\n",
       "                                  &#x27;wind_speed_120m_dest_dep_time&#x27;,\n",
       "                                  &#x27;wind_speed_180m_dest_dep_time&#x27;,\n",
       "                                  &#x27;wind_direction_80m_dest_dep_time&#x27;,\n",
       "                                  &#x27;wind_direction_120m_dest_dep_time&#x27;,\n",
       "                                  &#x27;wind_direction_180m_dest_dep_time&#x27;,\n",
       "                                  &#x27;soil_temperature_0cm_dest_dep_time&#x27;,\n",
       "                                  &#x27;soil_temperature_0cm&#x27;, &#x27;rain&#x27;,\n",
       "                                  &#x27;rain_dest_dep_time&#x27;,\n",
       "                                  &#x27;dew_point_2m_dest_dep_time&#x27;,\n",
       "                                  &#x27;cloud_cover_mid&#x27;, &#x27;cloud_cover&#x27;, ...])],\n",
       "                  verbose_feature_names_out=False)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-607\" type=\"checkbox\" ><label for=\"sk-estimator-id-607\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">numeric</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Distance&#x27;, &#x27;relative_humidity_2m&#x27;, &#x27;temperature_2m&#x27;, &#x27;Aircraft_Age&#x27;, &#x27;temperature_2m_dest_dep_time&#x27;, &#x27;snowfall&#x27;, &#x27;soil_moisture_0_to_1cm&#x27;, &#x27;snowfall_dest_dep_time&#x27;, &#x27;et0_fao_evapotranspiration_dest_dep_time&#x27;, &#x27;surface_pressure_dest_dep_time&#x27;, &#x27;pressure_msl_dest_dep_time&#x27;, &#x27;wind_direction_10m_dest_dep_time&#x27;, &#x27;wind_gusts_10m_dest_dep_time&#x27;, &#x27;CRSElapsedTime&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-608\" type=\"checkbox\" ><label for=\"sk-estimator-id-608\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-609\" type=\"checkbox\" ><label for=\"sk-estimator-id-609\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AgeClipper</label><div class=\"sk-toggleable__content\"><pre>AgeClipper()</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-610\" type=\"checkbox\" ><label for=\"sk-estimator-id-610\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">log1p_distance: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;log&#x27;,\n",
       "                                 FunctionTransformer(func=&lt;ufunc &#x27;log1p&#x27;&gt;),\n",
       "                                 [&#x27;Distance&#x27;, &#x27;wind_gusts_10m_dest_dep_time&#x27;])],\n",
       "                  verbose_feature_names_out=False)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-611\" type=\"checkbox\" ><label for=\"sk-estimator-id-611\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">log</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Distance&#x27;, &#x27;wind_gusts_10m_dest_dep_time&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-612\" type=\"checkbox\" ><label for=\"sk-estimator-id-612\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;ufunc &#x27;log1p&#x27;&gt;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-613\" type=\"checkbox\" ><label for=\"sk-estimator-id-613\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre></pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-614\" type=\"checkbox\" ><label for=\"sk-estimator-id-614\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-615\" type=\"checkbox\" ><label for=\"sk-estimator-id-615\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-616\" type=\"checkbox\" ><label for=\"sk-estimator-id-616\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">categorical</label><div class=\"sk-toggleable__content\"><pre>[&#x27;DayOfWeek&#x27;, &#x27;Month&#x27;, &#x27;OriginAirportID&#x27;, &#x27;DestAirportID&#x27;, &#x27;Is_Holiday_Week&#x27;, &#x27;Operating_Airline &#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-617\" type=\"checkbox\" ><label for=\"sk-estimator-id-617\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-618\" type=\"checkbox\" ><label for=\"sk-estimator-id-618\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OHE: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;top50&#x27;,\n",
       "                                 OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                               max_categories=51,\n",
       "                                               sparse_output=False),\n",
       "                                 [&#x27;OriginAirportID&#x27;, &#x27;DestAirportID&#x27;]),\n",
       "                                (&#x27;OHE&#x27;,\n",
       "                                 OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                               sparse_output=False),\n",
       "                                 [&#x27;DayOfWeek&#x27;, &#x27;Month&#x27;, &#x27;Operating_Airline &#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-619\" type=\"checkbox\" ><label for=\"sk-estimator-id-619\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">top50</label><div class=\"sk-toggleable__content\"><pre>[&#x27;OriginAirportID&#x27;, &#x27;DestAirportID&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-620\" type=\"checkbox\" ><label for=\"sk-estimator-id-620\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, max_categories=51, sparse_output=False)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-621\" type=\"checkbox\" ><label for=\"sk-estimator-id-621\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OHE</label><div class=\"sk-toggleable__content\"><pre>[&#x27;DayOfWeek&#x27;, &#x27;Month&#x27;, &#x27;Operating_Airline &#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-622\" type=\"checkbox\" ><label for=\"sk-estimator-id-622\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse_output=False)</pre></div></div></div></div></div></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-623\" type=\"checkbox\" ><label for=\"sk-estimator-id-623\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">drop</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Aircraft_Model&#x27;, &#x27;Aircraft_EngineType&#x27;, &#x27;Holiday&#x27;, &#x27;dep_datetime&#x27;, &#x27;Tail_Number&#x27;, &#x27;temperature_120m_dest_dep_time&#x27;, &#x27;temperature_180m_dest_dep_time&#x27;, &#x27;temperature_80m_dest_dep_time&#x27;, &#x27;temperature_180m&#x27;, &#x27;temperature_120m&#x27;, &#x27;temperature_80m&#x27;, &#x27;wind_speed_80m&#x27;, &#x27;wind_speed_120m&#x27;, &#x27;wind_speed_180m&#x27;, &#x27;wind_direction_80m&#x27;, &#x27;wind_direction_120m&#x27;, &#x27;wind_direction_180m&#x27;, &#x27;wind_speed_80m_dest_dep_time&#x27;, &#x27;wind_speed_120m_dest_dep_time&#x27;, &#x27;wind_speed_180m_dest_dep_time&#x27;, &#x27;wind_direction_80m_dest_dep_time&#x27;, &#x27;wind_direction_120m_dest_dep_time&#x27;, &#x27;wind_direction_180m_dest_dep_time&#x27;, &#x27;soil_temperature_0cm_dest_dep_time&#x27;, &#x27;soil_temperature_0cm&#x27;, &#x27;rain&#x27;, &#x27;rain_dest_dep_time&#x27;, &#x27;dew_point_2m_dest_dep_time&#x27;, &#x27;cloud_cover_mid&#x27;, &#x27;cloud_cover&#x27;, &#x27;cloud_cover_mid_dest_dep_time&#x27;, &#x27;cloud_cover_dest_dep_time&#x27;, &#x27;dew_point_2m&#x27;, &#x27;wind_speed_10m&#x27;, &#x27;wind_speed_10m_dest_dep_time&#x27;, &#x27;visibility_dest_dep_time&#x27;, &#x27;visibility&#x27;, &#x27;apparent_temperature&#x27;, &#x27;apparent_temperature_dest_dep_time&#x27;, &#x27;vapour_pressure_deficit&#x27;, &#x27;vapour_pressure_deficit_dest_dep_time&#x27;, &#x27;Flights&#x27;, &#x27;DOT_ID_Operating_Airline&#x27;, &#x27;Flight_Number_Operating_Airline&#x27;, &#x27;Aircraft_Engines&#x27;, &#x27;Aircraft_Seats&#x27;, &#x27;Is_Freighter&#x27;, &#x27;relative_humidity_2m_dest_dep_time&#x27;, &#x27;precipitation&#x27;, &#x27;showers&#x27;, &#x27;snow_depth&#x27;, &#x27;et0_fao_evapotranspiration&#x27;, &#x27;evapotranspiration&#x27;, &#x27;cloud_cover_high&#x27;, &#x27;cloud_cover_low&#x27;, &#x27;surface_pressure&#x27;, &#x27;weather_code&#x27;, &#x27;pressure_msl&#x27;, &#x27;wind_direction_10m&#x27;, &#x27;wind_gusts_10m&#x27;, &#x27;precipitation_dest_dep_time&#x27;, &#x27;showers_dest_dep_time&#x27;, &#x27;snow_depth_dest_dep_time&#x27;, &#x27;soil_moisture_0_to_1cm_dest_dep_time&#x27;, &#x27;evapotranspiration_dest_dep_time&#x27;, &#x27;cloud_cover_high_dest_dep_time&#x27;, &#x27;cloud_cover_low_dest_dep_time&#x27;, &#x27;weather_code_dest_dep_time&#x27;, &#x27;Operated_or_Branded_Code_Share_Partners&#x27;, &#x27;Year&#x27;, &#x27;Quarter&#x27;, &#x27;Marketing_Airline_Network&#x27;, &#x27;DayofMonth&#x27;, &#x27;DOT_ID_Marketing_Airline&#x27;, &#x27;Flight_Number_Marketing_Airline&#x27;, &#x27;OriginAirportSeqID&#x27;, &#x27;OriginCityMarketID&#x27;, &#x27;Origin&#x27;, &#x27;OriginCityName&#x27;, &#x27;OriginState&#x27;, &#x27;OriginStateFips&#x27;, &#x27;OriginStateName&#x27;, &#x27;OriginWac&#x27;, &#x27;DestAirportSeqID&#x27;, &#x27;DestCityMarketID&#x27;, &#x27;Dest&#x27;, &#x27;DestCityName&#x27;, &#x27;DestState&#x27;, &#x27;DestStateFips&#x27;, &#x27;DestStateName&#x27;, &#x27;DestWac&#x27;, &#x27;CRSDepTime&#x27;, &#x27;DepTimeBlk&#x27;, &#x27;CRSArrTime&#x27;, &#x27;ArrTimeBlk&#x27;, &#x27;DistanceGroup&#x27;, &#x27;Duplicate&#x27;, &#x27;Aircraft_Airline&#x27;, &#x27;Aircraft_ModelCode&#x27;, &#x27;Aircraft_Type&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-624\" type=\"checkbox\" ><label for=\"sk-estimator-id-624\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">drop</label><div class=\"sk-toggleable__content\"><pre>drop</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-625\" type=\"checkbox\" ><label for=\"sk-estimator-id-625\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre></pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-626\" type=\"checkbox\" ><label for=\"sk-estimator-id-626\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-627\" type=\"checkbox\" ><label for=\"sk-estimator-id-627\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ProgressLogger</label><div class=\"sk-toggleable__content\"><pre>ProgressLogger(name=&#x27;Feature Prep Complete&#x27;, total_rows=13000000)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-628\" type=\"checkbox\" ><label for=\"sk-estimator-id-628\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(n_components=75, random_state=42)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-629\" type=\"checkbox\" ><label for=\"sk-estimator-id-629\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ProgressLogger</label><div class=\"sk-toggleable__content\"><pre>ProgressLogger(name=&#x27;Pipeline Complete&#x27;, total_rows=13000000)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('initial_logger',\n",
       "                 ProgressLogger(name='Starting Pipeline', total_rows=13000000)),\n",
       "                ('delay_trend', DelayTrendEncoder()),\n",
       "                ('trend_logger',\n",
       "                 ProgressLogger(name='Delay Trend Complete',\n",
       "                                total_rows=13000000)),\n",
       "                ('tail_reuse', SameDayTailReuseEncoder()),\n",
       "                ('reuse_logger',\n",
       "                 ProgressLogger(name='Tail Reuse Complete',\n",
       "                                total_rows=13000000)),\n",
       "                ('turnaround_delay', T...\n",
       "                                                   'soil_temperature_0cm',\n",
       "                                                   'rain', 'rain_dest_dep_time',\n",
       "                                                   'dew_point_2m_dest_dep_time',\n",
       "                                                   'cloud_cover_mid',\n",
       "                                                   'cloud_cover', ...])],\n",
       "                                   verbose_feature_names_out=False)),\n",
       "                ('prep_logger',\n",
       "                 ProgressLogger(name='Feature Prep Complete',\n",
       "                                total_rows=13000000)),\n",
       "                ('select', PCA(n_components=75, random_state=42)),\n",
       "                ('final_logger',\n",
       "                 ProgressLogger(name='Pipeline Complete',\n",
       "                                total_rows=13000000))])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "numerical_features = [\n",
    "    'Distance', 'relative_humidity_2m', 'temperature_2m',\n",
    "    'Aircraft_Age', 'temperature_2m_dest_dep_time',\n",
    "    'snowfall', 'soil_moisture_0_to_1cm',\n",
    "    'snowfall_dest_dep_time', \n",
    "    'et0_fao_evapotranspiration_dest_dep_time',\n",
    "    'surface_pressure_dest_dep_time', 'pressure_msl_dest_dep_time',\n",
    "    'wind_direction_10m_dest_dep_time', 'wind_gusts_10m_dest_dep_time', 'CRSElapsedTime'\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    'DayOfWeek', 'Month',\n",
    "    'OriginAirportID',\n",
    "    'DestAirportID', 'Is_Holiday_Week', 'Operating_Airline '\n",
    "]\n",
    "\n",
    "drop_features = [\n",
    "            'Aircraft_Model', 'Aircraft_EngineType', 'Holiday',\n",
    "            'dep_datetime', 'Tail_Number', 'temperature_120m_dest_dep_time', \n",
    "            'temperature_180m_dest_dep_time', 'temperature_80m_dest_dep_time', 'temperature_180m', \n",
    "            'temperature_120m', 'temperature_80m', 'wind_speed_80m', 'wind_speed_120m',\n",
    "            'wind_speed_180m', 'wind_direction_80m', 'wind_direction_120m', 'wind_direction_180m',\n",
    "            'wind_speed_80m_dest_dep_time', 'wind_speed_120m_dest_dep_time', 'wind_speed_180m_dest_dep_time',\n",
    "            'wind_direction_80m_dest_dep_time', 'wind_direction_120m_dest_dep_time', 'wind_direction_180m_dest_dep_time', \n",
    "            'soil_temperature_0cm_dest_dep_time', 'soil_temperature_0cm', 'rain', 'rain_dest_dep_time', 'dew_point_2m_dest_dep_time', \n",
    "            'cloud_cover_mid', 'cloud_cover', 'cloud_cover_mid_dest_dep_time', 'cloud_cover_dest_dep_time', 'dew_point_2m', \n",
    "            'wind_speed_10m', 'wind_speed_10m_dest_dep_time', 'visibility_dest_dep_time', 'visibility', 'apparent_temperature', \n",
    "            'apparent_temperature_dest_dep_time', 'vapour_pressure_deficit', 'vapour_pressure_deficit_dest_dep_time', 'Flights',\n",
    "            'DOT_ID_Operating_Airline', 'Flight_Number_Operating_Airline', 'Aircraft_Engines', 'Aircraft_Seats', 'Is_Freighter',\n",
    "            'relative_humidity_2m_dest_dep_time', 'precipitation', 'showers', 'snow_depth', 'et0_fao_evapotranspiration',\n",
    "            'evapotranspiration', 'cloud_cover_high', 'cloud_cover_low', 'surface_pressure', 'weather_code', 'pressure_msl', \n",
    "            'wind_direction_10m', 'wind_gusts_10m', 'precipitation_dest_dep_time', 'showers_dest_dep_time', 'snow_depth_dest_dep_time',\n",
    "            'soil_moisture_0_to_1cm_dest_dep_time', 'evapotranspiration_dest_dep_time', 'cloud_cover_high_dest_dep_time',\n",
    "            'cloud_cover_low_dest_dep_time', 'weather_code_dest_dep_time', 'Operated_or_Branded_Code_Share_Partners', 'Year',\n",
    "            'Quarter', 'Marketing_Airline_Network', 'DayofMonth', 'DOT_ID_Marketing_Airline', 'Flight_Number_Marketing_Airline', \n",
    "            'OriginAirportSeqID', 'OriginCityMarketID', 'Origin', 'OriginCityName', 'OriginState', 'OriginStateFips', \n",
    "            'OriginStateName', 'OriginWac', 'DestAirportSeqID', 'DestCityMarketID', 'Dest', 'DestCityName', 'DestState', 'DestStateFips', \n",
    "            'DestStateName', 'DestWac', 'CRSDepTime', 'DepTimeBlk', 'CRSArrTime', 'ArrTimeBlk', 'DistanceGroup', 'Duplicate', \n",
    "            'Aircraft_Airline', 'Aircraft_ModelCode', 'Aircraft_Type'\n",
    "        ]\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('age_clipper', AgeClipper(max_age=56.9, column_name='Aircraft_Age')),\n",
    "    ('log1p_distance', ColumnTransformer([\n",
    "        ('log', FunctionTransformer(np.log1p), ['Distance', 'wind_gusts_10m_dest_dep_time'])\n",
    "    ], remainder='passthrough', verbose_feature_names_out=False)), \n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('OHE', ColumnTransformer([\n",
    "        ('top50', OneHotEncoder(handle_unknown='ignore', sparse_output=False, max_categories=51), ['OriginAirportID', 'DestAirportID']),\n",
    "        ('OHE' , OneHotEncoder(handle_unknown='ignore', sparse_output=False), ['DayOfWeek', 'Month', 'Operating_Airline '])\n",
    "    ]))\n",
    "])\n",
    "\n",
    "preprocessor = Pipeline([\n",
    "    ('initial_logger', ProgressLogger(total_rows=13000000, name='Starting Pipeline')),\n",
    "    \n",
    "    ('delay_trend', DelayTrendEncoder(\n",
    "        date_col='dep_datetime',\n",
    "        origin_col='OriginAirportID',\n",
    "        dest_col='DestAirportID',\n",
    "        status_col='Flight_Status',\n",
    "        output_col='Delay_Trend',\n",
    "        top_n_airports=15\n",
    "    )),\n",
    "    \n",
    "    ('trend_logger', ProgressLogger(total_rows=13000000, name='Delay Trend Complete')),\n",
    "    \n",
    "    ('tail_reuse', SameDayTailReuseEncoder(\n",
    "        datetime_col='dep_datetime',\n",
    "        tail_col='Tail_Number',\n",
    "        output_col='Same_Day_Tail_Reuse'\n",
    "    )),\n",
    "    \n",
    "    ('reuse_logger', ProgressLogger(total_rows=13000000, name='Tail Reuse Complete')),\n",
    "    \n",
    "    ('turnaround_delay', TurnaroundDelayEncoder(\n",
    "        datetime_col='dep_datetime',\n",
    "        dep_time_col='CRSDepTime',\n",
    "        arr_time_col='CRSArrTime',\n",
    "        tail_col='Tail_Number',\n",
    "        output_prefix=''\n",
    "    )),\n",
    "    \n",
    "    ('turnaround_logger', ProgressLogger(total_rows=13000000, name='Turnaround Delay Complete')),\n",
    "    \n",
    "    ('slack_time', SlackTimeEncoder(\n",
    "        arr_col='CRSArrTime',\n",
    "        elapsed_col='CRSElapsedTime',\n",
    "        output_col='Slack_Time'\n",
    "    )),\n",
    "    \n",
    "    ('slack_logger', ProgressLogger(total_rows=13000000, name='Slack Time Complete')),\n",
    "    \n",
    "    ('feature_prep', ColumnTransformer([\n",
    "        ('numeric', numeric_transformer, numerical_features),\n",
    "        ('categorical', categorical_transformer, categorical_features),\n",
    "        ('drop', 'drop', drop_features)\n",
    "    ], remainder='passthrough', verbose_feature_names_out=False, n_jobs=16)),\n",
    "    \n",
    "    ('prep_logger', ProgressLogger(total_rows=13000000, name='Feature Prep Complete')),\n",
    "    ('select', PCA(\n",
    "        n_components=75,\n",
    "        random_state=42,\n",
    "    )),\n",
    "    ('final_logger', ProgressLogger(total_rows=13000000, name='Pipeline Complete'))\n",
    "])\n",
    "# so that I dont forget, dep_datetime is dropped because of redundancy\n",
    "\n",
    "preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pipeline processing started on 13,000,000 rows\n",
      "Starting Pipeline: 0.8% complete (100,000/13,000,000 rows) - Est. remaining: 0.0s\n",
      "Delay Trend Complete processing started on 13,000,000 rows\n",
      "Delay Trend Complete: 0.8% complete (100,000/13,000,000 rows) - Est. remaining: 0.0s\n",
      "Tail Reuse Complete processing started on 13,000,000 rows\n",
      "Tail Reuse Complete: 0.8% complete (100,000/13,000,000 rows) - Est. remaining: 0.0s\n",
      "Turnaround Delay Complete processing started on 13,000,000 rows\n",
      "Turnaround Delay Complete: 0.8% complete (100,000/13,000,000 rows) - Est. remaining: 0.0s\n",
      "Slack Time Complete processing started on 13,000,000 rows\n",
      "Slack Time Complete: 0.8% complete (100,000/13,000,000 rows) - Est. remaining: 0.0s\n",
      "Feature Prep Complete processing started on 13,000,000 rows\n",
      "Feature Prep Complete: 0.8% complete (100,000/13,000,000 rows) - Est. remaining: 0.0s\n",
      "Pipeline Complete processing started on 13,000,000 rows\n",
      "Pipeline Complete: 0.8% complete (100,000/13,000,000 rows) - Est. remaining: 0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pca0</th>\n",
       "      <th>pca1</th>\n",
       "      <th>pca2</th>\n",
       "      <th>pca3</th>\n",
       "      <th>pca4</th>\n",
       "      <th>pca5</th>\n",
       "      <th>pca6</th>\n",
       "      <th>pca7</th>\n",
       "      <th>pca8</th>\n",
       "      <th>pca9</th>\n",
       "      <th>pca10</th>\n",
       "      <th>pca11</th>\n",
       "      <th>pca12</th>\n",
       "      <th>pca13</th>\n",
       "      <th>pca14</th>\n",
       "      <th>pca15</th>\n",
       "      <th>pca16</th>\n",
       "      <th>pca17</th>\n",
       "      <th>pca18</th>\n",
       "      <th>pca19</th>\n",
       "      <th>pca20</th>\n",
       "      <th>pca21</th>\n",
       "      <th>pca22</th>\n",
       "      <th>pca23</th>\n",
       "      <th>pca24</th>\n",
       "      <th>pca25</th>\n",
       "      <th>pca26</th>\n",
       "      <th>pca27</th>\n",
       "      <th>pca28</th>\n",
       "      <th>pca29</th>\n",
       "      <th>pca30</th>\n",
       "      <th>pca31</th>\n",
       "      <th>pca32</th>\n",
       "      <th>pca33</th>\n",
       "      <th>pca34</th>\n",
       "      <th>pca35</th>\n",
       "      <th>pca36</th>\n",
       "      <th>pca37</th>\n",
       "      <th>pca38</th>\n",
       "      <th>pca39</th>\n",
       "      <th>pca40</th>\n",
       "      <th>pca41</th>\n",
       "      <th>pca42</th>\n",
       "      <th>pca43</th>\n",
       "      <th>pca44</th>\n",
       "      <th>pca45</th>\n",
       "      <th>pca46</th>\n",
       "      <th>pca47</th>\n",
       "      <th>pca48</th>\n",
       "      <th>pca49</th>\n",
       "      <th>pca50</th>\n",
       "      <th>pca51</th>\n",
       "      <th>pca52</th>\n",
       "      <th>pca53</th>\n",
       "      <th>pca54</th>\n",
       "      <th>pca55</th>\n",
       "      <th>pca56</th>\n",
       "      <th>pca57</th>\n",
       "      <th>pca58</th>\n",
       "      <th>pca59</th>\n",
       "      <th>pca60</th>\n",
       "      <th>pca61</th>\n",
       "      <th>pca62</th>\n",
       "      <th>pca63</th>\n",
       "      <th>pca64</th>\n",
       "      <th>pca65</th>\n",
       "      <th>pca66</th>\n",
       "      <th>pca67</th>\n",
       "      <th>pca68</th>\n",
       "      <th>pca69</th>\n",
       "      <th>pca70</th>\n",
       "      <th>pca71</th>\n",
       "      <th>pca72</th>\n",
       "      <th>pca73</th>\n",
       "      <th>pca74</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84341</th>\n",
       "      <td>369.406386</td>\n",
       "      <td>-9.608162</td>\n",
       "      <td>0.179558</td>\n",
       "      <td>-0.062166</td>\n",
       "      <td>0.596542</td>\n",
       "      <td>0.550946</td>\n",
       "      <td>-0.264805</td>\n",
       "      <td>-0.513814</td>\n",
       "      <td>0.620569</td>\n",
       "      <td>-0.494372</td>\n",
       "      <td>-0.033893</td>\n",
       "      <td>-0.995415</td>\n",
       "      <td>-0.787977</td>\n",
       "      <td>1.142734</td>\n",
       "      <td>0.158463</td>\n",
       "      <td>0.712329</td>\n",
       "      <td>0.101890</td>\n",
       "      <td>0.226943</td>\n",
       "      <td>0.124162</td>\n",
       "      <td>-0.294356</td>\n",
       "      <td>0.021556</td>\n",
       "      <td>0.094708</td>\n",
       "      <td>0.192587</td>\n",
       "      <td>0.501935</td>\n",
       "      <td>1.026374</td>\n",
       "      <td>-0.284926</td>\n",
       "      <td>-0.768755</td>\n",
       "      <td>-0.461073</td>\n",
       "      <td>-0.015108</td>\n",
       "      <td>-0.096331</td>\n",
       "      <td>-0.181976</td>\n",
       "      <td>-0.309769</td>\n",
       "      <td>-0.666685</td>\n",
       "      <td>0.297711</td>\n",
       "      <td>0.118579</td>\n",
       "      <td>-0.368372</td>\n",
       "      <td>0.384661</td>\n",
       "      <td>0.169260</td>\n",
       "      <td>0.034277</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>-0.030203</td>\n",
       "      <td>-0.003334</td>\n",
       "      <td>-0.175433</td>\n",
       "      <td>-0.079776</td>\n",
       "      <td>-0.057985</td>\n",
       "      <td>-0.054252</td>\n",
       "      <td>-0.127423</td>\n",
       "      <td>-0.039765</td>\n",
       "      <td>0.029790</td>\n",
       "      <td>-0.034567</td>\n",
       "      <td>0.015400</td>\n",
       "      <td>-0.125174</td>\n",
       "      <td>-0.107160</td>\n",
       "      <td>0.091005</td>\n",
       "      <td>0.008068</td>\n",
       "      <td>-0.057949</td>\n",
       "      <td>-0.046862</td>\n",
       "      <td>-0.089729</td>\n",
       "      <td>-0.060579</td>\n",
       "      <td>0.085124</td>\n",
       "      <td>0.074155</td>\n",
       "      <td>0.014692</td>\n",
       "      <td>0.126393</td>\n",
       "      <td>-0.077876</td>\n",
       "      <td>-0.009426</td>\n",
       "      <td>0.055077</td>\n",
       "      <td>-0.084227</td>\n",
       "      <td>-0.086071</td>\n",
       "      <td>0.014726</td>\n",
       "      <td>0.175574</td>\n",
       "      <td>-0.087826</td>\n",
       "      <td>0.090813</td>\n",
       "      <td>0.013114</td>\n",
       "      <td>-0.080915</td>\n",
       "      <td>0.057627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37492</th>\n",
       "      <td>-653.419003</td>\n",
       "      <td>-28.480496</td>\n",
       "      <td>1.441660</td>\n",
       "      <td>0.403025</td>\n",
       "      <td>-0.210278</td>\n",
       "      <td>1.273879</td>\n",
       "      <td>1.188273</td>\n",
       "      <td>0.604383</td>\n",
       "      <td>-0.605486</td>\n",
       "      <td>-0.228558</td>\n",
       "      <td>-0.084783</td>\n",
       "      <td>-0.375250</td>\n",
       "      <td>-0.546711</td>\n",
       "      <td>0.029999</td>\n",
       "      <td>-0.257772</td>\n",
       "      <td>0.389423</td>\n",
       "      <td>0.653168</td>\n",
       "      <td>0.186674</td>\n",
       "      <td>0.678997</td>\n",
       "      <td>0.421090</td>\n",
       "      <td>-0.288825</td>\n",
       "      <td>-0.247507</td>\n",
       "      <td>-0.250112</td>\n",
       "      <td>-0.166262</td>\n",
       "      <td>0.223529</td>\n",
       "      <td>-0.114127</td>\n",
       "      <td>-0.280239</td>\n",
       "      <td>-0.372612</td>\n",
       "      <td>0.040899</td>\n",
       "      <td>0.430109</td>\n",
       "      <td>0.691879</td>\n",
       "      <td>0.226532</td>\n",
       "      <td>-0.182182</td>\n",
       "      <td>-0.098686</td>\n",
       "      <td>-0.077041</td>\n",
       "      <td>-0.099270</td>\n",
       "      <td>0.171210</td>\n",
       "      <td>0.110906</td>\n",
       "      <td>0.083219</td>\n",
       "      <td>0.154603</td>\n",
       "      <td>0.012287</td>\n",
       "      <td>-0.048274</td>\n",
       "      <td>-0.041235</td>\n",
       "      <td>-0.006061</td>\n",
       "      <td>0.023991</td>\n",
       "      <td>-0.071345</td>\n",
       "      <td>0.000542</td>\n",
       "      <td>-0.083028</td>\n",
       "      <td>-0.017518</td>\n",
       "      <td>0.050702</td>\n",
       "      <td>-0.095135</td>\n",
       "      <td>-0.087924</td>\n",
       "      <td>0.073731</td>\n",
       "      <td>0.044353</td>\n",
       "      <td>0.019871</td>\n",
       "      <td>-0.037660</td>\n",
       "      <td>-0.044624</td>\n",
       "      <td>-0.133056</td>\n",
       "      <td>0.001022</td>\n",
       "      <td>0.071558</td>\n",
       "      <td>0.031961</td>\n",
       "      <td>0.058267</td>\n",
       "      <td>0.180589</td>\n",
       "      <td>-0.026137</td>\n",
       "      <td>0.029428</td>\n",
       "      <td>-0.001374</td>\n",
       "      <td>-0.070153</td>\n",
       "      <td>0.008106</td>\n",
       "      <td>0.048121</td>\n",
       "      <td>0.252027</td>\n",
       "      <td>-0.103192</td>\n",
       "      <td>0.021629</td>\n",
       "      <td>0.053371</td>\n",
       "      <td>0.068848</td>\n",
       "      <td>0.073725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55696</th>\n",
       "      <td>170.439372</td>\n",
       "      <td>-13.279279</td>\n",
       "      <td>0.424960</td>\n",
       "      <td>-0.865623</td>\n",
       "      <td>0.010005</td>\n",
       "      <td>1.300962</td>\n",
       "      <td>-0.513658</td>\n",
       "      <td>-1.093548</td>\n",
       "      <td>0.485868</td>\n",
       "      <td>-0.025464</td>\n",
       "      <td>-0.085488</td>\n",
       "      <td>-0.288770</td>\n",
       "      <td>-0.799541</td>\n",
       "      <td>1.098683</td>\n",
       "      <td>-0.744922</td>\n",
       "      <td>0.173100</td>\n",
       "      <td>1.028667</td>\n",
       "      <td>0.262057</td>\n",
       "      <td>0.056733</td>\n",
       "      <td>-0.253986</td>\n",
       "      <td>0.099261</td>\n",
       "      <td>0.747357</td>\n",
       "      <td>-0.514250</td>\n",
       "      <td>-0.133495</td>\n",
       "      <td>0.059222</td>\n",
       "      <td>-0.132035</td>\n",
       "      <td>-0.246426</td>\n",
       "      <td>-0.506664</td>\n",
       "      <td>0.039164</td>\n",
       "      <td>-0.126774</td>\n",
       "      <td>-0.426497</td>\n",
       "      <td>0.658513</td>\n",
       "      <td>-0.185086</td>\n",
       "      <td>-0.121259</td>\n",
       "      <td>-0.036137</td>\n",
       "      <td>0.055114</td>\n",
       "      <td>0.065869</td>\n",
       "      <td>0.195934</td>\n",
       "      <td>0.166376</td>\n",
       "      <td>0.117271</td>\n",
       "      <td>0.034822</td>\n",
       "      <td>-0.342663</td>\n",
       "      <td>0.052657</td>\n",
       "      <td>0.039262</td>\n",
       "      <td>0.303700</td>\n",
       "      <td>0.356481</td>\n",
       "      <td>0.250798</td>\n",
       "      <td>0.161384</td>\n",
       "      <td>0.403531</td>\n",
       "      <td>-0.172050</td>\n",
       "      <td>-0.044468</td>\n",
       "      <td>-0.047200</td>\n",
       "      <td>-0.140299</td>\n",
       "      <td>0.012314</td>\n",
       "      <td>0.014660</td>\n",
       "      <td>-0.060238</td>\n",
       "      <td>-0.096416</td>\n",
       "      <td>-0.046480</td>\n",
       "      <td>0.005344</td>\n",
       "      <td>-0.025261</td>\n",
       "      <td>0.164102</td>\n",
       "      <td>0.028976</td>\n",
       "      <td>0.127662</td>\n",
       "      <td>0.009735</td>\n",
       "      <td>0.052783</td>\n",
       "      <td>0.073739</td>\n",
       "      <td>-0.079384</td>\n",
       "      <td>-0.065289</td>\n",
       "      <td>-0.019136</td>\n",
       "      <td>0.220117</td>\n",
       "      <td>-0.083960</td>\n",
       "      <td>0.039033</td>\n",
       "      <td>-0.004053</td>\n",
       "      <td>-0.095916</td>\n",
       "      <td>0.008449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8859</th>\n",
       "      <td>-290.482590</td>\n",
       "      <td>-21.784067</td>\n",
       "      <td>0.993400</td>\n",
       "      <td>-1.629461</td>\n",
       "      <td>0.419143</td>\n",
       "      <td>-0.613777</td>\n",
       "      <td>0.709189</td>\n",
       "      <td>0.458208</td>\n",
       "      <td>0.372986</td>\n",
       "      <td>-0.385654</td>\n",
       "      <td>0.120670</td>\n",
       "      <td>-0.548422</td>\n",
       "      <td>0.245208</td>\n",
       "      <td>-0.089310</td>\n",
       "      <td>-0.753674</td>\n",
       "      <td>-0.209001</td>\n",
       "      <td>0.088275</td>\n",
       "      <td>0.399016</td>\n",
       "      <td>-0.346035</td>\n",
       "      <td>-0.480131</td>\n",
       "      <td>-0.638432</td>\n",
       "      <td>-0.238420</td>\n",
       "      <td>-0.371723</td>\n",
       "      <td>-0.266506</td>\n",
       "      <td>0.720798</td>\n",
       "      <td>-0.196218</td>\n",
       "      <td>-0.650979</td>\n",
       "      <td>-0.475358</td>\n",
       "      <td>-0.506042</td>\n",
       "      <td>0.672654</td>\n",
       "      <td>-0.368695</td>\n",
       "      <td>-0.191316</td>\n",
       "      <td>0.015183</td>\n",
       "      <td>-0.147292</td>\n",
       "      <td>0.008653</td>\n",
       "      <td>-0.275956</td>\n",
       "      <td>-0.114787</td>\n",
       "      <td>-0.227552</td>\n",
       "      <td>-0.160119</td>\n",
       "      <td>0.035556</td>\n",
       "      <td>-0.016678</td>\n",
       "      <td>-0.058753</td>\n",
       "      <td>-0.150326</td>\n",
       "      <td>-0.065618</td>\n",
       "      <td>-0.018790</td>\n",
       "      <td>-0.114727</td>\n",
       "      <td>-0.111390</td>\n",
       "      <td>-0.063124</td>\n",
       "      <td>0.006538</td>\n",
       "      <td>0.039179</td>\n",
       "      <td>-0.042315</td>\n",
       "      <td>-0.108234</td>\n",
       "      <td>-0.046616</td>\n",
       "      <td>0.055069</td>\n",
       "      <td>0.029809</td>\n",
       "      <td>-0.046890</td>\n",
       "      <td>-0.034855</td>\n",
       "      <td>-0.129810</td>\n",
       "      <td>0.011569</td>\n",
       "      <td>0.051555</td>\n",
       "      <td>0.067567</td>\n",
       "      <td>0.008258</td>\n",
       "      <td>0.104265</td>\n",
       "      <td>-0.090196</td>\n",
       "      <td>0.008584</td>\n",
       "      <td>0.004241</td>\n",
       "      <td>-0.035065</td>\n",
       "      <td>-0.079586</td>\n",
       "      <td>-0.043614</td>\n",
       "      <td>0.197611</td>\n",
       "      <td>-0.066696</td>\n",
       "      <td>0.012070</td>\n",
       "      <td>-0.017909</td>\n",
       "      <td>-0.084068</td>\n",
       "      <td>0.058986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63927</th>\n",
       "      <td>180.438408</td>\n",
       "      <td>-13.094857</td>\n",
       "      <td>0.412573</td>\n",
       "      <td>-0.265649</td>\n",
       "      <td>0.577157</td>\n",
       "      <td>-0.261206</td>\n",
       "      <td>-0.811060</td>\n",
       "      <td>-0.919617</td>\n",
       "      <td>0.377864</td>\n",
       "      <td>0.138909</td>\n",
       "      <td>0.088343</td>\n",
       "      <td>0.432462</td>\n",
       "      <td>-0.557569</td>\n",
       "      <td>1.044393</td>\n",
       "      <td>0.444634</td>\n",
       "      <td>0.150587</td>\n",
       "      <td>0.707015</td>\n",
       "      <td>0.235432</td>\n",
       "      <td>0.749725</td>\n",
       "      <td>0.355320</td>\n",
       "      <td>-0.240020</td>\n",
       "      <td>-0.224256</td>\n",
       "      <td>-0.283004</td>\n",
       "      <td>-0.154981</td>\n",
       "      <td>0.301620</td>\n",
       "      <td>-0.172372</td>\n",
       "      <td>-0.339936</td>\n",
       "      <td>-0.412389</td>\n",
       "      <td>-0.429822</td>\n",
       "      <td>0.688057</td>\n",
       "      <td>-0.347213</td>\n",
       "      <td>-0.164563</td>\n",
       "      <td>0.003498</td>\n",
       "      <td>-0.054972</td>\n",
       "      <td>0.051276</td>\n",
       "      <td>-0.063025</td>\n",
       "      <td>-0.010599</td>\n",
       "      <td>-0.217660</td>\n",
       "      <td>-0.095197</td>\n",
       "      <td>0.175298</td>\n",
       "      <td>0.000363</td>\n",
       "      <td>-0.000030</td>\n",
       "      <td>-0.073339</td>\n",
       "      <td>-0.016454</td>\n",
       "      <td>-0.020901</td>\n",
       "      <td>-0.027462</td>\n",
       "      <td>-0.004294</td>\n",
       "      <td>-0.118264</td>\n",
       "      <td>-0.010297</td>\n",
       "      <td>0.018758</td>\n",
       "      <td>0.003588</td>\n",
       "      <td>-0.100117</td>\n",
       "      <td>0.007330</td>\n",
       "      <td>0.107345</td>\n",
       "      <td>0.010003</td>\n",
       "      <td>-0.059084</td>\n",
       "      <td>-0.070466</td>\n",
       "      <td>-0.081514</td>\n",
       "      <td>-0.054371</td>\n",
       "      <td>0.087490</td>\n",
       "      <td>0.065572</td>\n",
       "      <td>0.059322</td>\n",
       "      <td>0.166721</td>\n",
       "      <td>-0.063915</td>\n",
       "      <td>-0.006499</td>\n",
       "      <td>0.032121</td>\n",
       "      <td>-0.086406</td>\n",
       "      <td>-0.141783</td>\n",
       "      <td>0.009698</td>\n",
       "      <td>0.246450</td>\n",
       "      <td>-0.049105</td>\n",
       "      <td>0.167784</td>\n",
       "      <td>0.044545</td>\n",
       "      <td>-0.027023</td>\n",
       "      <td>0.044475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56457</th>\n",
       "      <td>272.423439</td>\n",
       "      <td>-11.397601</td>\n",
       "      <td>0.299051</td>\n",
       "      <td>1.049562</td>\n",
       "      <td>0.887998</td>\n",
       "      <td>-0.154112</td>\n",
       "      <td>-2.259923</td>\n",
       "      <td>-1.174667</td>\n",
       "      <td>0.939465</td>\n",
       "      <td>-0.324289</td>\n",
       "      <td>0.142413</td>\n",
       "      <td>-0.888163</td>\n",
       "      <td>-0.466841</td>\n",
       "      <td>0.914062</td>\n",
       "      <td>0.226891</td>\n",
       "      <td>0.969369</td>\n",
       "      <td>0.055987</td>\n",
       "      <td>0.235886</td>\n",
       "      <td>-0.334974</td>\n",
       "      <td>-0.548431</td>\n",
       "      <td>-0.665348</td>\n",
       "      <td>-0.257553</td>\n",
       "      <td>-0.384939</td>\n",
       "      <td>-0.269167</td>\n",
       "      <td>0.729279</td>\n",
       "      <td>-0.140257</td>\n",
       "      <td>-0.722307</td>\n",
       "      <td>-0.379208</td>\n",
       "      <td>0.056280</td>\n",
       "      <td>-0.097889</td>\n",
       "      <td>0.027030</td>\n",
       "      <td>0.163891</td>\n",
       "      <td>-0.118186</td>\n",
       "      <td>-0.153676</td>\n",
       "      <td>-0.642712</td>\n",
       "      <td>-0.230875</td>\n",
       "      <td>0.210449</td>\n",
       "      <td>-0.495717</td>\n",
       "      <td>-0.340380</td>\n",
       "      <td>-0.014402</td>\n",
       "      <td>-0.008586</td>\n",
       "      <td>-0.050982</td>\n",
       "      <td>-0.152503</td>\n",
       "      <td>-0.065527</td>\n",
       "      <td>-0.081110</td>\n",
       "      <td>-0.031524</td>\n",
       "      <td>-0.077445</td>\n",
       "      <td>-0.031281</td>\n",
       "      <td>0.080550</td>\n",
       "      <td>-0.029484</td>\n",
       "      <td>-0.057563</td>\n",
       "      <td>-0.133563</td>\n",
       "      <td>-0.067893</td>\n",
       "      <td>0.058199</td>\n",
       "      <td>0.012539</td>\n",
       "      <td>-0.022202</td>\n",
       "      <td>-0.038458</td>\n",
       "      <td>-0.087365</td>\n",
       "      <td>-0.064144</td>\n",
       "      <td>0.106497</td>\n",
       "      <td>0.048255</td>\n",
       "      <td>-0.001019</td>\n",
       "      <td>0.165281</td>\n",
       "      <td>0.004340</td>\n",
       "      <td>0.044619</td>\n",
       "      <td>0.014873</td>\n",
       "      <td>-0.085760</td>\n",
       "      <td>-0.069628</td>\n",
       "      <td>0.057621</td>\n",
       "      <td>0.149355</td>\n",
       "      <td>-0.067925</td>\n",
       "      <td>0.155274</td>\n",
       "      <td>0.021784</td>\n",
       "      <td>-0.076124</td>\n",
       "      <td>0.026221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85107</th>\n",
       "      <td>-380.465280</td>\n",
       "      <td>-23.444177</td>\n",
       "      <td>1.104279</td>\n",
       "      <td>1.295955</td>\n",
       "      <td>-0.199383</td>\n",
       "      <td>-1.560158</td>\n",
       "      <td>0.007369</td>\n",
       "      <td>0.281071</td>\n",
       "      <td>0.204463</td>\n",
       "      <td>-0.168330</td>\n",
       "      <td>-0.035494</td>\n",
       "      <td>-0.348671</td>\n",
       "      <td>0.288222</td>\n",
       "      <td>-0.674397</td>\n",
       "      <td>-0.276337</td>\n",
       "      <td>-0.562774</td>\n",
       "      <td>-0.797003</td>\n",
       "      <td>0.141040</td>\n",
       "      <td>0.098534</td>\n",
       "      <td>-0.194190</td>\n",
       "      <td>0.007139</td>\n",
       "      <td>0.075563</td>\n",
       "      <td>0.033263</td>\n",
       "      <td>-0.033686</td>\n",
       "      <td>0.436093</td>\n",
       "      <td>0.903622</td>\n",
       "      <td>-0.008902</td>\n",
       "      <td>-0.095733</td>\n",
       "      <td>0.048257</td>\n",
       "      <td>-0.077473</td>\n",
       "      <td>0.044971</td>\n",
       "      <td>0.213805</td>\n",
       "      <td>-0.135484</td>\n",
       "      <td>-0.122858</td>\n",
       "      <td>-0.574807</td>\n",
       "      <td>-0.037961</td>\n",
       "      <td>0.227216</td>\n",
       "      <td>-0.323514</td>\n",
       "      <td>-0.273558</td>\n",
       "      <td>0.031939</td>\n",
       "      <td>-0.050307</td>\n",
       "      <td>0.131515</td>\n",
       "      <td>-0.210701</td>\n",
       "      <td>0.075566</td>\n",
       "      <td>-0.013212</td>\n",
       "      <td>0.026382</td>\n",
       "      <td>-0.202430</td>\n",
       "      <td>0.061240</td>\n",
       "      <td>-0.029218</td>\n",
       "      <td>0.008849</td>\n",
       "      <td>-0.007954</td>\n",
       "      <td>-0.104001</td>\n",
       "      <td>-0.174207</td>\n",
       "      <td>0.246146</td>\n",
       "      <td>0.089714</td>\n",
       "      <td>-0.110091</td>\n",
       "      <td>-0.099578</td>\n",
       "      <td>-0.117778</td>\n",
       "      <td>0.055855</td>\n",
       "      <td>-0.183307</td>\n",
       "      <td>0.344112</td>\n",
       "      <td>0.086584</td>\n",
       "      <td>-0.461102</td>\n",
       "      <td>0.581721</td>\n",
       "      <td>-0.338702</td>\n",
       "      <td>-0.239570</td>\n",
       "      <td>-0.134775</td>\n",
       "      <td>0.220266</td>\n",
       "      <td>0.113473</td>\n",
       "      <td>0.109242</td>\n",
       "      <td>0.026682</td>\n",
       "      <td>0.104874</td>\n",
       "      <td>0.059077</td>\n",
       "      <td>0.133471</td>\n",
       "      <td>0.047502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>809.330375</td>\n",
       "      <td>-1.488648</td>\n",
       "      <td>-0.363055</td>\n",
       "      <td>0.232749</td>\n",
       "      <td>-1.304640</td>\n",
       "      <td>-1.616957</td>\n",
       "      <td>-0.133677</td>\n",
       "      <td>0.103888</td>\n",
       "      <td>0.489555</td>\n",
       "      <td>-0.146001</td>\n",
       "      <td>-0.124768</td>\n",
       "      <td>-0.456670</td>\n",
       "      <td>0.412055</td>\n",
       "      <td>-0.507539</td>\n",
       "      <td>-0.065535</td>\n",
       "      <td>-0.367373</td>\n",
       "      <td>0.036662</td>\n",
       "      <td>0.113159</td>\n",
       "      <td>0.021222</td>\n",
       "      <td>-0.113348</td>\n",
       "      <td>0.092393</td>\n",
       "      <td>0.748955</td>\n",
       "      <td>-0.370062</td>\n",
       "      <td>0.017586</td>\n",
       "      <td>-0.303835</td>\n",
       "      <td>-0.159816</td>\n",
       "      <td>1.042052</td>\n",
       "      <td>-0.388768</td>\n",
       "      <td>0.079151</td>\n",
       "      <td>-0.129915</td>\n",
       "      <td>0.051711</td>\n",
       "      <td>0.218511</td>\n",
       "      <td>-0.161141</td>\n",
       "      <td>-0.164185</td>\n",
       "      <td>-0.598167</td>\n",
       "      <td>-0.052229</td>\n",
       "      <td>0.246792</td>\n",
       "      <td>-0.301275</td>\n",
       "      <td>-0.293132</td>\n",
       "      <td>-0.320089</td>\n",
       "      <td>0.004867</td>\n",
       "      <td>0.163151</td>\n",
       "      <td>-0.268619</td>\n",
       "      <td>0.100604</td>\n",
       "      <td>-0.047159</td>\n",
       "      <td>0.111273</td>\n",
       "      <td>-0.287029</td>\n",
       "      <td>0.028149</td>\n",
       "      <td>-0.178728</td>\n",
       "      <td>0.060060</td>\n",
       "      <td>0.037626</td>\n",
       "      <td>-0.044209</td>\n",
       "      <td>-0.180846</td>\n",
       "      <td>0.468412</td>\n",
       "      <td>1.585908</td>\n",
       "      <td>0.811831</td>\n",
       "      <td>0.496688</td>\n",
       "      <td>0.366944</td>\n",
       "      <td>0.106318</td>\n",
       "      <td>-0.073995</td>\n",
       "      <td>0.195277</td>\n",
       "      <td>-0.023088</td>\n",
       "      <td>-0.368545</td>\n",
       "      <td>0.209962</td>\n",
       "      <td>-0.553170</td>\n",
       "      <td>-0.127615</td>\n",
       "      <td>-0.141667</td>\n",
       "      <td>0.106703</td>\n",
       "      <td>0.182462</td>\n",
       "      <td>0.067878</td>\n",
       "      <td>-0.107040</td>\n",
       "      <td>0.126785</td>\n",
       "      <td>0.155378</td>\n",
       "      <td>0.051131</td>\n",
       "      <td>0.086904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56102</th>\n",
       "      <td>373.657521</td>\n",
       "      <td>573.614184</td>\n",
       "      <td>7.936077</td>\n",
       "      <td>-0.864480</td>\n",
       "      <td>3.430380</td>\n",
       "      <td>0.627452</td>\n",
       "      <td>0.906955</td>\n",
       "      <td>-1.130587</td>\n",
       "      <td>-0.006697</td>\n",
       "      <td>0.072143</td>\n",
       "      <td>0.457770</td>\n",
       "      <td>1.311895</td>\n",
       "      <td>0.721516</td>\n",
       "      <td>-0.216496</td>\n",
       "      <td>-1.143928</td>\n",
       "      <td>-0.488288</td>\n",
       "      <td>0.797072</td>\n",
       "      <td>0.756073</td>\n",
       "      <td>0.154506</td>\n",
       "      <td>-0.408371</td>\n",
       "      <td>0.108292</td>\n",
       "      <td>0.776406</td>\n",
       "      <td>-0.547547</td>\n",
       "      <td>-0.261748</td>\n",
       "      <td>0.582770</td>\n",
       "      <td>-0.235049</td>\n",
       "      <td>-0.100535</td>\n",
       "      <td>0.760732</td>\n",
       "      <td>0.085789</td>\n",
       "      <td>-0.038428</td>\n",
       "      <td>0.075302</td>\n",
       "      <td>0.208538</td>\n",
       "      <td>-0.111765</td>\n",
       "      <td>-0.114521</td>\n",
       "      <td>-0.548806</td>\n",
       "      <td>-0.180342</td>\n",
       "      <td>0.315016</td>\n",
       "      <td>-0.383090</td>\n",
       "      <td>-0.312783</td>\n",
       "      <td>-0.003132</td>\n",
       "      <td>0.062059</td>\n",
       "      <td>0.195384</td>\n",
       "      <td>-0.066369</td>\n",
       "      <td>0.138277</td>\n",
       "      <td>0.073050</td>\n",
       "      <td>0.005418</td>\n",
       "      <td>-0.259615</td>\n",
       "      <td>-0.119560</td>\n",
       "      <td>-0.101697</td>\n",
       "      <td>-0.077715</td>\n",
       "      <td>0.228720</td>\n",
       "      <td>0.052273</td>\n",
       "      <td>-0.056388</td>\n",
       "      <td>0.228059</td>\n",
       "      <td>1.216312</td>\n",
       "      <td>0.406900</td>\n",
       "      <td>0.325878</td>\n",
       "      <td>0.295633</td>\n",
       "      <td>0.027026</td>\n",
       "      <td>0.161872</td>\n",
       "      <td>0.251420</td>\n",
       "      <td>-0.505005</td>\n",
       "      <td>-0.299936</td>\n",
       "      <td>-0.205255</td>\n",
       "      <td>-0.005661</td>\n",
       "      <td>0.120301</td>\n",
       "      <td>-0.049197</td>\n",
       "      <td>-0.002847</td>\n",
       "      <td>-0.179501</td>\n",
       "      <td>0.054250</td>\n",
       "      <td>-0.127216</td>\n",
       "      <td>-0.100144</td>\n",
       "      <td>-0.194842</td>\n",
       "      <td>0.104562</td>\n",
       "      <td>-0.057194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45103</th>\n",
       "      <td>-444.023645</td>\n",
       "      <td>973.702063</td>\n",
       "      <td>-122.741852</td>\n",
       "      <td>2.799582</td>\n",
       "      <td>-0.741432</td>\n",
       "      <td>-1.279848</td>\n",
       "      <td>-0.972672</td>\n",
       "      <td>-0.044527</td>\n",
       "      <td>-0.384021</td>\n",
       "      <td>0.408903</td>\n",
       "      <td>0.005179</td>\n",
       "      <td>0.573463</td>\n",
       "      <td>0.349042</td>\n",
       "      <td>-0.511426</td>\n",
       "      <td>-0.502209</td>\n",
       "      <td>-0.101678</td>\n",
       "      <td>0.604210</td>\n",
       "      <td>0.399284</td>\n",
       "      <td>0.048875</td>\n",
       "      <td>-0.198011</td>\n",
       "      <td>0.103783</td>\n",
       "      <td>0.772170</td>\n",
       "      <td>-0.447462</td>\n",
       "      <td>-0.070181</td>\n",
       "      <td>-0.023569</td>\n",
       "      <td>-0.127795</td>\n",
       "      <td>0.047722</td>\n",
       "      <td>0.128625</td>\n",
       "      <td>0.099692</td>\n",
       "      <td>-0.094534</td>\n",
       "      <td>0.055521</td>\n",
       "      <td>0.184291</td>\n",
       "      <td>-0.146245</td>\n",
       "      <td>-0.152848</td>\n",
       "      <td>-0.589068</td>\n",
       "      <td>-0.174715</td>\n",
       "      <td>0.300705</td>\n",
       "      <td>-0.337735</td>\n",
       "      <td>-0.241285</td>\n",
       "      <td>0.036835</td>\n",
       "      <td>0.019475</td>\n",
       "      <td>0.054699</td>\n",
       "      <td>-0.053229</td>\n",
       "      <td>0.018926</td>\n",
       "      <td>0.052906</td>\n",
       "      <td>0.027899</td>\n",
       "      <td>-0.085761</td>\n",
       "      <td>-0.038867</td>\n",
       "      <td>-0.002102</td>\n",
       "      <td>0.083255</td>\n",
       "      <td>-0.069832</td>\n",
       "      <td>-0.094290</td>\n",
       "      <td>-0.027839</td>\n",
       "      <td>0.219398</td>\n",
       "      <td>0.919810</td>\n",
       "      <td>0.416703</td>\n",
       "      <td>0.201614</td>\n",
       "      <td>0.079594</td>\n",
       "      <td>0.050340</td>\n",
       "      <td>-0.129533</td>\n",
       "      <td>0.040859</td>\n",
       "      <td>0.035003</td>\n",
       "      <td>-0.072087</td>\n",
       "      <td>0.121597</td>\n",
       "      <td>0.023802</td>\n",
       "      <td>-0.155225</td>\n",
       "      <td>-0.038463</td>\n",
       "      <td>0.011749</td>\n",
       "      <td>0.030698</td>\n",
       "      <td>0.058923</td>\n",
       "      <td>0.023557</td>\n",
       "      <td>0.072026</td>\n",
       "      <td>0.034707</td>\n",
       "      <td>0.103286</td>\n",
       "      <td>0.099152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             pca0        pca1        pca2      pca3      pca4      pca5  \\\n",
       "84341  369.406386   -9.608162    0.179558 -0.062166  0.596542  0.550946   \n",
       "37492 -653.419003  -28.480496    1.441660  0.403025 -0.210278  1.273879   \n",
       "55696  170.439372  -13.279279    0.424960 -0.865623  0.010005  1.300962   \n",
       "8859  -290.482590  -21.784067    0.993400 -1.629461  0.419143 -0.613777   \n",
       "63927  180.438408  -13.094857    0.412573 -0.265649  0.577157 -0.261206   \n",
       "...           ...         ...         ...       ...       ...       ...   \n",
       "56457  272.423439  -11.397601    0.299051  1.049562  0.887998 -0.154112   \n",
       "85107 -380.465280  -23.444177    1.104279  1.295955 -0.199383 -1.560158   \n",
       "606    809.330375   -1.488648   -0.363055  0.232749 -1.304640 -1.616957   \n",
       "56102  373.657521  573.614184    7.936077 -0.864480  3.430380  0.627452   \n",
       "45103 -444.023645  973.702063 -122.741852  2.799582 -0.741432 -1.279848   \n",
       "\n",
       "           pca6      pca7      pca8      pca9     pca10     pca11     pca12  \\\n",
       "84341 -0.264805 -0.513814  0.620569 -0.494372 -0.033893 -0.995415 -0.787977   \n",
       "37492  1.188273  0.604383 -0.605486 -0.228558 -0.084783 -0.375250 -0.546711   \n",
       "55696 -0.513658 -1.093548  0.485868 -0.025464 -0.085488 -0.288770 -0.799541   \n",
       "8859   0.709189  0.458208  0.372986 -0.385654  0.120670 -0.548422  0.245208   \n",
       "63927 -0.811060 -0.919617  0.377864  0.138909  0.088343  0.432462 -0.557569   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "56457 -2.259923 -1.174667  0.939465 -0.324289  0.142413 -0.888163 -0.466841   \n",
       "85107  0.007369  0.281071  0.204463 -0.168330 -0.035494 -0.348671  0.288222   \n",
       "606   -0.133677  0.103888  0.489555 -0.146001 -0.124768 -0.456670  0.412055   \n",
       "56102  0.906955 -1.130587 -0.006697  0.072143  0.457770  1.311895  0.721516   \n",
       "45103 -0.972672 -0.044527 -0.384021  0.408903  0.005179  0.573463  0.349042   \n",
       "\n",
       "          pca13     pca14     pca15     pca16     pca17     pca18     pca19  \\\n",
       "84341  1.142734  0.158463  0.712329  0.101890  0.226943  0.124162 -0.294356   \n",
       "37492  0.029999 -0.257772  0.389423  0.653168  0.186674  0.678997  0.421090   \n",
       "55696  1.098683 -0.744922  0.173100  1.028667  0.262057  0.056733 -0.253986   \n",
       "8859  -0.089310 -0.753674 -0.209001  0.088275  0.399016 -0.346035 -0.480131   \n",
       "63927  1.044393  0.444634  0.150587  0.707015  0.235432  0.749725  0.355320   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "56457  0.914062  0.226891  0.969369  0.055987  0.235886 -0.334974 -0.548431   \n",
       "85107 -0.674397 -0.276337 -0.562774 -0.797003  0.141040  0.098534 -0.194190   \n",
       "606   -0.507539 -0.065535 -0.367373  0.036662  0.113159  0.021222 -0.113348   \n",
       "56102 -0.216496 -1.143928 -0.488288  0.797072  0.756073  0.154506 -0.408371   \n",
       "45103 -0.511426 -0.502209 -0.101678  0.604210  0.399284  0.048875 -0.198011   \n",
       "\n",
       "          pca20     pca21     pca22     pca23     pca24     pca25     pca26  \\\n",
       "84341  0.021556  0.094708  0.192587  0.501935  1.026374 -0.284926 -0.768755   \n",
       "37492 -0.288825 -0.247507 -0.250112 -0.166262  0.223529 -0.114127 -0.280239   \n",
       "55696  0.099261  0.747357 -0.514250 -0.133495  0.059222 -0.132035 -0.246426   \n",
       "8859  -0.638432 -0.238420 -0.371723 -0.266506  0.720798 -0.196218 -0.650979   \n",
       "63927 -0.240020 -0.224256 -0.283004 -0.154981  0.301620 -0.172372 -0.339936   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "56457 -0.665348 -0.257553 -0.384939 -0.269167  0.729279 -0.140257 -0.722307   \n",
       "85107  0.007139  0.075563  0.033263 -0.033686  0.436093  0.903622 -0.008902   \n",
       "606    0.092393  0.748955 -0.370062  0.017586 -0.303835 -0.159816  1.042052   \n",
       "56102  0.108292  0.776406 -0.547547 -0.261748  0.582770 -0.235049 -0.100535   \n",
       "45103  0.103783  0.772170 -0.447462 -0.070181 -0.023569 -0.127795  0.047722   \n",
       "\n",
       "          pca27     pca28     pca29     pca30     pca31     pca32     pca33  \\\n",
       "84341 -0.461073 -0.015108 -0.096331 -0.181976 -0.309769 -0.666685  0.297711   \n",
       "37492 -0.372612  0.040899  0.430109  0.691879  0.226532 -0.182182 -0.098686   \n",
       "55696 -0.506664  0.039164 -0.126774 -0.426497  0.658513 -0.185086 -0.121259   \n",
       "8859  -0.475358 -0.506042  0.672654 -0.368695 -0.191316  0.015183 -0.147292   \n",
       "63927 -0.412389 -0.429822  0.688057 -0.347213 -0.164563  0.003498 -0.054972   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "56457 -0.379208  0.056280 -0.097889  0.027030  0.163891 -0.118186 -0.153676   \n",
       "85107 -0.095733  0.048257 -0.077473  0.044971  0.213805 -0.135484 -0.122858   \n",
       "606   -0.388768  0.079151 -0.129915  0.051711  0.218511 -0.161141 -0.164185   \n",
       "56102  0.760732  0.085789 -0.038428  0.075302  0.208538 -0.111765 -0.114521   \n",
       "45103  0.128625  0.099692 -0.094534  0.055521  0.184291 -0.146245 -0.152848   \n",
       "\n",
       "          pca34     pca35     pca36     pca37     pca38     pca39     pca40  \\\n",
       "84341  0.118579 -0.368372  0.384661  0.169260  0.034277  0.009300 -0.030203   \n",
       "37492 -0.077041 -0.099270  0.171210  0.110906  0.083219  0.154603  0.012287   \n",
       "55696 -0.036137  0.055114  0.065869  0.195934  0.166376  0.117271  0.034822   \n",
       "8859   0.008653 -0.275956 -0.114787 -0.227552 -0.160119  0.035556 -0.016678   \n",
       "63927  0.051276 -0.063025 -0.010599 -0.217660 -0.095197  0.175298  0.000363   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "56457 -0.642712 -0.230875  0.210449 -0.495717 -0.340380 -0.014402 -0.008586   \n",
       "85107 -0.574807 -0.037961  0.227216 -0.323514 -0.273558  0.031939 -0.050307   \n",
       "606   -0.598167 -0.052229  0.246792 -0.301275 -0.293132 -0.320089  0.004867   \n",
       "56102 -0.548806 -0.180342  0.315016 -0.383090 -0.312783 -0.003132  0.062059   \n",
       "45103 -0.589068 -0.174715  0.300705 -0.337735 -0.241285  0.036835  0.019475   \n",
       "\n",
       "          pca41     pca42     pca43     pca44     pca45     pca46     pca47  \\\n",
       "84341 -0.003334 -0.175433 -0.079776 -0.057985 -0.054252 -0.127423 -0.039765   \n",
       "37492 -0.048274 -0.041235 -0.006061  0.023991 -0.071345  0.000542 -0.083028   \n",
       "55696 -0.342663  0.052657  0.039262  0.303700  0.356481  0.250798  0.161384   \n",
       "8859  -0.058753 -0.150326 -0.065618 -0.018790 -0.114727 -0.111390 -0.063124   \n",
       "63927 -0.000030 -0.073339 -0.016454 -0.020901 -0.027462 -0.004294 -0.118264   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "56457 -0.050982 -0.152503 -0.065527 -0.081110 -0.031524 -0.077445 -0.031281   \n",
       "85107  0.131515 -0.210701  0.075566 -0.013212  0.026382 -0.202430  0.061240   \n",
       "606    0.163151 -0.268619  0.100604 -0.047159  0.111273 -0.287029  0.028149   \n",
       "56102  0.195384 -0.066369  0.138277  0.073050  0.005418 -0.259615 -0.119560   \n",
       "45103  0.054699 -0.053229  0.018926  0.052906  0.027899 -0.085761 -0.038867   \n",
       "\n",
       "          pca48     pca49     pca50     pca51     pca52     pca53     pca54  \\\n",
       "84341  0.029790 -0.034567  0.015400 -0.125174 -0.107160  0.091005  0.008068   \n",
       "37492 -0.017518  0.050702 -0.095135 -0.087924  0.073731  0.044353  0.019871   \n",
       "55696  0.403531 -0.172050 -0.044468 -0.047200 -0.140299  0.012314  0.014660   \n",
       "8859   0.006538  0.039179 -0.042315 -0.108234 -0.046616  0.055069  0.029809   \n",
       "63927 -0.010297  0.018758  0.003588 -0.100117  0.007330  0.107345  0.010003   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "56457  0.080550 -0.029484 -0.057563 -0.133563 -0.067893  0.058199  0.012539   \n",
       "85107 -0.029218  0.008849 -0.007954 -0.104001 -0.174207  0.246146  0.089714   \n",
       "606   -0.178728  0.060060  0.037626 -0.044209 -0.180846  0.468412  1.585908   \n",
       "56102 -0.101697 -0.077715  0.228720  0.052273 -0.056388  0.228059  1.216312   \n",
       "45103 -0.002102  0.083255 -0.069832 -0.094290 -0.027839  0.219398  0.919810   \n",
       "\n",
       "          pca55     pca56     pca57     pca58     pca59     pca60     pca61  \\\n",
       "84341 -0.057949 -0.046862 -0.089729 -0.060579  0.085124  0.074155  0.014692   \n",
       "37492 -0.037660 -0.044624 -0.133056  0.001022  0.071558  0.031961  0.058267   \n",
       "55696 -0.060238 -0.096416 -0.046480  0.005344 -0.025261  0.164102  0.028976   \n",
       "8859  -0.046890 -0.034855 -0.129810  0.011569  0.051555  0.067567  0.008258   \n",
       "63927 -0.059084 -0.070466 -0.081514 -0.054371  0.087490  0.065572  0.059322   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "56457 -0.022202 -0.038458 -0.087365 -0.064144  0.106497  0.048255 -0.001019   \n",
       "85107 -0.110091 -0.099578 -0.117778  0.055855 -0.183307  0.344112  0.086584   \n",
       "606    0.811831  0.496688  0.366944  0.106318 -0.073995  0.195277 -0.023088   \n",
       "56102  0.406900  0.325878  0.295633  0.027026  0.161872  0.251420 -0.505005   \n",
       "45103  0.416703  0.201614  0.079594  0.050340 -0.129533  0.040859  0.035003   \n",
       "\n",
       "          pca62     pca63     pca64     pca65     pca66     pca67     pca68  \\\n",
       "84341  0.126393 -0.077876 -0.009426  0.055077 -0.084227 -0.086071  0.014726   \n",
       "37492  0.180589 -0.026137  0.029428 -0.001374 -0.070153  0.008106  0.048121   \n",
       "55696  0.127662  0.009735  0.052783  0.073739 -0.079384 -0.065289 -0.019136   \n",
       "8859   0.104265 -0.090196  0.008584  0.004241 -0.035065 -0.079586 -0.043614   \n",
       "63927  0.166721 -0.063915 -0.006499  0.032121 -0.086406 -0.141783  0.009698   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "56457  0.165281  0.004340  0.044619  0.014873 -0.085760 -0.069628  0.057621   \n",
       "85107 -0.461102  0.581721 -0.338702 -0.239570 -0.134775  0.220266  0.113473   \n",
       "606   -0.368545  0.209962 -0.553170 -0.127615 -0.141667  0.106703  0.182462   \n",
       "56102 -0.299936 -0.205255 -0.005661  0.120301 -0.049197 -0.002847 -0.179501   \n",
       "45103 -0.072087  0.121597  0.023802 -0.155225 -0.038463  0.011749  0.030698   \n",
       "\n",
       "          pca69     pca70     pca71     pca72     pca73     pca74  \n",
       "84341  0.175574 -0.087826  0.090813  0.013114 -0.080915  0.057627  \n",
       "37492  0.252027 -0.103192  0.021629  0.053371  0.068848  0.073725  \n",
       "55696  0.220117 -0.083960  0.039033 -0.004053 -0.095916  0.008449  \n",
       "8859   0.197611 -0.066696  0.012070 -0.017909 -0.084068  0.058986  \n",
       "63927  0.246450 -0.049105  0.167784  0.044545 -0.027023  0.044475  \n",
       "...         ...       ...       ...       ...       ...       ...  \n",
       "56457  0.149355 -0.067925  0.155274  0.021784 -0.076124  0.026221  \n",
       "85107  0.109242  0.026682  0.104874  0.059077  0.133471  0.047502  \n",
       "606    0.067878 -0.107040  0.126785  0.155378  0.051131  0.086904  \n",
       "56102  0.054250 -0.127216 -0.100144 -0.194842  0.104562 -0.057194  \n",
       "45103  0.058923  0.023557  0.072026  0.034707  0.103286  0.099152  \n",
       "\n",
       "[100000 rows x 75 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the pipeline in this cell and run it on X, this cell must end with the transformed data\n",
    "X = preprocessor.fit_transform(X_train, y_train)\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mX\u001b[49m\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39msort_values(ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m20\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "X.isna().sum().sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the preprocessor as a parquet file\n",
    "X.to_parquet(\"preprocessor.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pickle the preprocessor\n",
    "import pickle\n",
    "with open(\"preprocessor.pkl\", \"wb\") as f:\n",
    "    pickle.dump(preprocessor, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_logger <class '__main__.ProgressLogger'> 48\n",
      "delay_trend <class '__main__.DelayTrendEncoder'> 48\n",
      "trend_logger <class '__main__.ProgressLogger'> 48\n",
      "tail_reuse <class '__main__.SameDayTailReuseEncoder'> 48\n",
      "reuse_logger <class '__main__.ProgressLogger'> 48\n",
      "turnaround_delay <class '__main__.TurnaroundDelayEncoder'> 48\n",
      "turnaround_logger <class '__main__.ProgressLogger'> 48\n",
      "slack_time <class '__main__.SlackTimeEncoder'> 48\n",
      "slack_logger <class '__main__.ProgressLogger'> 48\n",
      "feature_prep <class 'sklearn.compose._column_transformer.ColumnTransformer'> 48\n",
      "prep_logger <class '__main__.ProgressLogger'> 48\n",
      "select <class 'sklearn.feature_selection._from_model.SelectFromModel'> 48\n",
      "final_logger <class '__main__.ProgressLogger'> 48\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "for name, step in preprocessor.named_steps.items():\n",
    "    print(name, type(step), sys.getsizeof(step))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, precision_score, recall_score, precision_recall_curve\n",
    "def precision_at_recall(y, y_pred, *, recall, **kwargs):\n",
    "    \"\"\"\n",
    "    Calculate the precision at a given recall level.\n",
    "\n",
    "    To use this with cross_val_score, you need to use the make_scorer function to\n",
    "    create a scoring function that can be used with cross_val_score. For example:\n",
    "\n",
    "        scorer = make_scorer(precision_at_recall, recall=0.9)  # 0.9 is the minimum recall level\n",
    "        cross_val_score(model, X, y, cv=5, scoring=scorer)\n",
    "\n",
    "    The default will only work for binary classification problems. You must change the\n",
    "    average parameter if you want to use for multiclass classification. For example:\n",
    "\n",
    "        scorer = make_scorer(precision_at_recall, recall=0.9, average=\"micro\")\n",
    "    \"\"\"\n",
    "    return precision_score(y, y_pred, **kwargs) if recall_score(y, y_pred, **kwargs) > recall else 0.0\n",
    "\n",
    "def recall_at_precision(y, y_pred, *, precision, **kwargs):\n",
    "    \"\"\"\n",
    "    Calculate the recall at a given precision level.\n",
    "\n",
    "    To use this with cross_val_score, you need to use the make_scorer function to\n",
    "    create a scoring function that can be used with cross_val_score. For example:\n",
    "\n",
    "        scorer = make_scorer(recall_at_precision, precision=0.9)\n",
    "        cross_val_score(model, X, y, cv=5, scoring=scorer)\n",
    "\n",
    "    The default will only work for binary classification problems. You must change the\n",
    "    average parameter if you want to use for multiclass classification. For example:\n",
    "\n",
    "        scorer = make_scorer(recall_at_precision, precision=0.9, average=\"micro\")\n",
    "    \"\"\"\n",
    "    return recall_score(y, y_pred, **kwargs) if precision_score(y, y_pred, **kwargs) > precision else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_sample = X.sample(n=100000, random_state=42)\n",
    "y_train = y_train.sample(n=100000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=64)]: Using backend LokyBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done   5 out of   5 | elapsed:   40.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.0565\n",
      "Precision: 0.0547\n",
      "F1 Score: 0.0130\n",
      "Cross-Validation Classification Report:\n",
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "            Carrier Cancellation       0.00      0.09      0.01       424\n",
      "      Major Delay - CarrierDelay       0.00      0.05      0.01       514\n",
      " Major Delay - LateAircraftDelay       0.01      0.09      0.01       649\n",
      "          Major Delay - NASDelay       0.00      0.02      0.00        91\n",
      "      Major Delay - WeatherDelay       0.00      0.02      0.00        96\n",
      "     Medium Delay - CarrierDelay       0.02      0.03      0.02      1881\n",
      "Medium Delay - LateAircraftDelay       0.02      0.02      0.02      2886\n",
      "         Medium Delay - NASDelay       0.01      0.08      0.01       487\n",
      "     Medium Delay - WeatherDelay       0.00      0.06      0.01       325\n",
      "      Minor Delay - CarrierDelay       0.04      0.02      0.03      3539\n",
      " Minor Delay - LateAircraftDelay       0.03      0.02      0.02      4238\n",
      "          Minor Delay - NASDelay       0.01      0.04      0.01      1060\n",
      "      Minor Delay - WeatherDelay       0.00      0.24      0.01       326\n",
      "                NAS Cancellation       0.00      0.10      0.00       205\n",
      "                         On-Time       0.78      0.01      0.02     78470\n",
      "                  Security Issue       0.00      0.02      0.00        51\n",
      "                         Unknown       0.04      0.03      0.03      3977\n",
      "            Weather Cancellation       0.01      0.09      0.02       781\n",
      "\n",
      "                        accuracy                           0.01    100000\n",
      "                       macro avg       0.05      0.06      0.01    100000\n",
      "                    weighted avg       0.61      0.01      0.02    100000\n",
      "\n",
      "Mean precision at recall 0.25: 0.0000 ± 0.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import classification_report, recall_score, precision_score, f1_score\n",
    "\n",
    "# Create a DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(\n",
    "    random_state=42,\n",
    "    max_depth=20,\n",
    "    min_samples_leaf=10,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "scorer = make_scorer(precision_at_recall, recall=0.25, average='weighted')\n",
    "\n",
    "scores = cross_val_score(dt, X_sample, y_train, cv=5, scoring=scorer, verbose=1, n_jobs=64)\n",
    "\n",
    "# Fit the model and predict using cross-validation\n",
    "y_pred_cv = cross_val_predict(dt, X_sample, y_train, cv=5, n_jobs=64)\n",
    "\n",
    "# Calculate recall, precision, and F1 score\n",
    "recall = recall_score(y_train, y_pred_cv, average='macro')\n",
    "precision = precision_score(y_train, y_pred_cv, average='macro', zero_division=0)\n",
    "f1 = f1_score(y_train, y_pred_cv, average='macro')\n",
    "\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Cross-validated performance\n",
    "print(\"Cross-Validation Classification Report:\")\n",
    "print(classification_report(y_train, y_pred_cv, zero_division=0))\n",
    "\n",
    "print(f\"Mean precision at recall 0.25: {scores.mean():.4f} ± {scores.std():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Flight_Status\n",
       "On-Time                             78470\n",
       "Minor Delay - LateAircraftDelay      4238\n",
       "Unknown                              3977\n",
       "Minor Delay - CarrierDelay           3539\n",
       "Medium Delay - LateAircraftDelay     2886\n",
       "Medium Delay - CarrierDelay          1881\n",
       "Minor Delay - NASDelay               1060\n",
       "Weather Cancellation                  781\n",
       "Major Delay - LateAircraftDelay       649\n",
       "Major Delay - CarrierDelay            514\n",
       "Medium Delay - NASDelay               487\n",
       "Carrier Cancellation                  424\n",
       "Minor Delay - WeatherDelay            326\n",
       "Medium Delay - WeatherDelay           325\n",
       "NAS Cancellation                      205\n",
       "Major Delay - WeatherDelay             96\n",
       "Major Delay - NASDelay                 91\n",
       "Security Issue                         51\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "\n",
    "# Create Gradient Boosting classifier\n",
    "model = GradientBoostingClassifier(\n",
    "    n_estimators=10,    # Number of trees\n",
    "    max_depth=3,         # Max tree depth\n",
    "    learning_rate=0.1,   # Slightly lower learning rate for better stability\n",
    "    subsample=0.8,       # Use 80% of samples for each tree (helps with large datasets)\n",
    "    random_state=42,\n",
    "    verbose=2            # Show progress\n",
    ")\n",
    "\n",
    "# Create scorer for precision at recall\n",
    "scorer = make_scorer(precision_at_recall, recall=0.25, average='weighted')\n",
    "\n",
    "# Run cross-validation with the Gradient Boosting model\n",
    "scores = cross_val_score(model, X_sample, y_train, cv=5, scoring=scorer, verbose=1, n_jobs=16)\n",
    "\n",
    "# Fit the model and predict using cross-validation\n",
    "y_pred_cv = cross_val_predict(model, X_sample, y_train, cv=5, n_jobs=16)\n",
    "\n",
    "# Calculate metrics\n",
    "recall = recall_score(y_train, y_pred_cv, average='macro')\n",
    "precision = precision_score(y_train, y_pred_cv, average='macro', zero_division=0)\n",
    "f1 = f1_score(y_train, y_pred_cv, average='macro')\n",
    "\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Print classification report\n",
    "print(\"Cross-Validation Classification Report:\")\n",
    "print(classification_report(y_train, y_pred_cv, zero_division=0))\n",
    "print(f\"Mean precision at recall 0.25: {scores.mean():.4f} ± {scores.std():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m classes \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m y_train_bin \u001b[38;5;241m=\u001b[39m label_binarize(y_train, classes\u001b[38;5;241m=\u001b[39mclasses)\n\u001b[1;32m      4\u001b[0m y_scores \u001b[38;5;241m=\u001b[39m cross_val_predict(dt_clf, X, y_train, cv\u001b[38;5;241m=\u001b[39mcv, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredict_proba\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36munique\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/numpy/lib/arraysetops.py:274\u001b[0m, in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[1;32m    272\u001b[0m ar \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(ar)\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43m_unique1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mequal_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mequal_nan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[1;32m    278\u001b[0m \u001b[38;5;66;03m# axis was specified and not None\u001b[39;00m\n",
      "File \u001b[0;32m/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/numpy/lib/arraysetops.py:336\u001b[0m, in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[1;32m    334\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar[perm]\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 336\u001b[0m     \u001b[43mar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    337\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar\n\u001b[1;32m    338\u001b[0m mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(aux\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mbool_)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "classes = np.unique(y_train)\n",
    "y_train_bin = label_binarize(y_train, classes=classes)\n",
    "\n",
    "y_scores = cross_val_predict(dt_clf, X, y_train, cv=cv, method='predict_proba')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i, class_name in enumerate(classes):\n",
    "    precision, recall, _ = precision_recall_curve(y_train_bin[:, i], y_scores[:, i])\n",
    "    plt.plot(recall, precision, lw=2, label=f\"{class_name}\")\n",
    "\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curves (One-vs-Rest)\")\n",
    "plt.legend(loc=\"best\", fontsize='small')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i, class_name in enumerate(classes):\n",
    "    fpr, tpr, _ = roc_curve(y_train_bin[:, i], y_scores[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, lw=2, label=f\"{class_name} (AUC = {roc_auc:.2f})\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curves (One-vs-Rest)\")\n",
    "plt.legend(loc=\"lower right\", fontsize='small')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Perform cross-validation\u001b[39;00m\n\u001b[0;32m     22\u001b[0m cv \u001b[38;5;241m=\u001b[39m StratifiedKFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 23\u001b[0m y_pred_cv_log_reg \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_reg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Fit the model on the training data\u001b[39;00m\n\u001b[0;32m     26\u001b[0m log_reg\u001b[38;5;241m.\u001b[39mfit(X_scaled, y_train)\n",
      "File \u001b[1;32mc:\\Users\\deni5\\OneDrive\\Documents\\Courses\\neural_networks\\NeuralNetworkProject\\venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\deni5\\OneDrive\\Documents\\Courses\\neural_networks\\NeuralNetworkProject\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:1247\u001b[0m, in \u001b[0;36mcross_val_predict\u001b[1;34m(estimator, X, y, groups, cv, n_jobs, verbose, params, pre_dispatch, method)\u001b[0m\n\u001b[0;32m   1244\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m   1245\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m   1246\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m-> 1247\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1248\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_predict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1251\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1256\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1257\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msplits\u001b[49m\n\u001b[0;32m   1258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1260\u001b[0m inv_test_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;28mlen\u001b[39m(test_indices), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m   1261\u001b[0m inv_test_indices[test_indices] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(test_indices))\n",
      "File \u001b[1;32mc:\\Users\\deni5\\OneDrive\\Documents\\Courses\\neural_networks\\NeuralNetworkProject\\venv\\lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\deni5\\OneDrive\\Documents\\Courses\\neural_networks\\NeuralNetworkProject\\venv\\lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\deni5\\OneDrive\\Documents\\Courses\\neural_networks\\NeuralNetworkProject\\venv\\lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\deni5\\OneDrive\\Documents\\Courses\\neural_networks\\NeuralNetworkProject\\venv\\lib\\site-packages\\sklearn\\utils\\parallel.py:139\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\deni5\\OneDrive\\Documents\\Courses\\neural_networks\\NeuralNetworkProject\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:1332\u001b[0m, in \u001b[0;36m_fit_and_predict\u001b[1;34m(estimator, X, y, train, test, fit_params, method)\u001b[0m\n\u001b[0;32m   1330\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m   1331\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1332\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m   1333\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(estimator, method)\n\u001b[0;32m   1334\u001b[0m predictions \u001b[38;5;241m=\u001b[39m func(X_test)\n",
      "File \u001b[1;32mc:\\Users\\deni5\\OneDrive\\Documents\\Courses\\neural_networks\\NeuralNetworkProject\\venv\\lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\deni5\\OneDrive\\Documents\\Courses\\neural_networks\\NeuralNetworkProject\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1350\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1347\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1348\u001b[0m     n_threads \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1350\u001b[0m fold_coefs_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1352\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1353\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1354\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1355\u001b[0m \u001b[43m        \u001b[49m\u001b[43mCs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mC_\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1356\u001b[0m \u001b[43m        \u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml1_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1357\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1358\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1359\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1360\u001b[0m \u001b[43m        \u001b[49m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1361\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1362\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1363\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1364\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1365\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1366\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoef\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1367\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpenalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1368\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1369\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1370\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1371\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1372\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclasses_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1373\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1375\u001b[0m fold_coefs_, _, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mfold_coefs_)\n\u001b[0;32m   1376\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(n_iter_, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint32)[:, \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\deni5\\OneDrive\\Documents\\Courses\\neural_networks\\NeuralNetworkProject\\venv\\lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\deni5\\OneDrive\\Documents\\Courses\\neural_networks\\NeuralNetworkProject\\venv\\lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\deni5\\OneDrive\\Documents\\Courses\\neural_networks\\NeuralNetworkProject\\venv\\lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\deni5\\OneDrive\\Documents\\Courses\\neural_networks\\NeuralNetworkProject\\venv\\lib\\site-packages\\sklearn\\utils\\parallel.py:139\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\deni5\\OneDrive\\Documents\\Courses\\neural_networks\\NeuralNetworkProject\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:451\u001b[0m, in \u001b[0;36m_logistic_regression_path\u001b[1;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[0;32m    447\u001b[0m l2_reg_strength \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m (C \u001b[38;5;241m*\u001b[39m sw_sum)\n\u001b[0;32m    448\u001b[0m iprint \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m101\u001b[39m][\n\u001b[0;32m    449\u001b[0m     np\u001b[38;5;241m.\u001b[39msearchsorted(np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m]), verbose)\n\u001b[0;32m    450\u001b[0m ]\n\u001b[1;32m--> 451\u001b[0m opt_res \u001b[38;5;241m=\u001b[39m \u001b[43moptimize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[43mw0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mL-BFGS-B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml2_reg_strength\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaxiter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaxls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# default is 20\u001b[39;49;00m\n\u001b[0;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43miprint\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43miprint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgtol\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mftol\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    464\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    465\u001b[0m n_iter_i \u001b[38;5;241m=\u001b[39m _check_optimize_result(\n\u001b[0;32m    466\u001b[0m     solver,\n\u001b[0;32m    467\u001b[0m     opt_res,\n\u001b[0;32m    468\u001b[0m     max_iter,\n\u001b[0;32m    469\u001b[0m     extra_warning_msg\u001b[38;5;241m=\u001b[39m_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n\u001b[0;32m    470\u001b[0m )\n\u001b[0;32m    471\u001b[0m w0, loss \u001b[38;5;241m=\u001b[39m opt_res\u001b[38;5;241m.\u001b[39mx, opt_res\u001b[38;5;241m.\u001b[39mfun\n",
      "File \u001b[1;32mc:\\Users\\deni5\\OneDrive\\Documents\\Courses\\neural_networks\\NeuralNetworkProject\\venv\\lib\\site-packages\\scipy\\optimize\\_minimize.py:738\u001b[0m, in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    735\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[0;32m    736\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    737\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 738\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m    739\u001b[0m                            callback\u001b[38;5;241m=\u001b[39mcallback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    740\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    741\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[0;32m    742\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[1;32mc:\\Users\\deni5\\OneDrive\\Documents\\Courses\\neural_networks\\NeuralNetworkProject\\venv\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:441\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    433\u001b[0m _lbfgsb\u001b[38;5;241m.\u001b[39msetulb(m, x, low_bnd, upper_bnd, nbd, f, g, factr, pgtol, wa,\n\u001b[0;32m    434\u001b[0m                iwa, task, lsave, isave, dsave, maxls, ln_task)\n\u001b[0;32m    436\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m    437\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[0;32m    438\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[1;32m--> 441\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    443\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[0;32m    444\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\deni5\\OneDrive\\Documents\\Courses\\neural_networks\\NeuralNetworkProject\\venv\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:344\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx):\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x(x)\n\u001b[1;32m--> 344\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_grad()\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[1;32mc:\\Users\\deni5\\OneDrive\\Documents\\Courses\\neural_networks\\NeuralNetworkProject\\venv\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:295\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    294\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[1;32m--> 295\u001b[0m         fx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrapped_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    296\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m fx \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lowest_f:\n\u001b[0;32m    297\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lowest_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx\n",
      "File \u001b[1;32mc:\\Users\\deni5\\OneDrive\\Documents\\Courses\\neural_networks\\NeuralNetworkProject\\venv\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:21\u001b[0m, in \u001b[0;36m_wrapper_fun.<locals>.wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     17\u001b[0m ncalls[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m fx \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "File \u001b[1;32mc:\\Users\\deni5\\OneDrive\\Documents\\Courses\\neural_networks\\NeuralNetworkProject\\venv\\lib\\site-packages\\scipy\\optimize\\_optimize.py:80\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m     79\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" returns the function value \"\"\"\u001b[39;00m\n\u001b[1;32m---> 80\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[1;32mc:\\Users\\deni5\\OneDrive\\Documents\\Courses\\neural_networks\\NeuralNetworkProject\\venv\\lib\\site-packages\\scipy\\optimize\\_optimize.py:74\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(x \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m---> 74\u001b[0m     fg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\deni5\\OneDrive\\Documents\\Courses\\neural_networks\\NeuralNetworkProject\\venv\\lib\\site-packages\\sklearn\\linear_model\\_linear_loss.py:316\u001b[0m, in \u001b[0;36mLinearModelLoss.loss_gradient\u001b[1;34m(self, coef, X, y, sample_weight, l2_reg_strength, n_threads, raw_prediction)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    314\u001b[0m     weights, intercept \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight_intercept(coef)\n\u001b[1;32m--> 316\u001b[0m loss, grad_pointwise \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_gradient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_prediction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_prediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    322\u001b[0m sw_sum \u001b[38;5;241m=\u001b[39m n_samples \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39msum(sample_weight)\n\u001b[0;32m    323\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m/\u001b[39m sw_sum\n",
      "File \u001b[1;32mc:\\Users\\deni5\\OneDrive\\Documents\\Courses\\neural_networks\\NeuralNetworkProject\\venv\\lib\\site-packages\\sklearn\\_loss\\loss.py:258\u001b[0m, in \u001b[0;36mBaseLoss.loss_gradient\u001b[1;34m(self, y_true, raw_prediction, sample_weight, loss_out, gradient_out, n_threads)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gradient_out\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m gradient_out\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    256\u001b[0m     gradient_out \u001b[38;5;241m=\u001b[39m gradient_out\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 258\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_gradient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    260\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_prediction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_prediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    261\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    262\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_out\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_out\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    263\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgradient_out\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient_out\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    265\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss_out, gradient_out\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "log_reg = LogisticRegression(\n",
    "    class_weight='balanced',\n",
    "    solver='lbfgs',\n",
    "    max_iter=2000,  \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "y_pred_cv_log_reg = cross_val_predict(log_reg, X_scaled, y_train, cv=cv)\n",
    "\n",
    "log_reg.fit(X_scaled, y_train)\n",
    "y_pred_train_log_reg = log_reg.predict(X_scaled)\n",
    "\n",
    "print(\"Performance on Training Set:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_train, y_pred_train_log_reg):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_train, y_pred_train_log_reg, average='macro', zero_division=0):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_train, y_pred_train_log_reg, average='macro'):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y_train, y_pred_train_log_reg, average='macro'):.4f}\\n\")\n",
    "\n",
    "print(\"Cross-Validated Performance:\")\n",
    "print(f\"CV Accuracy: {accuracy_score(y_train, y_pred_cv_log_reg):.4f}\")\n",
    "print(f\"CV Precision: {precision_score(y_train, y_pred_cv_log_reg, average='macro', zero_division=0):.4f}\")\n",
    "print(f\"CV Recall: {recall_score(y_train, y_pred_cv_log_reg, average='macro'):.4f}\")\n",
    "print(f\"CV F1 Score: {f1_score(y_train, y_pred_cv_log_reg, average='macro'):.4f}\\n\")\n",
    "\n",
    "print(\"Cross-Validation Classification Report:\")\n",
    "print(classification_report(y_train, y_pred_cv_log_reg, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 32\u001b[0m\n\u001b[0;32m     17\u001b[0m mlp \u001b[38;5;241m=\u001b[39m MLPClassifier(\n\u001b[0;32m     18\u001b[0m     hidden_layer_sizes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m50\u001b[39m),  \u001b[38;5;66;03m# Two hidden layers\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m,             \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     28\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m,\n\u001b[0;32m     29\u001b[0m )\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Train the model using your preprocessed X data\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m \u001b[43mmlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_prepped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# For testing, you'll need to apply the same preprocessing to X_test\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# If you haven't already done this, you would typically do:\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# X_test_prepped = preprocessor.transform(X_test)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Make predictions (using whatever preprocessed test data you have)\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# If X_test is already preprocessed:\u001b[39;00m\n\u001b[0;32m     41\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m mlp\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32mc:\\Users\\deni5\\OneDrive\\Documents\\Courses\\neural_networks\\NeuralNetworkProject\\venv\\lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\deni5\\OneDrive\\Documents\\Courses\\neural_networks\\NeuralNetworkProject\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:754\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    736\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    737\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[0;32m    738\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model to data matrix X and target(s) y.\u001b[39;00m\n\u001b[0;32m    739\u001b[0m \n\u001b[0;32m    740\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    752\u001b[0m \u001b[38;5;124;03m        Returns a trained MLP model.\u001b[39;00m\n\u001b[0;32m    753\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 754\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mincremental\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\deni5\\OneDrive\\Documents\\Courses\\neural_networks\\NeuralNetworkProject\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:476\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron._fit\u001b[1;34m(self, X, y, incremental)\u001b[0m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;66;03m# Run the Stochastic optimization solver\u001b[39;00m\n\u001b[0;32m    475\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msolver \u001b[38;5;129;01min\u001b[39;00m _STOCHASTIC_SOLVERS:\n\u001b[1;32m--> 476\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_stochastic\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mactivations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeltas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoef_grads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintercept_grads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_units\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mincremental\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;66;03m# Run the LBFGS solver\u001b[39;00m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msolver \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlbfgs\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\deni5\\OneDrive\\Documents\\Courses\\neural_networks\\NeuralNetworkProject\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:660\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron._fit_stochastic\u001b[1;34m(self, X, y, activations, deltas, coef_grads, intercept_grads, layer_units, incremental)\u001b[0m\n\u001b[0;32m    656\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIteration \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m, loss = \u001b[39m\u001b[38;5;132;01m%.8f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_))\n\u001b[0;32m    658\u001b[0m \u001b[38;5;66;03m# update no_improvement_count based on training loss or\u001b[39;00m\n\u001b[0;32m    659\u001b[0m \u001b[38;5;66;03m# validation score according to early_stopping\u001b[39;00m\n\u001b[1;32m--> 660\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_no_improvement_count\u001b[49m\u001b[43m(\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    662\u001b[0m \u001b[38;5;66;03m# for learning rate that needs to be updated at iteration end\u001b[39;00m\n\u001b[0;32m    663\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer\u001b[38;5;241m.\u001b[39miteration_ends(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt_)\n",
      "File \u001b[1;32mc:\\Users\\deni5\\OneDrive\\Documents\\Courses\\neural_networks\\NeuralNetworkProject\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:708\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron._update_no_improvement_count\u001b[1;34m(self, early_stopping, X_val, y_val)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_update_no_improvement_count\u001b[39m(\u001b[38;5;28mself\u001b[39m, early_stopping, X_val, y_val):\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m early_stopping:\n\u001b[0;32m    707\u001b[0m         \u001b[38;5;66;03m# compute validation score (can be NaN), use that for stopping\u001b[39;00m\n\u001b[1;32m--> 708\u001b[0m         val_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    710\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidation_scores_\u001b[38;5;241m.\u001b[39mappend(val_score)\n\u001b[0;32m    712\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n",
      "File \u001b[1;32mc:\\Users\\deni5\\OneDrive\\Documents\\Courses\\neural_networks\\NeuralNetworkProject\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1194\u001b[0m, in \u001b[0;36mMLPClassifier._score\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   1193\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_score\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_score_with_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscore_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccuracy_score\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\deni5\\OneDrive\\Documents\\Courses\\neural_networks\\NeuralNetworkProject\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:769\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron._score_with_function\u001b[1;34m(self, X, y, score_function)\u001b[0m\n\u001b[0;32m    766\u001b[0m \u001b[38;5;66;03m# Input validation would remove feature names, so we disable it\u001b[39;00m\n\u001b[0;32m    767\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict(X, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 769\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misnan\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39many() \u001b[38;5;129;01mor\u001b[39;00m np\u001b[38;5;241m.\u001b[39misinf(y_pred)\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m    770\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mnan\n\u001b[0;32m    772\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m score_function(y, y_pred)\n",
      "\u001b[1;31mTypeError\u001b[0m: ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
     ]
    }
   ],
   "source": [
    "# use MLP classifier on the pipeline\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, precision_score, f1_score\n",
    "\n",
    "X_test = test_data.drop('Flight_Status', axis=1)\n",
    "y_test = test_data['Flight_Status']\n",
    "\n",
    "# Your X_prepped is already available from previous preprocessing\n",
    "# Now we'll create and train the MLP classifier optimized for precision\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, precision_score\n",
    "\n",
    "# Create the MLP classifier with precision-focused parameters\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(100,), \n",
    "    random_state=42            \n",
    ")\n",
    "\n",
    "# Train the model using your preprocessed X data\n",
    "mlp.fit(X_prepped, y)\n",
    "\n",
    "# For testing, you'll need to apply the same preprocessing to X_test\n",
    "# If you haven't already done this, you would typically do:\n",
    "# X_test_prepped = preprocessor.transform(X_test)\n",
    "# But since you didn't specify this step, I'll assume you need to do it:\n",
    "\n",
    "# Make predictions (using whatever preprocessed test data you have)\n",
    "# If X_test is already preprocessed:\n",
    "y_pred = mlp.predict(X_test)\n",
    "# If you need to preprocess X_test:\n",
    "# y_pred = mlp.predict(X_test_prepped)\n",
    "\n",
    "# Evaluate with focus on precision\n",
    "print(\"Precision score:\", precision_score(y_test, y_pred, average='macro'))\n",
    "print(\"F1 score:\", f1_score(y_test, y_pred, average='macro'))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
